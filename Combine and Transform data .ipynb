{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_json(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_basic_data = open_json('../basic_1482000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['responseHeader', 'response'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_basic_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['zkConnected', 'status', 'QTime', 'params'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_basic_data['responseHeader'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['numFound', 'start', 'docs'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_basic_data['response'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_basic_data_list = all_basic_data['response']['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_df = pd.DataFrame(all_basic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>email</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994-06-08T22:11:38Z</td>\n",
       "      <td>549 MOUNTAINVIEW DR.</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318</td>\n",
       "      <td>54</td>\n",
       "      <td>-166</td>\n",
       "      <td>DELUCCA,SHALEE V</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-02-08T22:11:38Z</td>\n",
       "      <td>476 VIA DEL PLANO</td>\n",
       "      <td>Cold Bay</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1319</td>\n",
       "      <td>55</td>\n",
       "      <td>-163</td>\n",
       "      <td>MUSSER,WOONG T</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-08T22:11:38Z</td>\n",
       "      <td>330 S THIRD ST</td>\n",
       "      <td>False Pass</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320</td>\n",
       "      <td>55</td>\n",
       "      <td>-163</td>\n",
       "      <td>BAYLY,JASHAN G</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-08T22:11:38Z</td>\n",
       "      <td>6200 E CANYON RIM RD #110D</td>\n",
       "      <td>King Cove</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321</td>\n",
       "      <td>55</td>\n",
       "      <td>-162</td>\n",
       "      <td>SUGITA,LLOYD R</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-10-08T22:11:38Z</td>\n",
       "      <td>750 LAS GALLINAS AVE, SUITE 116A</td>\n",
       "      <td>Atka</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1324</td>\n",
       "      <td>52</td>\n",
       "      <td>-174</td>\n",
       "      <td>OSWALD II,DE QIAN B</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996-11-08T22:11:38Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saint George Island</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1325</td>\n",
       "      <td>57</td>\n",
       "      <td>-170</td>\n",
       "      <td>YAPPERT,DEZARAEE L</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1994-01-08T22:11:38Z</td>\n",
       "      <td>1526 LINCOLN ST</td>\n",
       "      <td>Nikolski</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1326</td>\n",
       "      <td>53</td>\n",
       "      <td>-169</td>\n",
       "      <td>DAMACION,TAL</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1994-05-08T22:11:38Z</td>\n",
       "      <td>2235 INYO #5</td>\n",
       "      <td>Dutch Harbor</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1329</td>\n",
       "      <td>54</td>\n",
       "      <td>-167</td>\n",
       "      <td>SAVITZ,KEALLIE ANN M</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1995-04-08T22:11:38Z</td>\n",
       "      <td>6931 STOCKTON AVENUE</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1330</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>ST LAWRENCE,MARCHELLE W</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1994-02-08T22:11:38Z</td>\n",
       "      <td>18579 OLIVE ST</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1331</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>KISSUN,ALMARIS M</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1999-04-08T22:11:38Z</td>\n",
       "      <td>8022 TAMOSHANTER DRIVE</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1332</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>ZINNERMAN,JOSEPH TODD M</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997-07-08T22:11:38Z</td>\n",
       "      <td>8830 TRENTON ROAD</td>\n",
       "      <td>Jber</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1334</td>\n",
       "      <td>60</td>\n",
       "      <td>-159</td>\n",
       "      <td>FERBER,ALEX A</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1999-08-08T22:11:38Z</td>\n",
       "      <td>110 N VALERIA ST #206</td>\n",
       "      <td>Jber</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1335</td>\n",
       "      <td>60</td>\n",
       "      <td>-159</td>\n",
       "      <td>GHIGGIA,FINIS L</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1993-03-08T22:11:38Z</td>\n",
       "      <td>105 CLEAR WATER</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1338</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>MENDOZA-RODRIGUEZ,SHAUTAVIA</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1997-05-08T22:11:38Z</td>\n",
       "      <td>5807 TEMPLE CITY BLVD</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>GOBBEL,LAVERNIA</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1997-11-08T22:11:38Z</td>\n",
       "      <td>3624 RONK WY</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1340</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>HANEEF,KASIE R</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1997-06-08T22:11:38Z</td>\n",
       "      <td>3440 MARGARET D</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1343</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>LEICHLITER,ZIA</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1997-01-08T22:11:38Z</td>\n",
       "      <td>2525 NW LOVEJOY ST #404</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1344</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>ANNIE,ROZINA</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1996-08-08T22:11:38Z</td>\n",
       "      <td>8 ESTRELLA CIRCLE</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1345</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>BOMAN,CAPRIESHA M</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1999-08-08T22:11:38Z</td>\n",
       "      <td>430 WILLOW AVE</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1348</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>IBARRA VELASCO,ANATOLI J</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1995-11-08T22:11:38Z</td>\n",
       "      <td>1076 REED AVE APT #76</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1349</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>TIDWELL JR,DEQUAN R</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1994-11-08T22:11:38Z</td>\n",
       "      <td>2502 TOLWORTH A</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1350</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>STRICKLAN,HYESOOK V</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1998-04-08T22:11:38Z</td>\n",
       "      <td>6450 DOUGHRTY RD</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1351</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>PACKEBUSH,BENJAMIN JR R</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1993-04-08T22:11:38Z</td>\n",
       "      <td>4220 PRIMRISE AVENUE</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>MOLLENA,DHEKRA L</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1993-12-08T22:11:38Z</td>\n",
       "      <td>8260 W FLAGER ST 1 H</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1353</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>FURRY ROSEMARI,JONATHON V</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1994-02-08T22:11:38Z</td>\n",
       "      <td>4397 INDIGO DR</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1354</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>EARSERY,ZELANA R</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1997-12-08T22:11:38Z</td>\n",
       "      <td>2487 WINSLOW WY</td>\n",
       "      <td>Eagle River</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1357</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>GLOW,SHIGEO</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1994-07-08T22:11:38Z</td>\n",
       "      <td>3983 KLAMATH WAY</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1359</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>NAJAER,POY-JING</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1998-06-08T22:11:38Z</td>\n",
       "      <td>3315 CHANATE RD 1E</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>61</td>\n",
       "      <td>-149</td>\n",
       "      <td>DESMAN,WIDIYATI A</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1997-06-08T22:11:38Z</td>\n",
       "      <td>100 FOWLER AVE #158</td>\n",
       "      <td>Kongiganak</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1361</td>\n",
       "      <td>60</td>\n",
       "      <td>-163</td>\n",
       "      <td>BUSENHART,LONIEL M</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417119</th>\n",
       "      <td>1987-03-08T22:11:38Z</td>\n",
       "      <td>5200 CASCADE ROAD SE</td>\n",
       "      <td>Truesdale</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397362</td>\n",
       "      <td>39</td>\n",
       "      <td>-91</td>\n",
       "      <td>KIRSTEINS,MAYTE M</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417120</th>\n",
       "      <td>1982-10-08T22:11:38Z</td>\n",
       "      <td>552 SILVA AVENUE</td>\n",
       "      <td>Warrenton</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397363</td>\n",
       "      <td>39</td>\n",
       "      <td>-91</td>\n",
       "      <td>STANFILL,MOLLEIGH A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417121</th>\n",
       "      <td>1979-10-08T22:11:38Z</td>\n",
       "      <td>P O BOX 313</td>\n",
       "      <td>Belgrade</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397366</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>MUTTER,JADENE</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417122</th>\n",
       "      <td>1979-12-08T22:11:38Z</td>\n",
       "      <td>P O BOX 8761</td>\n",
       "      <td>Caledonia</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397368</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>ZIRSCHKY,SAMANTHA RAE C</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417123</th>\n",
       "      <td>1980-05-08T22:11:38Z</td>\n",
       "      <td>2001 PINER ROAD, APT 102</td>\n",
       "      <td>Irondale</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397369</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>ROSDAIL,LEALO FITAUTE M</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417124</th>\n",
       "      <td>1986-06-08T22:11:38Z</td>\n",
       "      <td>7977 PARK DRIVE</td>\n",
       "      <td>Tiff</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397372</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>VILLARICO,CASSANDA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417125</th>\n",
       "      <td>1983-01-08T22:11:38Z</td>\n",
       "      <td>33955 JULIET CIR.</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397373</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>ALBAR-JEN,KATSUKO</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417126</th>\n",
       "      <td>1980-10-08T22:11:38Z</td>\n",
       "      <td>1195 KRONA LN</td>\n",
       "      <td>Clubb</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397375</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>VIDAS,AMAYATZIN A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417127</th>\n",
       "      <td>1983-05-08T22:11:38Z</td>\n",
       "      <td>399 E HIGHLAND AVE #516</td>\n",
       "      <td>Lodi</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397377</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>MANJARREZ,SALIYAH M</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417128</th>\n",
       "      <td>1985-09-08T22:11:38Z</td>\n",
       "      <td>1143 NW 64TH TERR, DIV 1</td>\n",
       "      <td>Lowndes</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397378</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>SPICUGLIA,LESLEY ANNE M</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417129</th>\n",
       "      <td>1987-06-08T22:11:38Z</td>\n",
       "      <td>210 CALEDONIA ST #B</td>\n",
       "      <td>Silva</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397382</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>JOHNSON RONALD,SHELDA D</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417130</th>\n",
       "      <td>1986-05-08T22:11:38Z</td>\n",
       "      <td>745 DAVIS ST #B</td>\n",
       "      <td>Diggins</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397385</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>ESPLANA,AUSHLEY C</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417131</th>\n",
       "      <td>1979-08-08T22:11:38Z</td>\n",
       "      <td>901 CAMPUS DR STE 112</td>\n",
       "      <td>Elkland</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397386</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>HULEN,SHANEA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417132</th>\n",
       "      <td>1985-05-08T22:11:38Z</td>\n",
       "      <td>1108 WEST TOKAY STREET</td>\n",
       "      <td>Fordland</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397387</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>TELLES JR,M.MICHELE I</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417133</th>\n",
       "      <td>1979-06-08T22:11:38Z</td>\n",
       "      <td>780 GUERRERE ST #10</td>\n",
       "      <td>Marshfield</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397388</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>PRESNAR JR,HUIZHEN J</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417134</th>\n",
       "      <td>1981-05-08T22:11:38Z</td>\n",
       "      <td>2836 MERLE AVEN</td>\n",
       "      <td>Niangua</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397389</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>WILLNER,LUZ-PILAR</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417135</th>\n",
       "      <td>1985-03-08T22:11:38Z</td>\n",
       "      <td>P.O. BOX 92</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397391</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>GONDORF,TYSCHELL N</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417136</th>\n",
       "      <td>1978-02-08T22:11:38Z</td>\n",
       "      <td>1538 ELMAR WAY</td>\n",
       "      <td>Allendale</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397392</td>\n",
       "      <td>40</td>\n",
       "      <td>-94</td>\n",
       "      <td>MAISLEN,ARILYNN</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417137</th>\n",
       "      <td>1982-01-08T22:11:38Z</td>\n",
       "      <td>9118 N WEST LANE</td>\n",
       "      <td>Denver</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397393</td>\n",
       "      <td>40</td>\n",
       "      <td>-94</td>\n",
       "      <td>BAMBRICK,LA LONNIE A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417138</th>\n",
       "      <td>1981-03-08T22:11:38Z</td>\n",
       "      <td>111 VIA TERESA</td>\n",
       "      <td>Grant City</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397394</td>\n",
       "      <td>40</td>\n",
       "      <td>-94</td>\n",
       "      <td>MANSOUR,MILA VILLA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417139</th>\n",
       "      <td>1987-04-08T22:11:38Z</td>\n",
       "      <td>6929 BISMARCK DRIVE</td>\n",
       "      <td>Sheridan</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397395</td>\n",
       "      <td>40</td>\n",
       "      <td>-95</td>\n",
       "      <td>HATHCOCK,YESINA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417140</th>\n",
       "      <td>1979-05-08T22:11:38Z</td>\n",
       "      <td>6394 E SANTA ANA CYN RD</td>\n",
       "      <td>Graff</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397397</td>\n",
       "      <td>37</td>\n",
       "      <td>-92</td>\n",
       "      <td>WURTS,JANADA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417141</th>\n",
       "      <td>1984-03-08T22:11:38Z</td>\n",
       "      <td>295 FELL ST STE B</td>\n",
       "      <td>Grovespring</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397398</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>MCCAMMOND,CAITLEN</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417142</th>\n",
       "      <td>1985-11-08T22:11:38Z</td>\n",
       "      <td>237 VEGA ROAD</td>\n",
       "      <td>Hartville</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397399</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>FARRAY,SANCHITA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417143</th>\n",
       "      <td>1978-09-08T22:11:38Z</td>\n",
       "      <td>77 BAYLOR LANE</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397401</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>ROJAS MIRANDA,MAYKAYLA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417144</th>\n",
       "      <td>1979-07-08T22:11:38Z</td>\n",
       "      <td>641 NELLO DR #2</td>\n",
       "      <td>Norwood</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397403</td>\n",
       "      <td>37</td>\n",
       "      <td>-92</td>\n",
       "      <td>MALFA,CLELID L</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417145</th>\n",
       "      <td>1983-01-08T22:11:38Z</td>\n",
       "      <td>4303 N EMERSON ST</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397405</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>FISHER-GILL,SILVERIA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417146</th>\n",
       "      <td>1983-02-08T22:11:38Z</td>\n",
       "      <td>218 PENNSYLVANIA AVE</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397406</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>TANNE,CHAIZ</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417147</th>\n",
       "      <td>1980-11-08T22:11:38Z</td>\n",
       "      <td>600 SAN PABLO AVENUE #202</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397410</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>SHOUN,AI HUA A</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417148</th>\n",
       "      <td>1986-01-08T22:11:38Z</td>\n",
       "      <td>1260 ROMO DRIVE</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397411</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>DRING,JODEEN</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417149 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DOB                           address  \\\n",
       "0       1994-06-08T22:11:38Z              549 MOUNTAINVIEW DR.   \n",
       "1       1999-02-08T22:11:38Z                 476 VIA DEL PLANO   \n",
       "2       1999-01-08T22:11:38Z                    330 S THIRD ST   \n",
       "3       1999-11-08T22:11:38Z        6200 E CANYON RIM RD #110D   \n",
       "4       1995-10-08T22:11:38Z  750 LAS GALLINAS AVE, SUITE 116A   \n",
       "5       1996-11-08T22:11:38Z                               NaN   \n",
       "6       1994-01-08T22:11:38Z                   1526 LINCOLN ST   \n",
       "7       1994-05-08T22:11:38Z                      2235 INYO #5   \n",
       "8       1995-04-08T22:11:38Z              6931 STOCKTON AVENUE   \n",
       "9       1994-02-08T22:11:38Z                    18579 OLIVE ST   \n",
       "10      1999-04-08T22:11:38Z            8022 TAMOSHANTER DRIVE   \n",
       "11      1997-07-08T22:11:38Z                 8830 TRENTON ROAD   \n",
       "12      1999-08-08T22:11:38Z             110 N VALERIA ST #206   \n",
       "13      1993-03-08T22:11:38Z                   105 CLEAR WATER   \n",
       "14      1997-05-08T22:11:38Z             5807 TEMPLE CITY BLVD   \n",
       "15      1997-11-08T22:11:38Z                      3624 RONK WY   \n",
       "16      1997-06-08T22:11:38Z                   3440 MARGARET D   \n",
       "17      1997-01-08T22:11:38Z           2525 NW LOVEJOY ST #404   \n",
       "18      1996-08-08T22:11:38Z                 8 ESTRELLA CIRCLE   \n",
       "19      1999-08-08T22:11:38Z                    430 WILLOW AVE   \n",
       "20      1995-11-08T22:11:38Z             1076 REED AVE APT #76   \n",
       "21      1994-11-08T22:11:38Z                   2502 TOLWORTH A   \n",
       "22      1998-04-08T22:11:38Z                  6450 DOUGHRTY RD   \n",
       "23      1993-04-08T22:11:38Z              4220 PRIMRISE AVENUE   \n",
       "24      1993-12-08T22:11:38Z              8260 W FLAGER ST 1 H   \n",
       "25      1994-02-08T22:11:38Z                    4397 INDIGO DR   \n",
       "26      1997-12-08T22:11:38Z                   2487 WINSLOW WY   \n",
       "27      1994-07-08T22:11:38Z                  3983 KLAMATH WAY   \n",
       "28      1998-06-08T22:11:38Z                3315 CHANATE RD 1E   \n",
       "29      1997-06-08T22:11:38Z               100 FOWLER AVE #158   \n",
       "...                      ...                               ...   \n",
       "417119  1987-03-08T22:11:38Z              5200 CASCADE ROAD SE   \n",
       "417120  1982-10-08T22:11:38Z                  552 SILVA AVENUE   \n",
       "417121  1979-10-08T22:11:38Z                       P O BOX 313   \n",
       "417122  1979-12-08T22:11:38Z                      P O BOX 8761   \n",
       "417123  1980-05-08T22:11:38Z          2001 PINER ROAD, APT 102   \n",
       "417124  1986-06-08T22:11:38Z                   7977 PARK DRIVE   \n",
       "417125  1983-01-08T22:11:38Z                 33955 JULIET CIR.   \n",
       "417126  1980-10-08T22:11:38Z                     1195 KRONA LN   \n",
       "417127  1983-05-08T22:11:38Z           399 E HIGHLAND AVE #516   \n",
       "417128  1985-09-08T22:11:38Z          1143 NW 64TH TERR, DIV 1   \n",
       "417129  1987-06-08T22:11:38Z               210 CALEDONIA ST #B   \n",
       "417130  1986-05-08T22:11:38Z                   745 DAVIS ST #B   \n",
       "417131  1979-08-08T22:11:38Z             901 CAMPUS DR STE 112   \n",
       "417132  1985-05-08T22:11:38Z            1108 WEST TOKAY STREET   \n",
       "417133  1979-06-08T22:11:38Z               780 GUERRERE ST #10   \n",
       "417134  1981-05-08T22:11:38Z                   2836 MERLE AVEN   \n",
       "417135  1985-03-08T22:11:38Z                       P.O. BOX 92   \n",
       "417136  1978-02-08T22:11:38Z                    1538 ELMAR WAY   \n",
       "417137  1982-01-08T22:11:38Z                  9118 N WEST LANE   \n",
       "417138  1981-03-08T22:11:38Z                    111 VIA TERESA   \n",
       "417139  1987-04-08T22:11:38Z               6929 BISMARCK DRIVE   \n",
       "417140  1979-05-08T22:11:38Z           6394 E SANTA ANA CYN RD   \n",
       "417141  1984-03-08T22:11:38Z                 295 FELL ST STE B   \n",
       "417142  1985-11-08T22:11:38Z                     237 VEGA ROAD   \n",
       "417143  1978-09-08T22:11:38Z                    77 BAYLOR LANE   \n",
       "417144  1979-07-08T22:11:38Z                   641 NELLO DR #2   \n",
       "417145  1983-01-08T22:11:38Z                 4303 N EMERSON ST   \n",
       "417146  1983-02-08T22:11:38Z              218 PENNSYLVANIA AVE   \n",
       "417147  1980-11-08T22:11:38Z         600 SAN PABLO AVENUE #202   \n",
       "417148  1986-01-08T22:11:38Z                   1260 ROMO DRIVE   \n",
       "\n",
       "                       city  collection_id email      id  latitude  longitude  \\\n",
       "0                    Akutan  V_Participant   NaN    1318        54       -166   \n",
       "1                  Cold Bay  V_Participant   NaN    1319        55       -163   \n",
       "2                False Pass  V_Participant   NaN    1320        55       -163   \n",
       "3                 King Cove  V_Participant   NaN    1321        55       -162   \n",
       "4                      Atka  V_Participant   NaN    1324        52       -174   \n",
       "5       Saint George Island  V_Participant   NaN    1325        57       -170   \n",
       "6                  Nikolski  V_Participant   NaN    1326        53       -169   \n",
       "7              Dutch Harbor  V_Participant   NaN    1329        54       -167   \n",
       "8                 Anchorage  V_Participant   NaN    1330        61       -150   \n",
       "9                 Anchorage  V_Participant   NaN    1331        61       -150   \n",
       "10                Anchorage  V_Participant   NaN    1332        61       -150   \n",
       "11                     Jber  V_Participant   NaN    1334        60       -159   \n",
       "12                     Jber  V_Participant   NaN    1335        60       -159   \n",
       "13                Anchorage  V_Participant   NaN    1338        61       -150   \n",
       "14                Anchorage  V_Participant   NaN    1339        61       -150   \n",
       "15                Anchorage  V_Participant   NaN    1340        61       -150   \n",
       "16                Anchorage  V_Participant   NaN    1343        61       -150   \n",
       "17                Anchorage  V_Participant   NaN    1344        61       -150   \n",
       "18                Anchorage  V_Participant   NaN    1345        61       -150   \n",
       "19                Anchorage  V_Participant   NaN    1348        61       -150   \n",
       "20                Anchorage  V_Participant   NaN    1349        61       -150   \n",
       "21                Anchorage  V_Participant   NaN    1350        61       -150   \n",
       "22                Anchorage  V_Participant   NaN    1351        61       -150   \n",
       "23                Anchorage  V_Participant   NaN    1352        61       -150   \n",
       "24                Anchorage  V_Participant   NaN    1353        61       -150   \n",
       "25                Anchorage  V_Participant   NaN    1354        61       -150   \n",
       "26              Eagle River  V_Participant   NaN    1357        61       -150   \n",
       "27                Anchorage  V_Participant   NaN    1359        61       -150   \n",
       "28                Anchorage  V_Participant   NaN    1360        61       -149   \n",
       "29               Kongiganak  V_Participant   NaN    1361        60       -163   \n",
       "...                     ...            ...   ...     ...       ...        ...   \n",
       "417119            Truesdale  V_Participant   NaN  397362        39        -91   \n",
       "417120            Warrenton  V_Participant   NaN  397363        39        -91   \n",
       "417121             Belgrade  V_Participant   NaN  397366        38        -91   \n",
       "417122            Caledonia  V_Participant   NaN  397368        38        -91   \n",
       "417123             Irondale  V_Participant   NaN  397369        38        -91   \n",
       "417124                 Tiff  V_Participant   NaN  397372        38        -91   \n",
       "417125              Cascade  V_Participant   NaN  397373        37        -90   \n",
       "417126                Clubb  V_Participant   NaN  397375        37        -90   \n",
       "417127                 Lodi  V_Participant   NaN  397377        37        -90   \n",
       "417128              Lowndes  V_Participant   NaN  397378        37        -90   \n",
       "417129                Silva  V_Participant   NaN  397382        37        -90   \n",
       "417130              Diggins  V_Participant   NaN  397385        37        -93   \n",
       "417131              Elkland  V_Participant   NaN  397386        37        -93   \n",
       "417132             Fordland  V_Participant   NaN  397387        37        -93   \n",
       "417133           Marshfield  V_Participant   NaN  397388        37        -93   \n",
       "417134              Niangua  V_Participant   NaN  397389        37        -93   \n",
       "417135              Seymour  V_Participant   NaN  397391        37        -93   \n",
       "417136            Allendale  V_Participant   NaN  397392        40        -94   \n",
       "417137               Denver  V_Participant   NaN  397393        40        -94   \n",
       "417138           Grant City  V_Participant   NaN  397394        40        -94   \n",
       "417139             Sheridan  V_Participant   NaN  397395        40        -95   \n",
       "417140                Graff  V_Participant   NaN  397397        37        -92   \n",
       "417141          Grovespring  V_Participant   NaN  397398        37        -93   \n",
       "417142            Hartville  V_Participant   NaN  397399        37        -93   \n",
       "417143            Mansfield  V_Participant   NaN  397401        37        -93   \n",
       "417144              Norwood  V_Participant   NaN  397403        37        -92   \n",
       "417145          Saint Louis  V_Participant   NaN  397405        39        -90   \n",
       "417146          Saint Louis  V_Participant   NaN  397406        39        -90   \n",
       "417147          Saint Louis  V_Participant   NaN  397410        39        -90   \n",
       "417148          Saint Louis  V_Participant   NaN  397411        39        -90   \n",
       "\n",
       "                                name sex     state  \n",
       "0                   DELUCCA,SHALEE V   M    Alaska  \n",
       "1                     MUSSER,WOONG T   F    Alaska  \n",
       "2                     BAYLY,JASHAN G   M    Alaska  \n",
       "3                     SUGITA,LLOYD R   F    Alaska  \n",
       "4                OSWALD II,DE QIAN B   M    Alaska  \n",
       "5                 YAPPERT,DEZARAEE L   F    Alaska  \n",
       "6                      DAMACION,TAL    M    Alaska  \n",
       "7               SAVITZ,KEALLIE ANN M   F    Alaska  \n",
       "8            ST LAWRENCE,MARCHELLE W   M    Alaska  \n",
       "9                   KISSUN,ALMARIS M   F    Alaska  \n",
       "10           ZINNERMAN,JOSEPH TODD M   M    Alaska  \n",
       "11                     FERBER,ALEX A   M    Alaska  \n",
       "12                   GHIGGIA,FINIS L   F    Alaska  \n",
       "13      MENDOZA-RODRIGUEZ,SHAUTAVIA    M    Alaska  \n",
       "14                  GOBBEL,LAVERNIA    F    Alaska  \n",
       "15                    HANEEF,KASIE R   M    Alaska  \n",
       "16                   LEICHLITER,ZIA    F    Alaska  \n",
       "17                     ANNIE,ROZINA    M    Alaska  \n",
       "18                 BOMAN,CAPRIESHA M   F    Alaska  \n",
       "19          IBARRA VELASCO,ANATOLI J   M    Alaska  \n",
       "20               TIDWELL JR,DEQUAN R   F    Alaska  \n",
       "21               STRICKLAN,HYESOOK V   M    Alaska  \n",
       "22           PACKEBUSH,BENJAMIN JR R   F    Alaska  \n",
       "23                  MOLLENA,DHEKRA L   M    Alaska  \n",
       "24         FURRY ROSEMARI,JONATHON V   F    Alaska  \n",
       "25                  EARSERY,ZELANA R   M    Alaska  \n",
       "26                      GLOW,SHIGEO    F    Alaska  \n",
       "27                  NAJAER,POY-JING    F    Alaska  \n",
       "28                 DESMAN,WIDIYATI A   M    Alaska  \n",
       "29                BUSENHART,LONIEL M   F    Alaska  \n",
       "...                              ...  ..       ...  \n",
       "417119             KIRSTEINS,MAYTE M   M  Missouri  \n",
       "417120           STANFILL,MOLLEIGH A   F  Missouri  \n",
       "417121                MUTTER,JADENE    M  Missouri  \n",
       "417122       ZIRSCHKY,SAMANTHA RAE C   M  Missouri  \n",
       "417123       ROSDAIL,LEALO FITAUTE M   F  Missouri  \n",
       "417124           VILLARICO,CASSANDA    M  Missouri  \n",
       "417125            ALBAR-JEN,KATSUKO    F  Missouri  \n",
       "417126             VIDAS,AMAYATZIN A   F  Missouri  \n",
       "417127           MANJARREZ,SALIYAH M   F  Missouri  \n",
       "417128       SPICUGLIA,LESLEY ANNE M   M  Missouri  \n",
       "417129       JOHNSON RONALD,SHELDA D   M  Missouri  \n",
       "417130             ESPLANA,AUSHLEY C   F  Missouri  \n",
       "417131                 HULEN,SHANEA    M  Missouri  \n",
       "417132         TELLES JR,M.MICHELE I   F  Missouri  \n",
       "417133          PRESNAR JR,HUIZHEN J   M  Missouri  \n",
       "417134            WILLNER,LUZ-PILAR    F  Missouri  \n",
       "417135            GONDORF,TYSCHELL N   F  Missouri  \n",
       "417136              MAISLEN,ARILYNN    M  Missouri  \n",
       "417137          BAMBRICK,LA LONNIE A   F  Missouri  \n",
       "417138           MANSOUR,MILA VILLA    M  Missouri  \n",
       "417139              HATHCOCK,YESINA    F  Missouri  \n",
       "417140                 WURTS,JANADA    F  Missouri  \n",
       "417141            MCCAMMOND,CAITLEN    M  Missouri  \n",
       "417142              FARRAY,SANCHITA    F  Missouri  \n",
       "417143       ROJAS MIRANDA,MAYKAYLA    F  Missouri  \n",
       "417144                MALFA,CLELID L   F  Missouri  \n",
       "417145         FISHER-GILL,SILVERIA    F  Missouri  \n",
       "417146                  TANNE,CHAIZ    M  Missouri  \n",
       "417147                SHOUN,AI HUA A   M  Missouri  \n",
       "417148                 DRING,JODEEN    F  Missouri  \n",
       "\n",
       "[417149 rows x 11 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alaska', 'Arizona', 'California', 'Colorado',\n",
       "       'District of Columbia', nan, 'Hawaii', 'Iowa', 'Idaho', 'Minnesota',\n",
       "       'Montana', 'North Dakota', 'New Mexico', 'Nevada', 'Oregon',\n",
       "       'South Dakota', 'Texas', 'Utah', 'Washington', 'Wisconsin',\n",
       "       'Wyoming', 'Alabama', 'Arkansas', 'Florida', 'Georgia', 'Illinois',\n",
       "       'Kansas', 'Louisiana', 'Missouri', 'Mississippi', 'Nebraska',\n",
       "       'Oklahoma', 'Tennessee', 'New Jersey', 'New York', 'Ohio',\n",
       "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'Virginia',\n",
       "       'Vermont', 'West Virginia', 'Connecticut', 'Delaware', 'Indiana',\n",
       "       'Kentucky', 'Massachusetts', 'Maryland', 'Maine', 'Michigan',\n",
       "       'North Carolina', 'New Hampshire'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417149"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_basic_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         416968\n",
       "unique            51\n",
       "top       California\n",
       "freq           50166\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df['state'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California              50166\n",
       "Texas                   27059\n",
       "Iowa                    20366\n",
       "Minnesota               19188\n",
       "Illinois                17007\n",
       "Florida                 16842\n",
       "Wisconsin               16740\n",
       "Washington              13390\n",
       "Missouri                13283\n",
       "Colorado                12536\n",
       "Georgia                 10303\n",
       "Arizona                 10140\n",
       "Oregon                   8901\n",
       "Alabama                  8874\n",
       "Kansas                   8535\n",
       "Louisiana                8292\n",
       "Oklahoma                 8187\n",
       "Tennessee                8131\n",
       "New York                 8039\n",
       "Arkansas                 7952\n",
       "Montana                  7858\n",
       "New Mexico               7829\n",
       "North Dakota             7681\n",
       "South Dakota             7195\n",
       "Pennsylvania             7173\n",
       "Nebraska                 6695\n",
       "Utah                     6464\n",
       "Idaho                    6219\n",
       "Mississippi              5775\n",
       "Ohio                     5334\n",
       "Alaska                   5265\n",
       "Nevada                   4688\n",
       "Indiana                  4123\n",
       "Virginia                 4024\n",
       "Wyoming                  3642\n",
       "Michigan                 3556\n",
       "West Virginia            3505\n",
       "Kentucky                 3443\n",
       "North Carolina           3260\n",
       "Hawaii                   2618\n",
       "Massachusetts            2581\n",
       "New Jersey               2462\n",
       "Maryland                 2239\n",
       "Connecticut              1928\n",
       "Maine                    1816\n",
       "South Carolina           1666\n",
       "District of Columbia     1282\n",
       "Vermont                  1135\n",
       "New Hampshire             849\n",
       "Delaware                  436\n",
       "Rhode Island              296\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decisions_df = pd.read_json('../decisions_semi_complete.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRONZE</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>PLATINUM</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>360653.000000</td>\n",
       "      <td>360653.000000</td>\n",
       "      <td>360653.000000</td>\n",
       "      <td>360653.000000</td>\n",
       "      <td>3.606530e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.996759</td>\n",
       "      <td>151.316376</td>\n",
       "      <td>225.972070</td>\n",
       "      <td>95.324606</td>\n",
       "      <td>6.312162e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.410558</td>\n",
       "      <td>42.539314</td>\n",
       "      <td>65.403851</td>\n",
       "      <td>26.066217</td>\n",
       "      <td>3.329092e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.356450e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>5.640740e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>7.947420e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>1.482000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BRONZE           GOLD       PLATINUM         SILVER  \\\n",
       "count  360653.000000  360653.000000  360653.000000  360653.000000   \n",
       "mean       57.996759     151.316376     225.972070      95.324606   \n",
       "std        16.410558      42.539314      65.403851      26.066217   \n",
       "min        20.000000      70.000000     110.000000      40.000000   \n",
       "25%        45.000000     121.000000     180.000000      76.000000   \n",
       "50%        56.000000     137.000000     201.000000      89.000000   \n",
       "75%        70.000000     177.000000     259.000000     113.000000   \n",
       "max       136.000000     286.000000     406.000000     196.000000   \n",
       "\n",
       "                 id  \n",
       "count  3.606530e+05  \n",
       "mean   6.312162e+05  \n",
       "std    3.329092e+05  \n",
       "min    4.000000e+00  \n",
       "25%    4.356450e+05  \n",
       "50%    5.640740e+05  \n",
       "75%    7.947420e+05  \n",
       "max    1.482000e+06  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRONZE</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>PLATINUM</th>\n",
       "      <th>PURCHASED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>187</td>\n",
       "      <td>283</td>\n",
       "      <td>Silver</td>\n",
       "      <td>115</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>912064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>151</td>\n",
       "      <td>227</td>\n",
       "      <td>Silver</td>\n",
       "      <td>94</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>762522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>228</td>\n",
       "      <td>348</td>\n",
       "      <td>Silver</td>\n",
       "      <td>138</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1196870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>221</td>\n",
       "      <td>333</td>\n",
       "      <td>Silver</td>\n",
       "      <td>137</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1343385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>171</td>\n",
       "      <td>247</td>\n",
       "      <td>Silver</td>\n",
       "      <td>114</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>706684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47</td>\n",
       "      <td>102</td>\n",
       "      <td>146</td>\n",
       "      <td>Silver</td>\n",
       "      <td>69</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>27846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>150</td>\n",
       "      <td>Silver</td>\n",
       "      <td>59</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>133968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>97</td>\n",
       "      <td>149</td>\n",
       "      <td>Silver</td>\n",
       "      <td>58</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>601707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76</td>\n",
       "      <td>161</td>\n",
       "      <td>229</td>\n",
       "      <td>Silver</td>\n",
       "      <td>110</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>437776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>230</td>\n",
       "      <td>350</td>\n",
       "      <td>Silver</td>\n",
       "      <td>140</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1163794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75</td>\n",
       "      <td>225</td>\n",
       "      <td>345</td>\n",
       "      <td>Silver</td>\n",
       "      <td>135</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1095202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>78</td>\n",
       "      <td>228</td>\n",
       "      <td>348</td>\n",
       "      <td>Silver</td>\n",
       "      <td>138</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1083496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76</td>\n",
       "      <td>216</td>\n",
       "      <td>328</td>\n",
       "      <td>Silver</td>\n",
       "      <td>132</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1438332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>79</td>\n",
       "      <td>219</td>\n",
       "      <td>331</td>\n",
       "      <td>Silver</td>\n",
       "      <td>135</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1135280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>61</td>\n",
       "      <td>126</td>\n",
       "      <td>178</td>\n",
       "      <td>Silver</td>\n",
       "      <td>87</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>84754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49</td>\n",
       "      <td>114</td>\n",
       "      <td>166</td>\n",
       "      <td>Silver</td>\n",
       "      <td>75</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>179881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>85</td>\n",
       "      <td>235</td>\n",
       "      <td>355</td>\n",
       "      <td>Silver</td>\n",
       "      <td>145</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1024021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>126</td>\n",
       "      <td>186</td>\n",
       "      <td>Silver</td>\n",
       "      <td>81</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>429696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "      <td>225</td>\n",
       "      <td>345</td>\n",
       "      <td>Silver</td>\n",
       "      <td>135</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1203130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>65</td>\n",
       "      <td>215</td>\n",
       "      <td>335</td>\n",
       "      <td>Silver</td>\n",
       "      <td>125</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>151</td>\n",
       "      <td>227</td>\n",
       "      <td>Silver</td>\n",
       "      <td>94</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>730306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>370</td>\n",
       "      <td>Silver</td>\n",
       "      <td>160</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1379022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>76</td>\n",
       "      <td>216</td>\n",
       "      <td>328</td>\n",
       "      <td>Silver</td>\n",
       "      <td>132</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1017439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>114</td>\n",
       "      <td>174</td>\n",
       "      <td>Silver</td>\n",
       "      <td>69</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>637013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>85</td>\n",
       "      <td>235</td>\n",
       "      <td>355</td>\n",
       "      <td>Silver</td>\n",
       "      <td>145</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1091398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>66</td>\n",
       "      <td>151</td>\n",
       "      <td>219</td>\n",
       "      <td>Silver</td>\n",
       "      <td>100</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>651310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>66</td>\n",
       "      <td>151</td>\n",
       "      <td>219</td>\n",
       "      <td>Silver</td>\n",
       "      <td>100</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38</td>\n",
       "      <td>103</td>\n",
       "      <td>155</td>\n",
       "      <td>Silver</td>\n",
       "      <td>64</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>161393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80</td>\n",
       "      <td>200</td>\n",
       "      <td>296</td>\n",
       "      <td>Silver</td>\n",
       "      <td>128</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>899146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>93</td>\n",
       "      <td>243</td>\n",
       "      <td>363</td>\n",
       "      <td>Silver</td>\n",
       "      <td>153</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>1428038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360623</th>\n",
       "      <td>41</td>\n",
       "      <td>116</td>\n",
       "      <td>176</td>\n",
       "      <td>Silver</td>\n",
       "      <td>71</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360624</th>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>190</td>\n",
       "      <td>Silver</td>\n",
       "      <td>85</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360625</th>\n",
       "      <td>59</td>\n",
       "      <td>134</td>\n",
       "      <td>194</td>\n",
       "      <td>Silver</td>\n",
       "      <td>89</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360626</th>\n",
       "      <td>39</td>\n",
       "      <td>114</td>\n",
       "      <td>174</td>\n",
       "      <td>Gold</td>\n",
       "      <td>69</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360627</th>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>210</td>\n",
       "      <td>Silver</td>\n",
       "      <td>105</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360628</th>\n",
       "      <td>43</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>Silver</td>\n",
       "      <td>77</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360629</th>\n",
       "      <td>41</td>\n",
       "      <td>116</td>\n",
       "      <td>176</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>71</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360630</th>\n",
       "      <td>52</td>\n",
       "      <td>117</td>\n",
       "      <td>169</td>\n",
       "      <td>Silver</td>\n",
       "      <td>78</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360631</th>\n",
       "      <td>76</td>\n",
       "      <td>161</td>\n",
       "      <td>229</td>\n",
       "      <td>Silver</td>\n",
       "      <td>110</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360632</th>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>190</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>85</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360633</th>\n",
       "      <td>39</td>\n",
       "      <td>114</td>\n",
       "      <td>174</td>\n",
       "      <td>Silver</td>\n",
       "      <td>69</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360634</th>\n",
       "      <td>47</td>\n",
       "      <td>112</td>\n",
       "      <td>164</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>73</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360635</th>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "      <td>197</td>\n",
       "      <td>Silver</td>\n",
       "      <td>92</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360636</th>\n",
       "      <td>80</td>\n",
       "      <td>165</td>\n",
       "      <td>233</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>114</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360637</th>\n",
       "      <td>96</td>\n",
       "      <td>181</td>\n",
       "      <td>249</td>\n",
       "      <td>Gold</td>\n",
       "      <td>130</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360638</th>\n",
       "      <td>52</td>\n",
       "      <td>117</td>\n",
       "      <td>169</td>\n",
       "      <td>Gold</td>\n",
       "      <td>78</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360639</th>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "      <td>197</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>92</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360640</th>\n",
       "      <td>41</td>\n",
       "      <td>116</td>\n",
       "      <td>176</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>71</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360641</th>\n",
       "      <td>46</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>76</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360642</th>\n",
       "      <td>86</td>\n",
       "      <td>171</td>\n",
       "      <td>239</td>\n",
       "      <td>Gold</td>\n",
       "      <td>120</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360643</th>\n",
       "      <td>36</td>\n",
       "      <td>111</td>\n",
       "      <td>171</td>\n",
       "      <td>Gold</td>\n",
       "      <td>66</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360644</th>\n",
       "      <td>44</td>\n",
       "      <td>119</td>\n",
       "      <td>179</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>74</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360645</th>\n",
       "      <td>56</td>\n",
       "      <td>131</td>\n",
       "      <td>191</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>86</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360646</th>\n",
       "      <td>61</td>\n",
       "      <td>146</td>\n",
       "      <td>214</td>\n",
       "      <td>Silver</td>\n",
       "      <td>95</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360647</th>\n",
       "      <td>41</td>\n",
       "      <td>116</td>\n",
       "      <td>176</td>\n",
       "      <td>Silver</td>\n",
       "      <td>71</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360648</th>\n",
       "      <td>52</td>\n",
       "      <td>127</td>\n",
       "      <td>187</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>82</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360649</th>\n",
       "      <td>41</td>\n",
       "      <td>116</td>\n",
       "      <td>176</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>71</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360650</th>\n",
       "      <td>59</td>\n",
       "      <td>134</td>\n",
       "      <td>194</td>\n",
       "      <td>Silver</td>\n",
       "      <td>89</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360651</th>\n",
       "      <td>46</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>Silver</td>\n",
       "      <td>76</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360652</th>\n",
       "      <td>36</td>\n",
       "      <td>111</td>\n",
       "      <td>171</td>\n",
       "      <td>Silver</td>\n",
       "      <td>66</td>\n",
       "      <td>v_quotes</td>\n",
       "      <td>657796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360653 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BRONZE  GOLD  PLATINUM PURCHASED  SILVER collection_id       id\n",
       "0           67   187       283    Silver     115      v_quotes   912064\n",
       "1           56   151       227    Silver      94      v_quotes   762522\n",
       "2           78   228       348    Silver     138      v_quotes  1196870\n",
       "3           81   221       333    Silver     137      v_quotes  1343385\n",
       "4           76   171       247    Silver     114      v_quotes   706684\n",
       "5           47   102       146    Silver      69      v_quotes    27846\n",
       "6           33    98       150    Silver      59      v_quotes   133968\n",
       "7           32    97       149    Silver      58      v_quotes   601707\n",
       "8           76   161       229    Silver     110      v_quotes   437776\n",
       "9           80   230       350    Silver     140      v_quotes  1163794\n",
       "10          75   225       345    Silver     135      v_quotes  1095202\n",
       "11          78   228       348    Silver     138      v_quotes  1083496\n",
       "12          76   216       328    Silver     132      v_quotes  1438332\n",
       "13          79   219       331    Silver     135      v_quotes  1135280\n",
       "14          61   126       178    Silver      87      v_quotes    84754\n",
       "15          49   114       166    Silver      75      v_quotes   179881\n",
       "16          85   235       355    Silver     145      v_quotes  1024021\n",
       "17          51   126       186    Silver      81      v_quotes   429696\n",
       "18          75   225       345    Silver     135      v_quotes  1203130\n",
       "19          65   215       335    Silver     125      v_quotes  1056300\n",
       "20          56   151       227    Silver      94      v_quotes   730306\n",
       "21         100   250       370    Silver     160      v_quotes  1379022\n",
       "22          76   216       328    Silver     132      v_quotes  1017439\n",
       "23          39   114       174    Silver      69      v_quotes   637013\n",
       "24          85   235       355    Silver     145      v_quotes  1091398\n",
       "25          66   151       219    Silver     100      v_quotes   651310\n",
       "26          66   151       219    Silver     100      v_quotes   357422\n",
       "27          38   103       155    Silver      64      v_quotes   161393\n",
       "28          80   200       296    Silver     128      v_quotes   899146\n",
       "29          93   243       363    Silver     153      v_quotes  1428038\n",
       "...        ...   ...       ...       ...     ...           ...      ...\n",
       "360623      41   116       176    Silver      71      v_quotes   657741\n",
       "360624      55   130       190    Silver      85      v_quotes   657742\n",
       "360625      59   134       194    Silver      89      v_quotes   657745\n",
       "360626      39   114       174      Gold      69      v_quotes   657746\n",
       "360627      75   150       210    Silver     105      v_quotes   657747\n",
       "360628      43   128       196    Silver      77      v_quotes   657749\n",
       "360629      41   116       176    Bronze      71      v_quotes   657752\n",
       "360630      52   117       169    Silver      78      v_quotes   657753\n",
       "360631      76   161       229    Silver     110      v_quotes   657757\n",
       "360632      55   130       190    Bronze      85      v_quotes   657759\n",
       "360633      39   114       174    Silver      69      v_quotes   657764\n",
       "360634      47   112       164    Bronze      73      v_quotes   657765\n",
       "360635      62   137       197    Silver      92      v_quotes   657767\n",
       "360636      80   165       233    Bronze     114      v_quotes   657770\n",
       "360637      96   181       249      Gold     130      v_quotes   657771\n",
       "360638      52   117       169      Gold      78      v_quotes   657775\n",
       "360639      62   137       197    Bronze      92      v_quotes   657776\n",
       "360640      41   116       176    Bronze      71      v_quotes   657778\n",
       "360641      46   121       181    Bronze      76      v_quotes   657781\n",
       "360642      86   171       239      Gold     120      v_quotes   657782\n",
       "360643      36   111       171      Gold      66      v_quotes   657783\n",
       "360644      44   119       179    Bronze      74      v_quotes   657784\n",
       "360645      56   131       191    Bronze      86      v_quotes   657786\n",
       "360646      61   146       214    Silver      95      v_quotes   657788\n",
       "360647      41   116       176    Silver      71      v_quotes   657789\n",
       "360648      52   127       187    Bronze      82      v_quotes   657791\n",
       "360649      41   116       176    Bronze      71      v_quotes   657792\n",
       "360650      59   134       194    Silver      89      v_quotes   657793\n",
       "360651      46   121       181    Silver      76      v_quotes   657795\n",
       "360652      36   111       171    Silver      66      v_quotes   657796\n",
       "\n",
       "[360653 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decisions_df['id'] = decisions_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOB              object\n",
       "address          object\n",
       "city             object\n",
       "collection_id    object\n",
       "email            object\n",
       "id               object\n",
       "latitude          int64\n",
       "longitude         int64\n",
       "name             object\n",
       "sex              object\n",
       "state            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONZE            int64\n",
       "GOLD              int64\n",
       "PLATINUM          int64\n",
       "PURCHASED        object\n",
       "SILVER            int64\n",
       "collection_id    object\n",
       "id               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_bd_df = basic_df.merge(decisions_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>BRONZE</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>PLATINUM</th>\n",
       "      <th>SILVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92882.000000</td>\n",
       "      <td>92882.000000</td>\n",
       "      <td>92882.000000</td>\n",
       "      <td>92882.000000</td>\n",
       "      <td>92882.000000</td>\n",
       "      <td>92882.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.193062</td>\n",
       "      <td>-96.371267</td>\n",
       "      <td>52.399195</td>\n",
       "      <td>132.752546</td>\n",
       "      <td>197.035227</td>\n",
       "      <td>84.540535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.908181</td>\n",
       "      <td>14.832005</td>\n",
       "      <td>15.515253</td>\n",
       "      <td>34.936826</td>\n",
       "      <td>52.542108</td>\n",
       "      <td>22.508499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>-177.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>-101.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude        BRONZE          GOLD      PLATINUM  \\\n",
       "count  92882.000000  92882.000000  92882.000000  92882.000000  92882.000000   \n",
       "mean      37.193062    -96.371267     52.399195    132.752546    197.035227   \n",
       "std        5.908181     14.832005     15.515253     34.936826     52.542108   \n",
       "min        7.000000   -177.000000     22.000000     72.000000    112.000000   \n",
       "25%       33.000000   -101.000000     41.000000    112.000000    170.000000   \n",
       "50%       37.000000    -94.000000     51.000000    127.000000    190.000000   \n",
       "75%       41.000000    -88.000000     62.000000    142.000000    209.000000   \n",
       "max       71.000000    171.000000    126.000000    276.000000    396.000000   \n",
       "\n",
       "             SILVER  \n",
       "count  92882.000000  \n",
       "mean      84.540535  \n",
       "std       22.508499  \n",
       "min       42.000000  \n",
       "25%       71.000000  \n",
       "50%       81.000000  \n",
       "75%       95.000000  \n",
       "max      186.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_bd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>collection_id_x</th>\n",
       "      <th>email</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>state</th>\n",
       "      <th>BRONZE</th>\n",
       "      <th>GOLD</th>\n",
       "      <th>PLATINUM</th>\n",
       "      <th>PURCHASED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>collection_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-08T22:11:38Z</td>\n",
       "      <td>6200 E CANYON RIM RD #110D</td>\n",
       "      <td>King Cove</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321</td>\n",
       "      <td>55</td>\n",
       "      <td>-162</td>\n",
       "      <td>SUGITA,LLOYD R</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>Silver</td>\n",
       "      <td>47</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994-01-08T22:11:38Z</td>\n",
       "      <td>1526 LINCOLN ST</td>\n",
       "      <td>Nikolski</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1326</td>\n",
       "      <td>53</td>\n",
       "      <td>-169</td>\n",
       "      <td>DAMACION,TAL</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>27</td>\n",
       "      <td>82</td>\n",
       "      <td>126</td>\n",
       "      <td>Silver</td>\n",
       "      <td>49</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-08T22:11:38Z</td>\n",
       "      <td>3624 RONK WY</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1340</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>HANEEF,KASIE R</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>112</td>\n",
       "      <td>Gold</td>\n",
       "      <td>42</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-06-08T22:11:38Z</td>\n",
       "      <td>3440 MARGARET D</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1343</td>\n",
       "      <td>61</td>\n",
       "      <td>-150</td>\n",
       "      <td>LEICHLITER,ZIA</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>112</td>\n",
       "      <td>Silver</td>\n",
       "      <td>42</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-06-08T22:11:38Z</td>\n",
       "      <td>100 FOWLER AVE #158</td>\n",
       "      <td>Kongiganak</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1361</td>\n",
       "      <td>60</td>\n",
       "      <td>-163</td>\n",
       "      <td>BUSENHART,LONIEL M</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "      <td>122</td>\n",
       "      <td>Gold</td>\n",
       "      <td>52</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996-09-08T22:11:38Z</td>\n",
       "      <td>240 EDITH AVE #134</td>\n",
       "      <td>Kwigillingok</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374</td>\n",
       "      <td>60</td>\n",
       "      <td>-163</td>\n",
       "      <td>JABOBS,ANNYSIA</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>34</td>\n",
       "      <td>89</td>\n",
       "      <td>133</td>\n",
       "      <td>Silver</td>\n",
       "      <td>56</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996-06-08T22:11:38Z</td>\n",
       "      <td>2824 VIA DEL CABBALLO</td>\n",
       "      <td>Tuntutuliak</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1385</td>\n",
       "      <td>60</td>\n",
       "      <td>-163</td>\n",
       "      <td>ELISARRARAZ,DORALY DORIS</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>131</td>\n",
       "      <td>Silver</td>\n",
       "      <td>54</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998-01-08T22:11:38Z</td>\n",
       "      <td>903 E DEVONSHIRE AVE #F</td>\n",
       "      <td>Clear</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1391</td>\n",
       "      <td>64</td>\n",
       "      <td>-149</td>\n",
       "      <td>WHITE, STEVEN,CHU YING K</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>Silver</td>\n",
       "      <td>50</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1995-12-08T22:11:38Z</td>\n",
       "      <td>521 CHINOOK LANE</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1394</td>\n",
       "      <td>64</td>\n",
       "      <td>-149</td>\n",
       "      <td>MENSINGER,SHARANDA A</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>34</td>\n",
       "      <td>89</td>\n",
       "      <td>133</td>\n",
       "      <td>Silver</td>\n",
       "      <td>56</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1996-09-08T22:11:38Z</td>\n",
       "      <td>2311 IVY HILL WAY APT 412</td>\n",
       "      <td>Aleknagik</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1396</td>\n",
       "      <td>59</td>\n",
       "      <td>-159</td>\n",
       "      <td>PINTENS,NEAL  K</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>Silver</td>\n",
       "      <td>46</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994-01-08T22:11:38Z</td>\n",
       "      <td>4151 MIDDLEFIELD #111</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>STEPHENABDMARIE@YAHOO.COM</td>\n",
       "      <td>1412</td>\n",
       "      <td>65</td>\n",
       "      <td>-148</td>\n",
       "      <td>RAAB,SHANORIA</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>Gold</td>\n",
       "      <td>46</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997-12-08T22:11:38Z</td>\n",
       "      <td>1 MERCADO STREET, SUITE 202</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>marcelleplymer@att.net</td>\n",
       "      <td>1427</td>\n",
       "      <td>58</td>\n",
       "      <td>-134</td>\n",
       "      <td>POTEETE,DYANNE</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "      <td>122</td>\n",
       "      <td>Silver</td>\n",
       "      <td>52</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1994-03-08T22:11:38Z</td>\n",
       "      <td>2630 ORCHARD ST SPACE 31</td>\n",
       "      <td>Hooper Bay</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1458</td>\n",
       "      <td>62</td>\n",
       "      <td>-166</td>\n",
       "      <td>BEARCE,DARRIELLE A</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>131</td>\n",
       "      <td>Silver</td>\n",
       "      <td>54</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1997-02-08T22:11:38Z</td>\n",
       "      <td>880 CASS ST #108</td>\n",
       "      <td>Skwentna</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483</td>\n",
       "      <td>62</td>\n",
       "      <td>-151</td>\n",
       "      <td>RENFROW,POHAI C</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>52</td>\n",
       "      <td>102</td>\n",
       "      <td>142</td>\n",
       "      <td>Silver</td>\n",
       "      <td>72</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1993-04-08T22:11:38Z</td>\n",
       "      <td>P O BOX 3279</td>\n",
       "      <td>Houston</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1489</td>\n",
       "      <td>62</td>\n",
       "      <td>-150</td>\n",
       "      <td>PATSEL,ANA (SANDY) L</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>131</td>\n",
       "      <td>Silver</td>\n",
       "      <td>54</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1996-01-08T22:11:38Z</td>\n",
       "      <td>172 HOME WOOD AVE</td>\n",
       "      <td>Unalakleet</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492</td>\n",
       "      <td>64</td>\n",
       "      <td>-161</td>\n",
       "      <td>CALLAS,TEDDREKA R</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "      <td>128</td>\n",
       "      <td>Gold</td>\n",
       "      <td>51</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1993-06-08T22:11:38Z</td>\n",
       "      <td>1509 FOXHOLLOW LN</td>\n",
       "      <td>Koyuk</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>ALFORD_DANIEL@HOTMAIL.COM</td>\n",
       "      <td>1495</td>\n",
       "      <td>65</td>\n",
       "      <td>-161</td>\n",
       "      <td>TIEMAN,ISALA</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>34</td>\n",
       "      <td>89</td>\n",
       "      <td>133</td>\n",
       "      <td>Silver</td>\n",
       "      <td>56</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1994-01-08T22:11:38Z</td>\n",
       "      <td>3265 CIRCLE CT WEST</td>\n",
       "      <td>Noatak</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1519</td>\n",
       "      <td>68</td>\n",
       "      <td>-163</td>\n",
       "      <td>HOLNESS,ANGELLISA L</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "      <td>128</td>\n",
       "      <td>Silver</td>\n",
       "      <td>51</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1994-05-08T22:11:38Z</td>\n",
       "      <td>P.O. BOX 292068</td>\n",
       "      <td>Gustavus</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1537</td>\n",
       "      <td>58</td>\n",
       "      <td>-136</td>\n",
       "      <td>SHIMANE,MARGAUX A</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>39</td>\n",
       "      <td>94</td>\n",
       "      <td>138</td>\n",
       "      <td>Gold</td>\n",
       "      <td>61</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1996-12-08T22:11:38Z</td>\n",
       "      <td>3773 CHERRY CRK N. #735</td>\n",
       "      <td>Pelican</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1539</td>\n",
       "      <td>58</td>\n",
       "      <td>-136</td>\n",
       "      <td>KONTAXAKIS,NATISHA L</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>37</td>\n",
       "      <td>87</td>\n",
       "      <td>127</td>\n",
       "      <td>Silver</td>\n",
       "      <td>57</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1999-08-08T22:11:38Z</td>\n",
       "      <td>22144 CLARENDON ST #300</td>\n",
       "      <td>Chitina</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1549</td>\n",
       "      <td>61</td>\n",
       "      <td>-145</td>\n",
       "      <td>SHABAZZ-TERRY,MAHYAR O</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "      <td>122</td>\n",
       "      <td>Silver</td>\n",
       "      <td>52</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1997-12-08T22:11:38Z</td>\n",
       "      <td>1306 C STREET #1</td>\n",
       "      <td>Copper Center</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>LGRONINGER@COMCAST.NET</td>\n",
       "      <td>1550</td>\n",
       "      <td>62</td>\n",
       "      <td>-145</td>\n",
       "      <td>RATZAK,MANDEEP C</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>112</td>\n",
       "      <td>Silver</td>\n",
       "      <td>42</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1993-02-08T22:11:38Z</td>\n",
       "      <td>1860 HAYES STREET</td>\n",
       "      <td>Gakona</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>LGRONINGER@COMCAST.NET</td>\n",
       "      <td>1552</td>\n",
       "      <td>63</td>\n",
       "      <td>-144</td>\n",
       "      <td>RORSCHACH,NIKY J</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>47</td>\n",
       "      <td>102</td>\n",
       "      <td>146</td>\n",
       "      <td>Silver</td>\n",
       "      <td>69</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1999-06-08T22:11:38Z</td>\n",
       "      <td>5465 SANTA MONICA BLVD #106</td>\n",
       "      <td>Glennallen</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553</td>\n",
       "      <td>62</td>\n",
       "      <td>-146</td>\n",
       "      <td>BUNYEA,KACI S</td>\n",
       "      <td>F</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>115</td>\n",
       "      <td>Gold</td>\n",
       "      <td>45</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1997-12-08T22:11:38Z</td>\n",
       "      <td>687 GRIZZLY PEAK BLVD,AVE #8</td>\n",
       "      <td>Tatitlek</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554</td>\n",
       "      <td>61</td>\n",
       "      <td>-147</td>\n",
       "      <td>WICKS JR,SHANAL W</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>Gold</td>\n",
       "      <td>47</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1999-09-08T22:11:38Z</td>\n",
       "      <td>1231 ROSE AVE</td>\n",
       "      <td>Kaltag</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1578</td>\n",
       "      <td>64</td>\n",
       "      <td>-159</td>\n",
       "      <td>WEHRLE,IMUA D</td>\n",
       "      <td>M</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>112</td>\n",
       "      <td>Silver</td>\n",
       "      <td>42</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1996-02-08T22:11:38Z</td>\n",
       "      <td>1630 S COMMERCE ST #A1</td>\n",
       "      <td>Springerville</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1598</td>\n",
       "      <td>34</td>\n",
       "      <td>-109</td>\n",
       "      <td>DRIGGS,IRINA</td>\n",
       "      <td>M</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>32</td>\n",
       "      <td>87</td>\n",
       "      <td>131</td>\n",
       "      <td>Silver</td>\n",
       "      <td>54</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1996-11-08T22:11:38Z</td>\n",
       "      <td>1674 DORCHESTER</td>\n",
       "      <td>Chambers</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>35</td>\n",
       "      <td>-110</td>\n",
       "      <td>HAKE,ANDRAE J</td>\n",
       "      <td>F</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>34</td>\n",
       "      <td>89</td>\n",
       "      <td>133</td>\n",
       "      <td>Gold</td>\n",
       "      <td>56</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1995-06-08T22:11:38Z</td>\n",
       "      <td>552 E GLENN #33</td>\n",
       "      <td>Ganado</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1604</td>\n",
       "      <td>36</td>\n",
       "      <td>-110</td>\n",
       "      <td>MASER JR,KYLIA M</td>\n",
       "      <td>M</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>Gold</td>\n",
       "      <td>46</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1998-11-08T22:11:38Z</td>\n",
       "      <td>2220 SO. BASCOM AVE.</td>\n",
       "      <td>Lupton</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1607</td>\n",
       "      <td>35</td>\n",
       "      <td>-109</td>\n",
       "      <td>JOHNSON, JOHAN,TORIE L</td>\n",
       "      <td>F</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>112</td>\n",
       "      <td>Silver</td>\n",
       "      <td>42</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92852</th>\n",
       "      <td>1980-02-08T22:11:38Z</td>\n",
       "      <td>4737 PARKER ST</td>\n",
       "      <td>Deerfield</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397349</td>\n",
       "      <td>38</td>\n",
       "      <td>-95</td>\n",
       "      <td>HOSOBUCHI,CHARMENACA L</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>84</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92853</th>\n",
       "      <td>1978-03-08T22:11:38Z</td>\n",
       "      <td>6619 SHATTUCK A</td>\n",
       "      <td>Metz</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397351</td>\n",
       "      <td>38</td>\n",
       "      <td>-94</td>\n",
       "      <td>WYDEVEN,CHELLSEA A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>43</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>Gold</td>\n",
       "      <td>77</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92854</th>\n",
       "      <td>1981-08-08T22:11:38Z</td>\n",
       "      <td>7536 ELIZABETH</td>\n",
       "      <td>Moundville</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397353</td>\n",
       "      <td>38</td>\n",
       "      <td>-94</td>\n",
       "      <td>BOCKMAN,KAIRO</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>61</td>\n",
       "      <td>146</td>\n",
       "      <td>214</td>\n",
       "      <td>Silver</td>\n",
       "      <td>95</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92855</th>\n",
       "      <td>1986-06-08T22:11:38Z</td>\n",
       "      <td>137 LORTON AVE APT 6</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397354</td>\n",
       "      <td>38</td>\n",
       "      <td>-94</td>\n",
       "      <td>QUESENBERRY,JEWELEAN</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>66</td>\n",
       "      <td>141</td>\n",
       "      <td>201</td>\n",
       "      <td>Silver</td>\n",
       "      <td>96</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92856</th>\n",
       "      <td>1987-05-08T22:11:38Z</td>\n",
       "      <td>1200 LAKESHORE AVENUE, SUITE 18C</td>\n",
       "      <td>Richards</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397355</td>\n",
       "      <td>38</td>\n",
       "      <td>-95</td>\n",
       "      <td>RAMBUR,TIARRA A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>56</td>\n",
       "      <td>121</td>\n",
       "      <td>173</td>\n",
       "      <td>Gold</td>\n",
       "      <td>82</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92857</th>\n",
       "      <td>1984-10-08T22:11:38Z</td>\n",
       "      <td>221 HAYES CIRCLE</td>\n",
       "      <td>Schell City</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397356</td>\n",
       "      <td>38</td>\n",
       "      <td>-94</td>\n",
       "      <td>JACQUILLARD,CALUNDRA S</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>82</td>\n",
       "      <td>157</td>\n",
       "      <td>217</td>\n",
       "      <td>Silver</td>\n",
       "      <td>112</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92858</th>\n",
       "      <td>1984-09-08T22:11:38Z</td>\n",
       "      <td>1600 NW 6TH STREET</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397357</td>\n",
       "      <td>38</td>\n",
       "      <td>-94</td>\n",
       "      <td>CARTERS,DYAN W</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "      <td>197</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>92</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92859</th>\n",
       "      <td>1978-08-08T22:11:38Z</td>\n",
       "      <td>230 E.DUNNE AVE. APT#414</td>\n",
       "      <td>Marthasville</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397360</td>\n",
       "      <td>39</td>\n",
       "      <td>-91</td>\n",
       "      <td>SECRETO,PEIGHTEN</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>193</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>74</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92860</th>\n",
       "      <td>1987-03-08T22:11:38Z</td>\n",
       "      <td>5200 CASCADE ROAD SE</td>\n",
       "      <td>Truesdale</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397362</td>\n",
       "      <td>39</td>\n",
       "      <td>-91</td>\n",
       "      <td>KIRSTEINS,MAYTE M</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>32</td>\n",
       "      <td>97</td>\n",
       "      <td>149</td>\n",
       "      <td>Silver</td>\n",
       "      <td>58</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92861</th>\n",
       "      <td>1982-10-08T22:11:38Z</td>\n",
       "      <td>552 SILVA AVENUE</td>\n",
       "      <td>Warrenton</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397363</td>\n",
       "      <td>39</td>\n",
       "      <td>-91</td>\n",
       "      <td>STANFILL,MOLLEIGH A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>51</td>\n",
       "      <td>126</td>\n",
       "      <td>186</td>\n",
       "      <td>Silver</td>\n",
       "      <td>81</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92862</th>\n",
       "      <td>1979-12-08T22:11:38Z</td>\n",
       "      <td>P O BOX 8761</td>\n",
       "      <td>Caledonia</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397368</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>ZIRSCHKY,SAMANTHA RAE C</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "      <td>213</td>\n",
       "      <td>Gold</td>\n",
       "      <td>94</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92863</th>\n",
       "      <td>1980-05-08T22:11:38Z</td>\n",
       "      <td>2001 PINER ROAD, APT 102</td>\n",
       "      <td>Irondale</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397369</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>ROSDAIL,LEALO FITAUTE M</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>70</td>\n",
       "      <td>155</td>\n",
       "      <td>223</td>\n",
       "      <td>Silver</td>\n",
       "      <td>104</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92864</th>\n",
       "      <td>1986-06-08T22:11:38Z</td>\n",
       "      <td>7977 PARK DRIVE</td>\n",
       "      <td>Tiff</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397372</td>\n",
       "      <td>38</td>\n",
       "      <td>-91</td>\n",
       "      <td>VILLARICO,CASSANDA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>51</td>\n",
       "      <td>126</td>\n",
       "      <td>186</td>\n",
       "      <td>Silver</td>\n",
       "      <td>81</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92865</th>\n",
       "      <td>1983-01-08T22:11:38Z</td>\n",
       "      <td>33955 JULIET CIR.</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397373</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>ALBAR-JEN,KATSUKO</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>59</td>\n",
       "      <td>134</td>\n",
       "      <td>194</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>89</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92866</th>\n",
       "      <td>1985-09-08T22:11:38Z</td>\n",
       "      <td>1143 NW 64TH TERR, DIV 1</td>\n",
       "      <td>Lowndes</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397378</td>\n",
       "      <td>37</td>\n",
       "      <td>-90</td>\n",
       "      <td>SPICUGLIA,LESLEY ANNE M</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "      <td>197</td>\n",
       "      <td>Gold</td>\n",
       "      <td>92</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92867</th>\n",
       "      <td>1986-05-08T22:11:38Z</td>\n",
       "      <td>745 DAVIS ST #B</td>\n",
       "      <td>Diggins</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397385</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>ESPLANA,AUSHLEY C</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>67</td>\n",
       "      <td>142</td>\n",
       "      <td>202</td>\n",
       "      <td>Gold</td>\n",
       "      <td>97</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92868</th>\n",
       "      <td>1979-08-08T22:11:38Z</td>\n",
       "      <td>901 CAMPUS DR STE 112</td>\n",
       "      <td>Elkland</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397386</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>HULEN,SHANEA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>84</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92869</th>\n",
       "      <td>1985-05-08T22:11:38Z</td>\n",
       "      <td>1108 WEST TOKAY STREET</td>\n",
       "      <td>Fordland</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397387</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>TELLES JR,M.MICHELE I</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>56</td>\n",
       "      <td>131</td>\n",
       "      <td>191</td>\n",
       "      <td>Gold</td>\n",
       "      <td>86</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92870</th>\n",
       "      <td>1979-06-08T22:11:38Z</td>\n",
       "      <td>780 GUERRERE ST #10</td>\n",
       "      <td>Marshfield</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397388</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>PRESNAR JR,HUIZHEN J</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>66</td>\n",
       "      <td>151</td>\n",
       "      <td>219</td>\n",
       "      <td>Silver</td>\n",
       "      <td>100</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92871</th>\n",
       "      <td>1981-05-08T22:11:38Z</td>\n",
       "      <td>2836 MERLE AVEN</td>\n",
       "      <td>Niangua</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397389</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>WILLNER,LUZ-PILAR</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>55</td>\n",
       "      <td>140</td>\n",
       "      <td>208</td>\n",
       "      <td>Gold</td>\n",
       "      <td>89</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92872</th>\n",
       "      <td>1982-01-08T22:11:38Z</td>\n",
       "      <td>9118 N WEST LANE</td>\n",
       "      <td>Denver</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397393</td>\n",
       "      <td>40</td>\n",
       "      <td>-94</td>\n",
       "      <td>BAMBRICK,LA LONNIE A</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>62</td>\n",
       "      <td>137</td>\n",
       "      <td>197</td>\n",
       "      <td>Gold</td>\n",
       "      <td>92</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92873</th>\n",
       "      <td>1981-03-08T22:11:38Z</td>\n",
       "      <td>111 VIA TERESA</td>\n",
       "      <td>Grant City</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397394</td>\n",
       "      <td>40</td>\n",
       "      <td>-94</td>\n",
       "      <td>MANSOUR,MILA VILLA</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>48</td>\n",
       "      <td>133</td>\n",
       "      <td>201</td>\n",
       "      <td>Gold</td>\n",
       "      <td>82</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92874</th>\n",
       "      <td>1987-04-08T22:11:38Z</td>\n",
       "      <td>6929 BISMARCK DRIVE</td>\n",
       "      <td>Sheridan</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397395</td>\n",
       "      <td>40</td>\n",
       "      <td>-95</td>\n",
       "      <td>HATHCOCK,YESINA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>32</td>\n",
       "      <td>97</td>\n",
       "      <td>149</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>58</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92875</th>\n",
       "      <td>1979-05-08T22:11:38Z</td>\n",
       "      <td>6394 E SANTA ANA CYN RD</td>\n",
       "      <td>Graff</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397397</td>\n",
       "      <td>37</td>\n",
       "      <td>-92</td>\n",
       "      <td>WURTS,JANADA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>43</td>\n",
       "      <td>128</td>\n",
       "      <td>196</td>\n",
       "      <td>Silver</td>\n",
       "      <td>77</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92876</th>\n",
       "      <td>1985-11-08T22:11:38Z</td>\n",
       "      <td>237 VEGA ROAD</td>\n",
       "      <td>Hartville</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397399</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>FARRAY,SANCHITA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>52</td>\n",
       "      <td>127</td>\n",
       "      <td>187</td>\n",
       "      <td>Silver</td>\n",
       "      <td>82</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92877</th>\n",
       "      <td>1978-09-08T22:11:38Z</td>\n",
       "      <td>77 BAYLOR LANE</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397401</td>\n",
       "      <td>37</td>\n",
       "      <td>-93</td>\n",
       "      <td>ROJAS MIRANDA,MAYKAYLA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>Gold</td>\n",
       "      <td>84</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92878</th>\n",
       "      <td>1979-07-08T22:11:38Z</td>\n",
       "      <td>641 NELLO DR #2</td>\n",
       "      <td>Norwood</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397403</td>\n",
       "      <td>37</td>\n",
       "      <td>-92</td>\n",
       "      <td>MALFA,CLELID L</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>56</td>\n",
       "      <td>141</td>\n",
       "      <td>209</td>\n",
       "      <td>Silver</td>\n",
       "      <td>90</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92879</th>\n",
       "      <td>1983-01-08T22:11:38Z</td>\n",
       "      <td>4303 N EMERSON ST</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397405</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>FISHER-GILL,SILVERIA</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36</td>\n",
       "      <td>111</td>\n",
       "      <td>171</td>\n",
       "      <td>Silver</td>\n",
       "      <td>66</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92880</th>\n",
       "      <td>1983-02-08T22:11:38Z</td>\n",
       "      <td>218 PENNSYLVANIA AVE</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397406</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>TANNE,CHAIZ</td>\n",
       "      <td>M</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>67</td>\n",
       "      <td>142</td>\n",
       "      <td>202</td>\n",
       "      <td>Silver</td>\n",
       "      <td>97</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92881</th>\n",
       "      <td>1986-01-08T22:11:38Z</td>\n",
       "      <td>1260 ROMO DRIVE</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>V_Participant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397411</td>\n",
       "      <td>39</td>\n",
       "      <td>-90</td>\n",
       "      <td>DRING,JODEEN</td>\n",
       "      <td>F</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>72</td>\n",
       "      <td>147</td>\n",
       "      <td>207</td>\n",
       "      <td>Silver</td>\n",
       "      <td>102</td>\n",
       "      <td>v_quotes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92882 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DOB                           address           city  \\\n",
       "0      1999-11-08T22:11:38Z        6200 E CANYON RIM RD #110D      King Cove   \n",
       "1      1994-01-08T22:11:38Z                   1526 LINCOLN ST       Nikolski   \n",
       "2      1997-11-08T22:11:38Z                      3624 RONK WY      Anchorage   \n",
       "3      1997-06-08T22:11:38Z                   3440 MARGARET D      Anchorage   \n",
       "4      1997-06-08T22:11:38Z               100 FOWLER AVE #158     Kongiganak   \n",
       "5      1996-09-08T22:11:38Z                240 EDITH AVE #134   Kwigillingok   \n",
       "6      1996-06-08T22:11:38Z             2824 VIA DEL CABBALLO    Tuntutuliak   \n",
       "7      1998-01-08T22:11:38Z           903 E DEVONSHIRE AVE #F          Clear   \n",
       "8      1995-12-08T22:11:38Z                  521 CHINOOK LANE       Anderson   \n",
       "9      1996-09-08T22:11:38Z         2311 IVY HILL WAY APT 412      Aleknagik   \n",
       "10     1994-01-08T22:11:38Z             4151 MIDDLEFIELD #111      Fairbanks   \n",
       "11     1997-12-08T22:11:38Z       1 MERCADO STREET, SUITE 202         Juneau   \n",
       "12     1994-03-08T22:11:38Z          2630 ORCHARD ST SPACE 31     Hooper Bay   \n",
       "13     1997-02-08T22:11:38Z                  880 CASS ST #108       Skwentna   \n",
       "14     1993-04-08T22:11:38Z                      P O BOX 3279        Houston   \n",
       "15     1996-01-08T22:11:38Z                 172 HOME WOOD AVE     Unalakleet   \n",
       "16     1993-06-08T22:11:38Z                 1509 FOXHOLLOW LN          Koyuk   \n",
       "17     1994-01-08T22:11:38Z               3265 CIRCLE CT WEST         Noatak   \n",
       "18     1994-05-08T22:11:38Z                   P.O. BOX 292068       Gustavus   \n",
       "19     1996-12-08T22:11:38Z           3773 CHERRY CRK N. #735        Pelican   \n",
       "20     1999-08-08T22:11:38Z           22144 CLARENDON ST #300        Chitina   \n",
       "21     1997-12-08T22:11:38Z                  1306 C STREET #1  Copper Center   \n",
       "22     1993-02-08T22:11:38Z                 1860 HAYES STREET         Gakona   \n",
       "23     1999-06-08T22:11:38Z       5465 SANTA MONICA BLVD #106     Glennallen   \n",
       "24     1997-12-08T22:11:38Z      687 GRIZZLY PEAK BLVD,AVE #8       Tatitlek   \n",
       "25     1999-09-08T22:11:38Z                    1231 ROSE AVE          Kaltag   \n",
       "26     1996-02-08T22:11:38Z            1630 S COMMERCE ST #A1  Springerville   \n",
       "27     1996-11-08T22:11:38Z                   1674 DORCHESTER       Chambers   \n",
       "28     1995-06-08T22:11:38Z                   552 E GLENN #33         Ganado   \n",
       "29     1998-11-08T22:11:38Z              2220 SO. BASCOM AVE.         Lupton   \n",
       "...                     ...                               ...            ...   \n",
       "92852  1980-02-08T22:11:38Z                    4737 PARKER ST      Deerfield   \n",
       "92853  1978-03-08T22:11:38Z                   6619 SHATTUCK A           Metz   \n",
       "92854  1981-08-08T22:11:38Z                    7536 ELIZABETH     Moundville   \n",
       "92855  1986-06-08T22:11:38Z              137 LORTON AVE APT 6         Nevada   \n",
       "92856  1987-05-08T22:11:38Z  1200 LAKESHORE AVENUE, SUITE 18C       Richards   \n",
       "92857  1984-10-08T22:11:38Z                  221 HAYES CIRCLE    Schell City   \n",
       "92858  1984-09-08T22:11:38Z                1600 NW 6TH STREET        Sheldon   \n",
       "92859  1978-08-08T22:11:38Z          230 E.DUNNE AVE. APT#414   Marthasville   \n",
       "92860  1987-03-08T22:11:38Z              5200 CASCADE ROAD SE      Truesdale   \n",
       "92861  1982-10-08T22:11:38Z                  552 SILVA AVENUE      Warrenton   \n",
       "92862  1979-12-08T22:11:38Z                      P O BOX 8761      Caledonia   \n",
       "92863  1980-05-08T22:11:38Z          2001 PINER ROAD, APT 102       Irondale   \n",
       "92864  1986-06-08T22:11:38Z                   7977 PARK DRIVE           Tiff   \n",
       "92865  1983-01-08T22:11:38Z                 33955 JULIET CIR.        Cascade   \n",
       "92866  1985-09-08T22:11:38Z          1143 NW 64TH TERR, DIV 1        Lowndes   \n",
       "92867  1986-05-08T22:11:38Z                   745 DAVIS ST #B        Diggins   \n",
       "92868  1979-08-08T22:11:38Z             901 CAMPUS DR STE 112        Elkland   \n",
       "92869  1985-05-08T22:11:38Z            1108 WEST TOKAY STREET       Fordland   \n",
       "92870  1979-06-08T22:11:38Z               780 GUERRERE ST #10     Marshfield   \n",
       "92871  1981-05-08T22:11:38Z                   2836 MERLE AVEN        Niangua   \n",
       "92872  1982-01-08T22:11:38Z                  9118 N WEST LANE         Denver   \n",
       "92873  1981-03-08T22:11:38Z                    111 VIA TERESA     Grant City   \n",
       "92874  1987-04-08T22:11:38Z               6929 BISMARCK DRIVE       Sheridan   \n",
       "92875  1979-05-08T22:11:38Z           6394 E SANTA ANA CYN RD          Graff   \n",
       "92876  1985-11-08T22:11:38Z                     237 VEGA ROAD      Hartville   \n",
       "92877  1978-09-08T22:11:38Z                    77 BAYLOR LANE      Mansfield   \n",
       "92878  1979-07-08T22:11:38Z                   641 NELLO DR #2        Norwood   \n",
       "92879  1983-01-08T22:11:38Z                 4303 N EMERSON ST    Saint Louis   \n",
       "92880  1983-02-08T22:11:38Z              218 PENNSYLVANIA AVE    Saint Louis   \n",
       "92881  1986-01-08T22:11:38Z                   1260 ROMO DRIVE    Saint Louis   \n",
       "\n",
       "      collection_id_x                      email      id  latitude  longitude  \\\n",
       "0       V_Participant                        NaN    1321        55       -162   \n",
       "1       V_Participant                        NaN    1326        53       -169   \n",
       "2       V_Participant                        NaN    1340        61       -150   \n",
       "3       V_Participant                        NaN    1343        61       -150   \n",
       "4       V_Participant                        NaN    1361        60       -163   \n",
       "5       V_Participant                        NaN    1374        60       -163   \n",
       "6       V_Participant                        NaN    1385        60       -163   \n",
       "7       V_Participant                        NaN    1391        64       -149   \n",
       "8       V_Participant                        NaN    1394        64       -149   \n",
       "9       V_Participant                        NaN    1396        59       -159   \n",
       "10      V_Participant  STEPHENABDMARIE@YAHOO.COM    1412        65       -148   \n",
       "11      V_Participant     marcelleplymer@att.net    1427        58       -134   \n",
       "12      V_Participant                        NaN    1458        62       -166   \n",
       "13      V_Participant                        NaN    1483        62       -151   \n",
       "14      V_Participant                        NaN    1489        62       -150   \n",
       "15      V_Participant                        NaN    1492        64       -161   \n",
       "16      V_Participant  ALFORD_DANIEL@HOTMAIL.COM    1495        65       -161   \n",
       "17      V_Participant                        NaN    1519        68       -163   \n",
       "18      V_Participant                        NaN    1537        58       -136   \n",
       "19      V_Participant                        NaN    1539        58       -136   \n",
       "20      V_Participant                        NaN    1549        61       -145   \n",
       "21      V_Participant     LGRONINGER@COMCAST.NET    1550        62       -145   \n",
       "22      V_Participant     LGRONINGER@COMCAST.NET    1552        63       -144   \n",
       "23      V_Participant                        NaN    1553        62       -146   \n",
       "24      V_Participant                        NaN    1554        61       -147   \n",
       "25      V_Participant                        NaN    1578        64       -159   \n",
       "26      V_Participant                        NaN    1598        34       -109   \n",
       "27      V_Participant                        NaN    1601        35       -110   \n",
       "28      V_Participant                        NaN    1604        36       -110   \n",
       "29      V_Participant                        NaN    1607        35       -109   \n",
       "...               ...                        ...     ...       ...        ...   \n",
       "92852   V_Participant                        NaN  397349        38        -95   \n",
       "92853   V_Participant                        NaN  397351        38        -94   \n",
       "92854   V_Participant                        NaN  397353        38        -94   \n",
       "92855   V_Participant                        NaN  397354        38        -94   \n",
       "92856   V_Participant                        NaN  397355        38        -95   \n",
       "92857   V_Participant                        NaN  397356        38        -94   \n",
       "92858   V_Participant                        NaN  397357        38        -94   \n",
       "92859   V_Participant                        NaN  397360        39        -91   \n",
       "92860   V_Participant                        NaN  397362        39        -91   \n",
       "92861   V_Participant                        NaN  397363        39        -91   \n",
       "92862   V_Participant                        NaN  397368        38        -91   \n",
       "92863   V_Participant                        NaN  397369        38        -91   \n",
       "92864   V_Participant                        NaN  397372        38        -91   \n",
       "92865   V_Participant                        NaN  397373        37        -90   \n",
       "92866   V_Participant                        NaN  397378        37        -90   \n",
       "92867   V_Participant                        NaN  397385        37        -93   \n",
       "92868   V_Participant                        NaN  397386        37        -93   \n",
       "92869   V_Participant                        NaN  397387        37        -93   \n",
       "92870   V_Participant                        NaN  397388        37        -93   \n",
       "92871   V_Participant                        NaN  397389        37        -93   \n",
       "92872   V_Participant                        NaN  397393        40        -94   \n",
       "92873   V_Participant                        NaN  397394        40        -94   \n",
       "92874   V_Participant                        NaN  397395        40        -95   \n",
       "92875   V_Participant                        NaN  397397        37        -92   \n",
       "92876   V_Participant                        NaN  397399        37        -93   \n",
       "92877   V_Participant                        NaN  397401        37        -93   \n",
       "92878   V_Participant                        NaN  397403        37        -92   \n",
       "92879   V_Participant                        NaN  397405        39        -90   \n",
       "92880   V_Participant                        NaN  397406        39        -90   \n",
       "92881   V_Participant                        NaN  397411        39        -90   \n",
       "\n",
       "                           name sex     state  BRONZE  GOLD  PLATINUM  \\\n",
       "0                SUGITA,LLOYD R   F    Alaska      27    77       117   \n",
       "1                 DAMACION,TAL    M    Alaska      27    82       126   \n",
       "2                HANEEF,KASIE R   M    Alaska      22    72       112   \n",
       "3               LEICHLITER,ZIA    F    Alaska      22    72       112   \n",
       "4            BUSENHART,LONIEL M   F    Alaska      32    82       122   \n",
       "5               JABOBS,ANNYSIA    M    Alaska      34    89       133   \n",
       "6      ELISARRARAZ,DORALY DORIS   F    Alaska      32    87       131   \n",
       "7      WHITE, STEVEN,CHU YING K   F    Alaska      30    80       120   \n",
       "8          MENSINGER,SHARANDA A   M    Alaska      34    89       133   \n",
       "9               PINTENS,NEAL  K   M    Alaska      24    79       123   \n",
       "10               RAAB,SHANORIA    M    Alaska      24    79       123   \n",
       "11              POTEETE,DYANNE    F    Alaska      32    82       122   \n",
       "12           BEARCE,DARRIELLE A   M    Alaska      32    87       131   \n",
       "13              RENFROW,POHAI C   F    Alaska      52   102       142   \n",
       "14         PATSEL,ANA (SANDY) L   F    Alaska      32    87       131   \n",
       "15            CALLAS,TEDDREKA R   M    Alaska      29    84       128   \n",
       "16                TIEMAN,ISALA    F    Alaska      34    89       133   \n",
       "17          HOLNESS,ANGELLISA L   F    Alaska      29    84       128   \n",
       "18            SHIMANE,MARGAUX A   F    Alaska      39    94       138   \n",
       "19         KONTAXAKIS,NATISHA L   F    Alaska      37    87       127   \n",
       "20       SHABAZZ-TERRY,MAHYAR O   F    Alaska      32    82       122   \n",
       "21             RATZAK,MANDEEP C   M    Alaska      22    72       112   \n",
       "22             RORSCHACH,NIKY J   M    Alaska      47   102       146   \n",
       "23                BUNYEA,KACI S   F    Alaska      25    75       115   \n",
       "24            WICKS JR,SHANAL W   M    Alaska      27    77       117   \n",
       "25                WEHRLE,IMUA D   M    Alaska      22    72       112   \n",
       "26                DRIGGS,IRINA    M   Arizona      32    87       131   \n",
       "27                HAKE,ANDRAE J   F   Arizona      34    89       133   \n",
       "28             MASER JR,KYLIA M   M   Arizona      24    79       123   \n",
       "29       JOHNSON, JOHAN,TORIE L   F   Arizona      22    72       112   \n",
       "...                         ...  ..       ...     ...   ...       ...   \n",
       "92852    HOSOBUCHI,CHARMENACA L   F  Missouri      50   135       203   \n",
       "92853        WYDEVEN,CHELLSEA A   F  Missouri      43   128       196   \n",
       "92854            BOCKMAN,KAIRO    F  Missouri      61   146       214   \n",
       "92855     QUESENBERRY,JEWELEAN    M  Missouri      66   141       201   \n",
       "92856           RAMBUR,TIARRA A   F  Missouri      56   121       173   \n",
       "92857    JACQUILLARD,CALUNDRA S   M  Missouri      82   157       217   \n",
       "92858            CARTERS,DYAN W   F  Missouri      62   137       197   \n",
       "92859         SECRETO,PEIGHTEN    M  Missouri      40   125       193   \n",
       "92860         KIRSTEINS,MAYTE M   M  Missouri      32    97       149   \n",
       "92861       STANFILL,MOLLEIGH A   F  Missouri      51   126       186   \n",
       "92862   ZIRSCHKY,SAMANTHA RAE C   M  Missouri      60   145       213   \n",
       "92863   ROSDAIL,LEALO FITAUTE M   F  Missouri      70   155       223   \n",
       "92864       VILLARICO,CASSANDA    M  Missouri      51   126       186   \n",
       "92865        ALBAR-JEN,KATSUKO    F  Missouri      59   134       194   \n",
       "92866   SPICUGLIA,LESLEY ANNE M   M  Missouri      62   137       197   \n",
       "92867         ESPLANA,AUSHLEY C   F  Missouri      67   142       202   \n",
       "92868             HULEN,SHANEA    M  Missouri      50   135       203   \n",
       "92869     TELLES JR,M.MICHELE I   F  Missouri      56   131       191   \n",
       "92870      PRESNAR JR,HUIZHEN J   M  Missouri      66   151       219   \n",
       "92871        WILLNER,LUZ-PILAR    F  Missouri      55   140       208   \n",
       "92872      BAMBRICK,LA LONNIE A   F  Missouri      62   137       197   \n",
       "92873       MANSOUR,MILA VILLA    M  Missouri      48   133       201   \n",
       "92874          HATHCOCK,YESINA    F  Missouri      32    97       149   \n",
       "92875             WURTS,JANADA    F  Missouri      43   128       196   \n",
       "92876          FARRAY,SANCHITA    F  Missouri      52   127       187   \n",
       "92877   ROJAS MIRANDA,MAYKAYLA    F  Missouri      50   135       203   \n",
       "92878            MALFA,CLELID L   F  Missouri      56   141       209   \n",
       "92879     FISHER-GILL,SILVERIA    F  Missouri      36   111       171   \n",
       "92880              TANNE,CHAIZ    M  Missouri      67   142       202   \n",
       "92881             DRING,JODEEN    F  Missouri      72   147       207   \n",
       "\n",
       "      PURCHASED  SILVER collection_id_y  \n",
       "0        Silver      47        v_quotes  \n",
       "1        Silver      49        v_quotes  \n",
       "2          Gold      42        v_quotes  \n",
       "3        Silver      42        v_quotes  \n",
       "4          Gold      52        v_quotes  \n",
       "5        Silver      56        v_quotes  \n",
       "6        Silver      54        v_quotes  \n",
       "7        Silver      50        v_quotes  \n",
       "8        Silver      56        v_quotes  \n",
       "9        Silver      46        v_quotes  \n",
       "10         Gold      46        v_quotes  \n",
       "11       Silver      52        v_quotes  \n",
       "12       Silver      54        v_quotes  \n",
       "13       Silver      72        v_quotes  \n",
       "14       Silver      54        v_quotes  \n",
       "15         Gold      51        v_quotes  \n",
       "16       Silver      56        v_quotes  \n",
       "17       Silver      51        v_quotes  \n",
       "18         Gold      61        v_quotes  \n",
       "19       Silver      57        v_quotes  \n",
       "20       Silver      52        v_quotes  \n",
       "21       Silver      42        v_quotes  \n",
       "22       Silver      69        v_quotes  \n",
       "23         Gold      45        v_quotes  \n",
       "24         Gold      47        v_quotes  \n",
       "25       Silver      42        v_quotes  \n",
       "26       Silver      54        v_quotes  \n",
       "27         Gold      56        v_quotes  \n",
       "28         Gold      46        v_quotes  \n",
       "29       Silver      42        v_quotes  \n",
       "...         ...     ...             ...  \n",
       "92852    Bronze      84        v_quotes  \n",
       "92853      Gold      77        v_quotes  \n",
       "92854    Silver      95        v_quotes  \n",
       "92855    Silver      96        v_quotes  \n",
       "92856      Gold      82        v_quotes  \n",
       "92857    Silver     112        v_quotes  \n",
       "92858    Bronze      92        v_quotes  \n",
       "92859    Bronze      74        v_quotes  \n",
       "92860    Silver      58        v_quotes  \n",
       "92861    Silver      81        v_quotes  \n",
       "92862      Gold      94        v_quotes  \n",
       "92863    Silver     104        v_quotes  \n",
       "92864    Silver      81        v_quotes  \n",
       "92865  Platinum      89        v_quotes  \n",
       "92866      Gold      92        v_quotes  \n",
       "92867      Gold      97        v_quotes  \n",
       "92868  Platinum      84        v_quotes  \n",
       "92869      Gold      86        v_quotes  \n",
       "92870    Silver     100        v_quotes  \n",
       "92871      Gold      89        v_quotes  \n",
       "92872      Gold      92        v_quotes  \n",
       "92873      Gold      82        v_quotes  \n",
       "92874    Bronze      58        v_quotes  \n",
       "92875    Silver      77        v_quotes  \n",
       "92876    Silver      82        v_quotes  \n",
       "92877      Gold      84        v_quotes  \n",
       "92878    Silver      90        v_quotes  \n",
       "92879    Silver      66        v_quotes  \n",
       "92880    Silver      97        v_quotes  \n",
       "92881    Silver     102        v_quotes  \n",
       "\n",
       "[92882 rows x 17 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_bd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(joined_bd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Texas                   10410\n",
       "California               7474\n",
       "Florida                  6145\n",
       "Illinois                 5568\n",
       "Missouri                 5032\n",
       "Georgia                  3605\n",
       "Alabama                  3484\n",
       "Oklahoma                 3212\n",
       "Kansas                   3176\n",
       "Tennessee                3154\n",
       "Louisiana                3051\n",
       "Iowa                     3037\n",
       "Minnesota                2850\n",
       "Arkansas                 2725\n",
       "Nebraska                 2464\n",
       "Wisconsin                2462\n",
       "Washington               2020\n",
       "Mississippi              1956\n",
       "Colorado                 1789\n",
       "Arizona                  1491\n",
       "Oregon                   1301\n",
       "New Mexico               1184\n",
       "Montana                  1158\n",
       "North Dakota             1125\n",
       "New York                 1084\n",
       "South Dakota             1082\n",
       "Utah                      984\n",
       "Idaho                     965\n",
       "Pennsylvania              942\n",
       "Alaska                    754\n",
       "Nevada                    708\n",
       "Ohio                      688\n",
       "Wyoming                   551\n",
       "Virginia                  532\n",
       "Indiana                   508\n",
       "West Virginia             460\n",
       "Michigan                  446\n",
       "North Carolina            413\n",
       "Kentucky                  413\n",
       "Hawaii                    384\n",
       "Massachusetts             335\n",
       "New Jersey                292\n",
       "Maryland                  279\n",
       "Connecticut               234\n",
       "Maine                     229\n",
       "South Carolina            205\n",
       "Vermont                   151\n",
       "District of Columbia      139\n",
       "New Hampshire             106\n",
       "Delaware                   57\n",
       "Rhode Island               31\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_bd_df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Silver      56954\n",
       "Gold        24155\n",
       "Bronze       8856\n",
       "Platinum     2917\n",
       "Name: PURCHASED, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_bd_df['PURCHASED'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format of data:\n",
    "\n",
    "`data = {\n",
    "    \"TX\":{\n",
    "        \"p_cnt\":12,\n",
    "        \"g_cnt\":23,\n",
    "        \"s_cnt\":45,\n",
    "        \"b_cnt\":21\n",
    "        }\n",
    "     }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_insurance_by_state = joined_bd_df['PURCHASED'].groupby(joined_bd_df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.SeriesGroupBy object at 0x187d278d0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_insurance_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alabama', 20167        Gold\n",
       "  20168      Silver\n",
       "  20229      Silver\n",
       "  20230      Silver\n",
       "  20231      Silver\n",
       "  20294        Gold\n",
       "  20295      Silver\n",
       "  20296      Silver\n",
       "  20365      Silver\n",
       "  20366      Silver\n",
       "  20486      Silver\n",
       "  20487      Silver\n",
       "  20488        Gold\n",
       "  20489      Silver\n",
       "  20490      Silver\n",
       "  20572        Gold\n",
       "  20573      Silver\n",
       "  20574      Silver\n",
       "  20687      Silver\n",
       "  20688      Silver\n",
       "  20689      Silver\n",
       "  20690      Silver\n",
       "  20691      Silver\n",
       "  20692      Silver\n",
       "  20693      Bronze\n",
       "  20694      Silver\n",
       "  20695      Silver\n",
       "  20696      Silver\n",
       "  20697      Bronze\n",
       "  20698      Silver\n",
       "             ...   \n",
       "  89346      Bronze\n",
       "  89347        Gold\n",
       "  89348      Silver\n",
       "  89349      Silver\n",
       "  89350      Silver\n",
       "  89351      Bronze\n",
       "  89352        Gold\n",
       "  89353      Bronze\n",
       "  89354      Silver\n",
       "  89355      Silver\n",
       "  89356        Gold\n",
       "  89357      Bronze\n",
       "  89358      Bronze\n",
       "  89359        Gold\n",
       "  89360      Silver\n",
       "  89361        Gold\n",
       "  89362    Platinum\n",
       "  89363        Gold\n",
       "  89364      Bronze\n",
       "  89365      Silver\n",
       "  89366        Gold\n",
       "  89367      Silver\n",
       "  89368        Gold\n",
       "  89369    Platinum\n",
       "  89370      Silver\n",
       "  89371      Silver\n",
       "  89372      Silver\n",
       "  89373      Silver\n",
       "  89374        Gold\n",
       "  89375      Bronze\n",
       "  Name: PURCHASED, Length: 3484, dtype: object), ('Alaska', 0        Silver\n",
       "  1        Silver\n",
       "  2          Gold\n",
       "  3        Silver\n",
       "  4          Gold\n",
       "  5        Silver\n",
       "  6        Silver\n",
       "  7        Silver\n",
       "  8        Silver\n",
       "  9        Silver\n",
       "  10         Gold\n",
       "  11       Silver\n",
       "  12       Silver\n",
       "  13       Silver\n",
       "  14       Silver\n",
       "  15         Gold\n",
       "  16       Silver\n",
       "  17       Silver\n",
       "  18         Gold\n",
       "  19       Silver\n",
       "  20       Silver\n",
       "  21       Silver\n",
       "  22       Silver\n",
       "  23         Gold\n",
       "  24         Gold\n",
       "  25       Silver\n",
       "  1175     Silver\n",
       "  1176       Gold\n",
       "  1177     Silver\n",
       "  1178     Silver\n",
       "            ...  \n",
       "  63895    Silver\n",
       "  63896      Gold\n",
       "  63897    Silver\n",
       "  64995    Silver\n",
       "  64996    Silver\n",
       "  64997    Silver\n",
       "  64998    Silver\n",
       "  64999    Silver\n",
       "  65000    Silver\n",
       "  65001    Silver\n",
       "  65002    Silver\n",
       "  65003    Silver\n",
       "  65004    Silver\n",
       "  65005      Gold\n",
       "  65006    Silver\n",
       "  65007    Silver\n",
       "  65008      Gold\n",
       "  65009    Silver\n",
       "  65010      Gold\n",
       "  65011    Silver\n",
       "  65012      Gold\n",
       "  65013    Silver\n",
       "  65014    Silver\n",
       "  65015    Silver\n",
       "  65016    Silver\n",
       "  65017      Gold\n",
       "  65018    Silver\n",
       "  65019    Silver\n",
       "  65020    Silver\n",
       "  65021    Silver\n",
       "  Name: PURCHASED, Length: 754, dtype: object), ('Arizona', 26       Silver\n",
       "  27         Gold\n",
       "  28         Gold\n",
       "  29       Silver\n",
       "  30       Silver\n",
       "  31       Silver\n",
       "  32       Silver\n",
       "  33       Silver\n",
       "  34       Silver\n",
       "  35         Gold\n",
       "  36       Silver\n",
       "  37       Silver\n",
       "  38         Gold\n",
       "  39         Gold\n",
       "  40       Silver\n",
       "  41       Silver\n",
       "  42       Silver\n",
       "  43         Gold\n",
       "  44         Gold\n",
       "  45       Silver\n",
       "  46       Silver\n",
       "  47       Silver\n",
       "  48       Silver\n",
       "  49       Silver\n",
       "  50         Gold\n",
       "  51       Silver\n",
       "  52       Silver\n",
       "  53       Silver\n",
       "  54       Silver\n",
       "  55         Gold\n",
       "            ...  \n",
       "  65040    Silver\n",
       "  65041    Silver\n",
       "  65042    Silver\n",
       "  65043      Gold\n",
       "  65044    Silver\n",
       "  65045      Gold\n",
       "  65046      Gold\n",
       "  65047    Silver\n",
       "  65048    Silver\n",
       "  65049    Silver\n",
       "  65050    Silver\n",
       "  65051      Gold\n",
       "  65052    Silver\n",
       "  65053      Gold\n",
       "  65054    Silver\n",
       "  65055    Silver\n",
       "  65056    Silver\n",
       "  65057    Silver\n",
       "  65058      Gold\n",
       "  65059    Silver\n",
       "  65060    Silver\n",
       "  65061    Silver\n",
       "  65062      Gold\n",
       "  65063    Silver\n",
       "  65064      Gold\n",
       "  65065    Silver\n",
       "  65066    Silver\n",
       "  65067    Silver\n",
       "  65068    Silver\n",
       "  65069    Silver\n",
       "  Name: PURCHASED, Length: 1491, dtype: object), ('Arkansas', 20169      Silver\n",
       "  20170        Gold\n",
       "  20171      Silver\n",
       "  20232        Gold\n",
       "  20233      Silver\n",
       "  20234        Gold\n",
       "  20235      Silver\n",
       "  20236      Silver\n",
       "  20297        Gold\n",
       "  20298      Silver\n",
       "  20367        Gold\n",
       "  20368        Gold\n",
       "  20369      Silver\n",
       "  20428      Silver\n",
       "  20429      Silver\n",
       "  20430      Silver\n",
       "  20491      Silver\n",
       "  20492      Silver\n",
       "  20493      Silver\n",
       "  20494      Silver\n",
       "  20575      Silver\n",
       "  20576      Silver\n",
       "  20577      Silver\n",
       "  20578      Silver\n",
       "  20579      Silver\n",
       "  20700        Gold\n",
       "  20701        Gold\n",
       "  20926        Gold\n",
       "  20927        Gold\n",
       "  20928      Silver\n",
       "             ...   \n",
       "  89676      Silver\n",
       "  89677      Bronze\n",
       "  89678        Gold\n",
       "  89679      Silver\n",
       "  89680      Bronze\n",
       "  89681        Gold\n",
       "  89682        Gold\n",
       "  89683        Gold\n",
       "  89684        Gold\n",
       "  89685      Bronze\n",
       "  89686        Gold\n",
       "  89687        Gold\n",
       "  89688      Silver\n",
       "  89689      Bronze\n",
       "  89690        Gold\n",
       "  89691      Silver\n",
       "  89692        Gold\n",
       "  89693      Silver\n",
       "  89694      Silver\n",
       "  89695      Bronze\n",
       "  89696      Silver\n",
       "  89697        Gold\n",
       "  89698      Silver\n",
       "  89699      Bronze\n",
       "  89700      Silver\n",
       "  89701    Platinum\n",
       "  89702      Silver\n",
       "  89703    Platinum\n",
       "  89704      Silver\n",
       "  89705      Bronze\n",
       "  Name: PURCHASED, Length: 2725, dtype: object), ('California', 79       Silver\n",
       "  80       Silver\n",
       "  81       Silver\n",
       "  82       Silver\n",
       "  83         Gold\n",
       "  84       Silver\n",
       "  85       Silver\n",
       "  86       Silver\n",
       "  87       Silver\n",
       "  88       Silver\n",
       "  89       Silver\n",
       "  90         Gold\n",
       "  91       Silver\n",
       "  92         Gold\n",
       "  93       Silver\n",
       "  94         Gold\n",
       "  95       Silver\n",
       "  96         Gold\n",
       "  97         Gold\n",
       "  98       Silver\n",
       "  99         Gold\n",
       "  100      Silver\n",
       "  101      Silver\n",
       "  102        Gold\n",
       "  103      Silver\n",
       "  104      Silver\n",
       "  105      Silver\n",
       "  106      Silver\n",
       "  107        Gold\n",
       "  108      Silver\n",
       "            ...  \n",
       "  65302    Silver\n",
       "  65303    Silver\n",
       "  65304      Gold\n",
       "  65305      Gold\n",
       "  65306      Gold\n",
       "  65307    Silver\n",
       "  65308    Silver\n",
       "  65309    Silver\n",
       "  65310    Silver\n",
       "  65311    Silver\n",
       "  65312    Silver\n",
       "  65313      Gold\n",
       "  65314      Gold\n",
       "  65315    Silver\n",
       "  65316    Silver\n",
       "  65317      Gold\n",
       "  65318    Silver\n",
       "  65319    Silver\n",
       "  65320    Silver\n",
       "  65321    Silver\n",
       "  65322      Gold\n",
       "  65323    Silver\n",
       "  65324      Gold\n",
       "  65325    Silver\n",
       "  65326    Silver\n",
       "  65327    Silver\n",
       "  65328    Silver\n",
       "  65329      Gold\n",
       "  65330      Gold\n",
       "  65331      Gold\n",
       "  Name: PURCHASED, Length: 7474, dtype: object), ('Colorado', 373        Gold\n",
       "  374      Silver\n",
       "  375      Silver\n",
       "  376      Silver\n",
       "  377        Gold\n",
       "  378      Silver\n",
       "  379        Gold\n",
       "  380      Silver\n",
       "  381        Gold\n",
       "  382        Gold\n",
       "  383      Silver\n",
       "  384        Gold\n",
       "  385      Silver\n",
       "  386      Silver\n",
       "  387      Silver\n",
       "  388      Silver\n",
       "  389        Gold\n",
       "  390      Silver\n",
       "  391      Silver\n",
       "  392      Silver\n",
       "  393      Silver\n",
       "  394      Silver\n",
       "  395      Silver\n",
       "  396      Silver\n",
       "  397      Silver\n",
       "  398      Silver\n",
       "  399      Silver\n",
       "  400      Silver\n",
       "  401        Gold\n",
       "  402        Gold\n",
       "            ...  \n",
       "  65364    Silver\n",
       "  65365    Silver\n",
       "  65366    Silver\n",
       "  65367    Silver\n",
       "  65368    Silver\n",
       "  65369    Silver\n",
       "  65370    Silver\n",
       "  65371    Silver\n",
       "  65372    Silver\n",
       "  65373    Silver\n",
       "  65374    Silver\n",
       "  65375    Silver\n",
       "  65376      Gold\n",
       "  65377    Silver\n",
       "  65378      Gold\n",
       "  65379    Silver\n",
       "  65380      Gold\n",
       "  65381    Silver\n",
       "  65382      Gold\n",
       "  65383    Silver\n",
       "  65384    Silver\n",
       "  65385    Silver\n",
       "  65386      Gold\n",
       "  65387      Gold\n",
       "  65388      Gold\n",
       "  65389    Silver\n",
       "  65390    Silver\n",
       "  65391    Silver\n",
       "  65392    Silver\n",
       "  65393    Silver\n",
       "  Name: PURCHASED, Length: 1789, dtype: object), ('Connecticut',\n",
       "  44202    Silver\n",
       "  44203    Silver\n",
       "  44204      Gold\n",
       "  44205      Gold\n",
       "  44206      Gold\n",
       "  44207      Gold\n",
       "  44208    Silver\n",
       "  44209    Silver\n",
       "  44210    Silver\n",
       "  44211    Silver\n",
       "  44212    Silver\n",
       "  44213    Silver\n",
       "  44214      Gold\n",
       "  44215    Silver\n",
       "  44216    Silver\n",
       "  44217    Silver\n",
       "  44218    Silver\n",
       "  44219      Gold\n",
       "  44220    Silver\n",
       "  44221    Silver\n",
       "  44222    Silver\n",
       "  44223    Silver\n",
       "  44224    Silver\n",
       "  44225    Silver\n",
       "  44226    Silver\n",
       "  44227    Silver\n",
       "  44228    Silver\n",
       "  44229    Silver\n",
       "  44230      Gold\n",
       "  44231    Silver\n",
       "            ...  \n",
       "  58034    Silver\n",
       "  58035    Silver\n",
       "  58036      Gold\n",
       "  58037    Silver\n",
       "  58038      Gold\n",
       "  58039      Gold\n",
       "  58040    Silver\n",
       "  58041    Silver\n",
       "  58042      Gold\n",
       "  58043      Gold\n",
       "  58044    Silver\n",
       "  58045    Silver\n",
       "  58046    Silver\n",
       "  58047      Gold\n",
       "  58048    Silver\n",
       "  58049    Silver\n",
       "  58050    Silver\n",
       "  58051      Gold\n",
       "  58052      Gold\n",
       "  58053      Gold\n",
       "  58054    Silver\n",
       "  58055    Silver\n",
       "  58056    Silver\n",
       "  58057    Silver\n",
       "  58058    Silver\n",
       "  58059    Silver\n",
       "  58060      Gold\n",
       "  58061    Silver\n",
       "  58062    Silver\n",
       "  58063      Gold\n",
       "  Name: PURCHASED, Length: 234, dtype: object), ('Delaware', 44268    Silver\n",
       "  44269    Silver\n",
       "  44270    Silver\n",
       "  44271    Silver\n",
       "  44272      Gold\n",
       "  44273    Silver\n",
       "  44274    Silver\n",
       "  44275    Silver\n",
       "  44276    Silver\n",
       "  44277    Silver\n",
       "  45402    Silver\n",
       "  45403      Gold\n",
       "  45404      Gold\n",
       "  45515      Gold\n",
       "  53187    Silver\n",
       "  53188    Silver\n",
       "  53270    Silver\n",
       "  53743    Silver\n",
       "  53744    Silver\n",
       "  54001    Silver\n",
       "  54267    Silver\n",
       "  54535      Gold\n",
       "  54601      Gold\n",
       "  54732    Silver\n",
       "  54872      Gold\n",
       "  54873      Gold\n",
       "  54874    Silver\n",
       "  54875    Silver\n",
       "  54876      Gold\n",
       "  54877    Silver\n",
       "  54878      Gold\n",
       "  54879    Silver\n",
       "  56184      Gold\n",
       "  56185    Silver\n",
       "  56186    Silver\n",
       "  56187      Gold\n",
       "  56188      Gold\n",
       "  56189    Silver\n",
       "  56665      Gold\n",
       "  56666    Silver\n",
       "  56667    Silver\n",
       "  56668    Silver\n",
       "  56669    Silver\n",
       "  56670      Gold\n",
       "  56671      Gold\n",
       "  56672      Gold\n",
       "  58082    Silver\n",
       "  58083    Silver\n",
       "  58084      Gold\n",
       "  58085    Silver\n",
       "  58086    Silver\n",
       "  58087      Gold\n",
       "  58088    Silver\n",
       "  58089    Silver\n",
       "  58090    Silver\n",
       "  58091    Silver\n",
       "  58092    Silver\n",
       "  Name: PURCHASED, dtype: object), ('District of Columbia', 1580     Silver\n",
       "  7229       Gold\n",
       "  9508       Gold\n",
       "  10636    Silver\n",
       "  10637    Silver\n",
       "  11783    Silver\n",
       "  15139    Silver\n",
       "  17370      Gold\n",
       "  27829    Silver\n",
       "  27830    Silver\n",
       "  28968    Silver\n",
       "  44243    Silver\n",
       "  44244    Silver\n",
       "  44245      Gold\n",
       "  44246    Silver\n",
       "  44247      Gold\n",
       "  44248    Silver\n",
       "  44249    Silver\n",
       "  44250    Silver\n",
       "  44251    Silver\n",
       "  44252      Gold\n",
       "  44253    Silver\n",
       "  44254      Gold\n",
       "  44255      Gold\n",
       "  44256      Gold\n",
       "  44257    Silver\n",
       "  44258    Silver\n",
       "  44259    Silver\n",
       "  44260      Gold\n",
       "  44261    Silver\n",
       "            ...  \n",
       "  56653    Silver\n",
       "  56654    Silver\n",
       "  56655      Gold\n",
       "  56656    Silver\n",
       "  56657    Silver\n",
       "  56658    Silver\n",
       "  56659    Silver\n",
       "  56660      Gold\n",
       "  56661    Silver\n",
       "  56662    Silver\n",
       "  56663    Silver\n",
       "  56664      Gold\n",
       "  58064      Gold\n",
       "  58065    Silver\n",
       "  58066      Gold\n",
       "  58067    Silver\n",
       "  58068      Gold\n",
       "  58069    Silver\n",
       "  58070    Silver\n",
       "  58071    Silver\n",
       "  58072    Silver\n",
       "  58073    Silver\n",
       "  58074    Silver\n",
       "  58075    Silver\n",
       "  58076    Silver\n",
       "  58077    Silver\n",
       "  58078      Gold\n",
       "  58079    Silver\n",
       "  58080      Gold\n",
       "  58081    Silver\n",
       "  Name: PURCHASED, Length: 139, dtype: object), ('Florida', 20172      Silver\n",
       "  20173        Gold\n",
       "  20174      Silver\n",
       "  20175      Silver\n",
       "  20176      Silver\n",
       "  20177      Silver\n",
       "  20178      Silver\n",
       "  20237        Gold\n",
       "  20238        Gold\n",
       "  20239      Silver\n",
       "  20240      Silver\n",
       "  20241      Silver\n",
       "  20242      Silver\n",
       "  20299      Silver\n",
       "  20300      Silver\n",
       "  20301      Silver\n",
       "  20302      Silver\n",
       "  20303        Gold\n",
       "  20304        Gold\n",
       "  20305      Silver\n",
       "  20306      Silver\n",
       "  20307        Gold\n",
       "  20308      Silver\n",
       "  20309        Gold\n",
       "  20310      Silver\n",
       "  20311        Gold\n",
       "  20312        Gold\n",
       "  20313      Silver\n",
       "  20314      Silver\n",
       "  20370      Silver\n",
       "             ...   \n",
       "  90413      Silver\n",
       "  90414      Silver\n",
       "  90415      Silver\n",
       "  90416      Silver\n",
       "  90417    Platinum\n",
       "  90418      Silver\n",
       "  90419        Gold\n",
       "  90420        Gold\n",
       "  90421      Silver\n",
       "  90422      Silver\n",
       "  90423      Silver\n",
       "  90424        Gold\n",
       "  90425      Bronze\n",
       "  90426      Silver\n",
       "  90427      Bronze\n",
       "  90428      Silver\n",
       "  90429      Bronze\n",
       "  90430      Bronze\n",
       "  90431      Silver\n",
       "  90432      Bronze\n",
       "  90433      Bronze\n",
       "  90434      Silver\n",
       "  90435        Gold\n",
       "  90436      Silver\n",
       "  90437      Bronze\n",
       "  90438      Bronze\n",
       "  90439    Platinum\n",
       "  90440    Platinum\n",
       "  90441      Silver\n",
       "  90442      Silver\n",
       "  Name: PURCHASED, Length: 6145, dtype: object), ('Georgia', 20179      Silver\n",
       "  20180      Silver\n",
       "  20181        Gold\n",
       "  20182      Silver\n",
       "  20183        Gold\n",
       "  20243        Gold\n",
       "  20244      Silver\n",
       "  20245      Silver\n",
       "  20246      Silver\n",
       "  20247      Silver\n",
       "  20248      Silver\n",
       "  20249        Gold\n",
       "  20250      Silver\n",
       "  20315        Gold\n",
       "  20316      Silver\n",
       "  20317        Gold\n",
       "  20318      Silver\n",
       "  20378      Silver\n",
       "  20379      Silver\n",
       "  20380        Gold\n",
       "  20381        Gold\n",
       "  20436        Gold\n",
       "  20437      Silver\n",
       "  20438      Silver\n",
       "  20439      Silver\n",
       "  20440      Silver\n",
       "  20503      Silver\n",
       "  20504        Gold\n",
       "  20505      Silver\n",
       "  20506      Silver\n",
       "             ...   \n",
       "  90855        Gold\n",
       "  90856    Platinum\n",
       "  90857        Gold\n",
       "  90858      Silver\n",
       "  90859      Silver\n",
       "  90860      Silver\n",
       "  90861      Bronze\n",
       "  90862      Silver\n",
       "  90863    Platinum\n",
       "  90864      Silver\n",
       "  90865      Silver\n",
       "  90866    Platinum\n",
       "  90867      Bronze\n",
       "  90868        Gold\n",
       "  90869      Bronze\n",
       "  90870    Platinum\n",
       "  90871      Silver\n",
       "  90872      Silver\n",
       "  90873      Silver\n",
       "  90874      Bronze\n",
       "  90875      Silver\n",
       "  90876      Silver\n",
       "  90877      Silver\n",
       "  90878        Gold\n",
       "  90879    Platinum\n",
       "  90880      Bronze\n",
       "  90881        Gold\n",
       "  90882      Bronze\n",
       "  90883      Silver\n",
       "  90884      Silver\n",
       "  Name: PURCHASED, Length: 3605, dtype: object), ('Hawaii', 439      Silver\n",
       "  440      Silver\n",
       "  441      Silver\n",
       "  442      Silver\n",
       "  443      Silver\n",
       "  444      Silver\n",
       "  445      Silver\n",
       "  446      Silver\n",
       "  447      Silver\n",
       "  448      Silver\n",
       "  449      Silver\n",
       "  450      Silver\n",
       "  451      Silver\n",
       "  452        Gold\n",
       "  453      Silver\n",
       "  454      Silver\n",
       "  455        Gold\n",
       "  456      Silver\n",
       "  457      Silver\n",
       "  458        Gold\n",
       "  1581     Silver\n",
       "  1582       Gold\n",
       "  1583       Gold\n",
       "  1584       Gold\n",
       "  1585     Silver\n",
       "  1586     Silver\n",
       "  1587     Silver\n",
       "  1588     Silver\n",
       "  1589     Silver\n",
       "  1590     Silver\n",
       "            ...  \n",
       "  63163      Gold\n",
       "  63164    Silver\n",
       "  63165    Silver\n",
       "  63166    Silver\n",
       "  63167      Gold\n",
       "  63168      Gold\n",
       "  63169      Gold\n",
       "  63170      Gold\n",
       "  64276      Gold\n",
       "  64277    Silver\n",
       "  64278    Silver\n",
       "  64279    Silver\n",
       "  64280    Silver\n",
       "  64281    Silver\n",
       "  64282    Silver\n",
       "  64283    Silver\n",
       "  64284    Silver\n",
       "  64285      Gold\n",
       "  64286    Silver\n",
       "  64287    Silver\n",
       "  64288    Silver\n",
       "  65394    Silver\n",
       "  65395    Silver\n",
       "  65396      Gold\n",
       "  65397    Silver\n",
       "  65398    Silver\n",
       "  65399    Silver\n",
       "  65400      Gold\n",
       "  65401    Silver\n",
       "  65402    Silver\n",
       "  Name: PURCHASED, Length: 384, dtype: object), ('Idaho', 561      Silver\n",
       "  562      Silver\n",
       "  563        Gold\n",
       "  564        Gold\n",
       "  565      Silver\n",
       "  566      Silver\n",
       "  567      Silver\n",
       "  568      Silver\n",
       "  569        Gold\n",
       "  570      Silver\n",
       "  571      Silver\n",
       "  572        Gold\n",
       "  573      Silver\n",
       "  574      Silver\n",
       "  575      Silver\n",
       "  576      Silver\n",
       "  577      Silver\n",
       "  578      Silver\n",
       "  579      Silver\n",
       "  580      Silver\n",
       "  581      Silver\n",
       "  582      Silver\n",
       "  583      Silver\n",
       "  584        Gold\n",
       "  585      Silver\n",
       "  586      Silver\n",
       "  587      Silver\n",
       "  588      Silver\n",
       "  589      Silver\n",
       "  590      Silver\n",
       "            ...  \n",
       "  65510    Silver\n",
       "  65511    Silver\n",
       "  65512    Silver\n",
       "  65513    Silver\n",
       "  65514    Silver\n",
       "  65515      Gold\n",
       "  65516      Gold\n",
       "  65517    Silver\n",
       "  65518    Silver\n",
       "  65519    Silver\n",
       "  65520      Gold\n",
       "  65521    Silver\n",
       "  65522      Gold\n",
       "  65523    Silver\n",
       "  65524    Silver\n",
       "  65525    Silver\n",
       "  65526    Silver\n",
       "  65527      Gold\n",
       "  65528    Silver\n",
       "  65529    Silver\n",
       "  65530    Silver\n",
       "  65531      Gold\n",
       "  65532    Silver\n",
       "  65533      Gold\n",
       "  65534      Gold\n",
       "  65535    Silver\n",
       "  65536    Silver\n",
       "  65537      Gold\n",
       "  65538      Gold\n",
       "  65539    Silver\n",
       "  Name: PURCHASED, Length: 965, dtype: object), ('Illinois', 20184      Silver\n",
       "  20185      Silver\n",
       "  20186        Gold\n",
       "  20187      Silver\n",
       "  20188      Silver\n",
       "  20189      Silver\n",
       "  20190        Gold\n",
       "  20251        Gold\n",
       "  20252        Gold\n",
       "  20253      Silver\n",
       "  20254        Gold\n",
       "  20255      Silver\n",
       "  20256      Silver\n",
       "  20257      Silver\n",
       "  20258      Silver\n",
       "  20259      Silver\n",
       "  20260      Silver\n",
       "  20261      Silver\n",
       "  20319      Silver\n",
       "  20320      Silver\n",
       "  20321      Silver\n",
       "  20322      Silver\n",
       "  20323      Silver\n",
       "  20324      Silver\n",
       "  20325      Silver\n",
       "  20382      Silver\n",
       "  20383      Silver\n",
       "  20384      Silver\n",
       "  20385      Silver\n",
       "  20386      Silver\n",
       "             ...   \n",
       "  91612    Platinum\n",
       "  91613        Gold\n",
       "  91614      Bronze\n",
       "  91615        Gold\n",
       "  91616        Gold\n",
       "  91617      Bronze\n",
       "  91618        Gold\n",
       "  91619        Gold\n",
       "  91620      Silver\n",
       "  91621        Gold\n",
       "  91622      Bronze\n",
       "  91623      Silver\n",
       "  91624        Gold\n",
       "  91625      Bronze\n",
       "  91626      Silver\n",
       "  91627      Silver\n",
       "  91628      Bronze\n",
       "  91629      Bronze\n",
       "  91630      Bronze\n",
       "  91631      Silver\n",
       "  91632    Platinum\n",
       "  91633      Silver\n",
       "  91634      Bronze\n",
       "  91635      Silver\n",
       "  91636        Gold\n",
       "  91637      Bronze\n",
       "  91638      Bronze\n",
       "  91639      Silver\n",
       "  91640        Gold\n",
       "  91641      Silver\n",
       "  Name: PURCHASED, Length: 5568, dtype: object), ('Indiana', 44278    Silver\n",
       "  44279    Silver\n",
       "  44280    Silver\n",
       "  44281      Gold\n",
       "  44282      Gold\n",
       "  44283    Silver\n",
       "  44284    Silver\n",
       "  44285    Silver\n",
       "  44286    Silver\n",
       "  44287    Silver\n",
       "  44288    Silver\n",
       "  44289    Silver\n",
       "  44290      Gold\n",
       "  44291    Silver\n",
       "  44292      Gold\n",
       "  44293    Silver\n",
       "  44294    Silver\n",
       "  44295    Silver\n",
       "  44296    Silver\n",
       "  44297    Silver\n",
       "  44298    Silver\n",
       "  44299      Gold\n",
       "  44300    Silver\n",
       "  44301      Gold\n",
       "  44302    Silver\n",
       "  44303      Gold\n",
       "  44304    Silver\n",
       "  44305    Silver\n",
       "  44306    Silver\n",
       "  44307    Silver\n",
       "            ...  \n",
       "  58122    Silver\n",
       "  58123    Silver\n",
       "  58124      Gold\n",
       "  58125      Gold\n",
       "  58126    Silver\n",
       "  58127    Silver\n",
       "  58128      Gold\n",
       "  58129    Silver\n",
       "  58130    Silver\n",
       "  58131    Silver\n",
       "  58132    Silver\n",
       "  58133    Silver\n",
       "  58134    Silver\n",
       "  58135      Gold\n",
       "  58136    Silver\n",
       "  58137      Gold\n",
       "  58138    Silver\n",
       "  58139    Silver\n",
       "  58140    Silver\n",
       "  58141    Silver\n",
       "  58142    Silver\n",
       "  58143    Silver\n",
       "  58144      Gold\n",
       "  58145    Silver\n",
       "  58146    Silver\n",
       "  58147      Gold\n",
       "  58148    Silver\n",
       "  58149      Gold\n",
       "  58150    Silver\n",
       "  58151    Silver\n",
       "  Name: PURCHASED, Length: 508, dtype: object), ('Iowa', 459      Silver\n",
       "  460      Silver\n",
       "  461      Silver\n",
       "  462        Gold\n",
       "  463      Silver\n",
       "  464      Silver\n",
       "  465      Silver\n",
       "  466        Gold\n",
       "  467      Silver\n",
       "  468      Silver\n",
       "  469      Silver\n",
       "  470        Gold\n",
       "  471      Silver\n",
       "  472        Gold\n",
       "  473      Silver\n",
       "  474      Silver\n",
       "  475      Silver\n",
       "  476      Silver\n",
       "  477        Gold\n",
       "  478      Silver\n",
       "  479      Silver\n",
       "  480      Silver\n",
       "  481      Silver\n",
       "  482        Gold\n",
       "  483      Silver\n",
       "  484      Silver\n",
       "  485      Silver\n",
       "  486      Silver\n",
       "  487      Silver\n",
       "  488      Silver\n",
       "            ...  \n",
       "  65474    Silver\n",
       "  65475    Silver\n",
       "  65476    Silver\n",
       "  65477    Silver\n",
       "  65478    Silver\n",
       "  65479    Silver\n",
       "  65480    Silver\n",
       "  65481    Silver\n",
       "  65482      Gold\n",
       "  65483    Silver\n",
       "  65484    Silver\n",
       "  65485    Silver\n",
       "  65486    Silver\n",
       "  65487      Gold\n",
       "  65488    Silver\n",
       "  65489      Gold\n",
       "  65490    Silver\n",
       "  65491    Silver\n",
       "  65492    Silver\n",
       "  65493    Silver\n",
       "  65494      Gold\n",
       "  65495    Silver\n",
       "  65496    Silver\n",
       "  65497    Silver\n",
       "  65498    Silver\n",
       "  65499    Silver\n",
       "  65500    Silver\n",
       "  65501    Silver\n",
       "  65502      Gold\n",
       "  65503      Gold\n",
       "  Name: PURCHASED, Length: 3037, dtype: object), ('Kansas', 20191      Silver\n",
       "  20192        Gold\n",
       "  20193      Silver\n",
       "  20194      Silver\n",
       "  20195      Silver\n",
       "  20262      Silver\n",
       "  20263        Gold\n",
       "  20326      Silver\n",
       "  20327        Gold\n",
       "  20328        Gold\n",
       "  20387        Gold\n",
       "  20388        Gold\n",
       "  20455      Silver\n",
       "  20519        Gold\n",
       "  20520      Silver\n",
       "  20521      Silver\n",
       "  20522        Gold\n",
       "  20523      Silver\n",
       "  20595      Silver\n",
       "  20596      Silver\n",
       "  20597      Silver\n",
       "  20598      Silver\n",
       "  20599        Gold\n",
       "  20600      Silver\n",
       "  20756      Silver\n",
       "  20757      Bronze\n",
       "  20758        Gold\n",
       "  20759      Bronze\n",
       "  20760      Silver\n",
       "  20761      Silver\n",
       "             ...   \n",
       "  91966        Gold\n",
       "  91967        Gold\n",
       "  91968      Silver\n",
       "  91969    Platinum\n",
       "  91970      Silver\n",
       "  91971      Bronze\n",
       "  91972        Gold\n",
       "  91973        Gold\n",
       "  91974      Silver\n",
       "  91975      Bronze\n",
       "  91976      Silver\n",
       "  91977      Silver\n",
       "  91978      Silver\n",
       "  91979      Silver\n",
       "  91980        Gold\n",
       "  91981    Platinum\n",
       "  91982      Silver\n",
       "  91983        Gold\n",
       "  91984    Platinum\n",
       "  91985      Silver\n",
       "  91986      Silver\n",
       "  91987    Platinum\n",
       "  91988      Silver\n",
       "  91989        Gold\n",
       "  91990      Silver\n",
       "  91991        Gold\n",
       "  91992      Silver\n",
       "  91993      Silver\n",
       "  91994      Silver\n",
       "  91995      Bronze\n",
       "  Name: PURCHASED, Length: 3176, dtype: object), ('Kentucky', 44368    Silver\n",
       "  44369      Gold\n",
       "  44370    Silver\n",
       "  44371      Gold\n",
       "  44372    Silver\n",
       "  44373    Silver\n",
       "  44374      Gold\n",
       "  44375    Silver\n",
       "  44376    Silver\n",
       "  44377    Silver\n",
       "  44378      Gold\n",
       "  44379    Silver\n",
       "  44380    Silver\n",
       "  44381    Silver\n",
       "  44382      Gold\n",
       "  44383      Gold\n",
       "  44384      Gold\n",
       "  44385      Gold\n",
       "  44386    Silver\n",
       "  44387    Silver\n",
       "  44388    Silver\n",
       "  44389    Silver\n",
       "  44390    Silver\n",
       "  44391    Silver\n",
       "  44392    Silver\n",
       "  44393      Gold\n",
       "  44394      Gold\n",
       "  44395      Gold\n",
       "  44396    Silver\n",
       "  44397    Silver\n",
       "            ...  \n",
       "  56816      Gold\n",
       "  56817    Silver\n",
       "  56818    Silver\n",
       "  56819    Silver\n",
       "  56820      Gold\n",
       "  56821    Silver\n",
       "  56822    Silver\n",
       "  56823    Silver\n",
       "  56824      Gold\n",
       "  56825    Silver\n",
       "  56826    Silver\n",
       "  56827    Silver\n",
       "  56828    Silver\n",
       "  56829      Gold\n",
       "  56830    Silver\n",
       "  56831    Silver\n",
       "  56832      Gold\n",
       "  56833    Silver\n",
       "  56834    Silver\n",
       "  56835      Gold\n",
       "  56836    Silver\n",
       "  56837    Silver\n",
       "  56838    Silver\n",
       "  56839      Gold\n",
       "  56840      Gold\n",
       "  56841    Silver\n",
       "  56842    Silver\n",
       "  56843      Gold\n",
       "  56844      Gold\n",
       "  56845      Gold\n",
       "  Name: PURCHASED, Length: 413, dtype: object), ('Louisiana', 20196      Silver\n",
       "  20197      Silver\n",
       "  20198        Gold\n",
       "  20264        Gold\n",
       "  20265      Silver\n",
       "  20266        Gold\n",
       "  20329        Gold\n",
       "  20330        Gold\n",
       "  20331        Gold\n",
       "  20332        Gold\n",
       "  20333      Silver\n",
       "  20389        Gold\n",
       "  20456      Silver\n",
       "  20457        Gold\n",
       "  20524        Gold\n",
       "  20525      Silver\n",
       "  20526      Silver\n",
       "  20527      Silver\n",
       "  20772        Gold\n",
       "  20773      Silver\n",
       "  20774        Gold\n",
       "  20775      Silver\n",
       "  20776      Bronze\n",
       "  20777        Gold\n",
       "  20778      Bronze\n",
       "  20779        Gold\n",
       "  20780        Gold\n",
       "  20781      Silver\n",
       "  20782    Platinum\n",
       "  20783      Silver\n",
       "             ...   \n",
       "  92309      Silver\n",
       "  92310      Silver\n",
       "  92311      Bronze\n",
       "  92312      Silver\n",
       "  92313        Gold\n",
       "  92314      Silver\n",
       "  92315        Gold\n",
       "  92316      Silver\n",
       "  92317      Silver\n",
       "  92318      Bronze\n",
       "  92319        Gold\n",
       "  92320      Bronze\n",
       "  92321        Gold\n",
       "  92322      Silver\n",
       "  92323        Gold\n",
       "  92324      Bronze\n",
       "  92325        Gold\n",
       "  92326        Gold\n",
       "  92327        Gold\n",
       "  92328      Silver\n",
       "  92329        Gold\n",
       "  92330    Platinum\n",
       "  92331      Bronze\n",
       "  92332      Silver\n",
       "  92333    Platinum\n",
       "  92334      Bronze\n",
       "  92335      Bronze\n",
       "  92336        Gold\n",
       "  92337        Gold\n",
       "  92338      Bronze\n",
       "  Name: PURCHASED, Length: 3051, dtype: object), ('Maine', 44583    Silver\n",
       "  44584    Silver\n",
       "  44585      Gold\n",
       "  44586    Silver\n",
       "  44587    Silver\n",
       "  44588    Silver\n",
       "  44589      Gold\n",
       "  44590    Silver\n",
       "  44591    Silver\n",
       "  44592    Silver\n",
       "  44593    Silver\n",
       "  44594    Silver\n",
       "  44595    Silver\n",
       "  44596      Gold\n",
       "  44597      Gold\n",
       "  44598    Silver\n",
       "  44599    Silver\n",
       "  44600    Silver\n",
       "  44601      Gold\n",
       "  44602    Silver\n",
       "  44603    Silver\n",
       "  44604      Gold\n",
       "  44605    Silver\n",
       "  44606      Gold\n",
       "  44607      Gold\n",
       "  44608    Silver\n",
       "  44609    Silver\n",
       "  44610      Gold\n",
       "  44611    Silver\n",
       "  44612    Silver\n",
       "            ...  \n",
       "  56973      Gold\n",
       "  56974    Silver\n",
       "  56975    Silver\n",
       "  56976    Silver\n",
       "  56977    Silver\n",
       "  56978    Silver\n",
       "  56979    Silver\n",
       "  56980    Silver\n",
       "  56981    Silver\n",
       "  56982    Silver\n",
       "  56983    Silver\n",
       "  56984    Silver\n",
       "  56985    Silver\n",
       "  56986      Gold\n",
       "  56987    Silver\n",
       "  56988    Silver\n",
       "  56989    Silver\n",
       "  56990    Silver\n",
       "  56991    Silver\n",
       "  56992    Silver\n",
       "  56993    Silver\n",
       "  56994    Silver\n",
       "  56995    Silver\n",
       "  56996    Silver\n",
       "  56997      Gold\n",
       "  56998    Silver\n",
       "  56999      Gold\n",
       "  57000      Gold\n",
       "  57001    Silver\n",
       "  57002      Gold\n",
       "  Name: PURCHASED, Length: 229, dtype: object), ('Maryland', 44519      Gold\n",
       "  44520      Gold\n",
       "  44521      Gold\n",
       "  44522      Gold\n",
       "  44523    Silver\n",
       "  44524    Silver\n",
       "  44525    Silver\n",
       "  44526      Gold\n",
       "  44527    Silver\n",
       "  44528      Gold\n",
       "  44529      Gold\n",
       "  44530    Silver\n",
       "  44531      Gold\n",
       "  44532    Silver\n",
       "  44533    Silver\n",
       "  44534    Silver\n",
       "  44535    Silver\n",
       "  44536      Gold\n",
       "  44537    Silver\n",
       "  44538    Silver\n",
       "  44539    Silver\n",
       "  44540    Silver\n",
       "  44541    Silver\n",
       "  44542    Silver\n",
       "  44543    Silver\n",
       "  44544    Silver\n",
       "  44545    Silver\n",
       "  44546    Silver\n",
       "  44547      Gold\n",
       "  44548      Gold\n",
       "            ...  \n",
       "  56932    Silver\n",
       "  56933    Silver\n",
       "  56934    Silver\n",
       "  56935    Silver\n",
       "  56936    Silver\n",
       "  56937    Silver\n",
       "  56938    Silver\n",
       "  56939    Silver\n",
       "  56940    Silver\n",
       "  56941      Gold\n",
       "  56942    Silver\n",
       "  56943    Silver\n",
       "  56944    Silver\n",
       "  56945    Silver\n",
       "  56946    Silver\n",
       "  56947    Silver\n",
       "  56948    Silver\n",
       "  56949    Silver\n",
       "  56950    Silver\n",
       "  56951      Gold\n",
       "  56952      Gold\n",
       "  56953    Silver\n",
       "  56954    Silver\n",
       "  56955    Silver\n",
       "  56956    Silver\n",
       "  56957    Silver\n",
       "  56958    Silver\n",
       "  56959    Silver\n",
       "  56960    Silver\n",
       "  56961    Silver\n",
       "  Name: PURCHASED, Length: 279, dtype: object), ('Massachusetts',\n",
       "  44449      Gold\n",
       "  44450    Silver\n",
       "  44451      Gold\n",
       "  44452    Silver\n",
       "  44453      Gold\n",
       "  44454      Gold\n",
       "  44455    Silver\n",
       "  44456    Silver\n",
       "  44457    Silver\n",
       "  44458    Silver\n",
       "  44459    Silver\n",
       "  44460    Silver\n",
       "  44461    Silver\n",
       "  44462    Silver\n",
       "  44463      Gold\n",
       "  44464    Silver\n",
       "  44465    Silver\n",
       "  44466    Silver\n",
       "  44467      Gold\n",
       "  44468      Gold\n",
       "  44469    Silver\n",
       "  44470      Gold\n",
       "  44471    Silver\n",
       "  44472    Silver\n",
       "  44473      Gold\n",
       "  44474      Gold\n",
       "  44475      Gold\n",
       "  44476    Silver\n",
       "  44477    Silver\n",
       "  44478    Silver\n",
       "            ...  \n",
       "  56879      Gold\n",
       "  56880    Silver\n",
       "  56881    Silver\n",
       "  56882    Silver\n",
       "  56883    Silver\n",
       "  56884      Gold\n",
       "  56885    Silver\n",
       "  56886    Silver\n",
       "  56887      Gold\n",
       "  56888    Silver\n",
       "  56889    Silver\n",
       "  56890    Silver\n",
       "  56891      Gold\n",
       "  56892      Gold\n",
       "  56893      Gold\n",
       "  56894      Gold\n",
       "  56895    Silver\n",
       "  56896    Silver\n",
       "  56897    Silver\n",
       "  56898    Silver\n",
       "  56899    Silver\n",
       "  56900    Silver\n",
       "  56901    Silver\n",
       "  56902    Silver\n",
       "  56903    Silver\n",
       "  56904      Gold\n",
       "  56905    Silver\n",
       "  56906    Silver\n",
       "  56907    Silver\n",
       "  56908    Silver\n",
       "  Name: PURCHASED, Length: 335, dtype: object), ('Michigan', 44640    Silver\n",
       "  44641    Silver\n",
       "  44642      Gold\n",
       "  44643      Gold\n",
       "  44644    Silver\n",
       "  44645    Silver\n",
       "  44646      Gold\n",
       "  44647      Gold\n",
       "  44648    Silver\n",
       "  44649    Silver\n",
       "  44650    Silver\n",
       "  44651    Silver\n",
       "  44652    Silver\n",
       "  44653    Silver\n",
       "  44654    Silver\n",
       "  44655      Gold\n",
       "  44656    Silver\n",
       "  44657    Silver\n",
       "  44658    Silver\n",
       "  44659    Silver\n",
       "  44660      Gold\n",
       "  44661    Silver\n",
       "  44662    Silver\n",
       "  44663      Gold\n",
       "  44664      Gold\n",
       "  44665    Silver\n",
       "  44666    Silver\n",
       "  44667      Gold\n",
       "  44668    Silver\n",
       "  44669    Silver\n",
       "            ...  \n",
       "  57071    Silver\n",
       "  57072    Silver\n",
       "  57073    Silver\n",
       "  57074    Silver\n",
       "  57075    Silver\n",
       "  57076    Silver\n",
       "  57077    Silver\n",
       "  57078    Silver\n",
       "  57079    Silver\n",
       "  57080    Silver\n",
       "  57081    Silver\n",
       "  57082      Gold\n",
       "  57083    Silver\n",
       "  57084    Silver\n",
       "  57085      Gold\n",
       "  57086    Silver\n",
       "  57087    Silver\n",
       "  57088    Silver\n",
       "  57089      Gold\n",
       "  57090    Silver\n",
       "  57091      Gold\n",
       "  57092    Silver\n",
       "  57093      Gold\n",
       "  57094      Gold\n",
       "  57095      Gold\n",
       "  57096    Silver\n",
       "  57097      Gold\n",
       "  57098    Silver\n",
       "  57099    Silver\n",
       "  57100    Silver\n",
       "  Name: PURCHASED, Length: 446, dtype: object), ('Minnesota', 595      Silver\n",
       "  596      Silver\n",
       "  597      Silver\n",
       "  598        Gold\n",
       "  599      Silver\n",
       "  600      Silver\n",
       "  601      Silver\n",
       "  602      Silver\n",
       "  603      Silver\n",
       "  604      Silver\n",
       "  605      Silver\n",
       "  606      Silver\n",
       "  607        Gold\n",
       "  608      Silver\n",
       "  609      Silver\n",
       "  610      Silver\n",
       "  611      Silver\n",
       "  612      Silver\n",
       "  613        Gold\n",
       "  614      Silver\n",
       "  615      Silver\n",
       "  616      Silver\n",
       "  617      Silver\n",
       "  618      Silver\n",
       "  619      Silver\n",
       "  620      Silver\n",
       "  621      Silver\n",
       "  622      Silver\n",
       "  623      Silver\n",
       "  624      Silver\n",
       "            ...  \n",
       "  65618      Gold\n",
       "  65619    Silver\n",
       "  65620    Silver\n",
       "  65621    Silver\n",
       "  65622    Silver\n",
       "  65623    Silver\n",
       "  65624    Silver\n",
       "  65625    Silver\n",
       "  65626      Gold\n",
       "  65627    Silver\n",
       "  65628    Silver\n",
       "  65629    Silver\n",
       "  65630    Silver\n",
       "  65631    Silver\n",
       "  65632    Silver\n",
       "  65633    Silver\n",
       "  65634    Silver\n",
       "  65635      Gold\n",
       "  65636      Gold\n",
       "  65637    Silver\n",
       "  65638      Gold\n",
       "  65639    Silver\n",
       "  65640    Silver\n",
       "  65641      Gold\n",
       "  65642    Silver\n",
       "  65643    Silver\n",
       "  65644      Gold\n",
       "  65645      Gold\n",
       "  65646    Silver\n",
       "  65647    Silver\n",
       "  Name: PURCHASED, Length: 2850, dtype: object), ('Mississippi',\n",
       "  20207      Silver\n",
       "  20208        Gold\n",
       "  20209      Silver\n",
       "  20210      Silver\n",
       "  20274      Silver\n",
       "  20339      Silver\n",
       "  20399        Gold\n",
       "  20400        Gold\n",
       "  20401      Silver\n",
       "  20402      Silver\n",
       "  20466      Silver\n",
       "  20467      Silver\n",
       "  20549      Silver\n",
       "  20550      Silver\n",
       "  20551      Silver\n",
       "  20552      Silver\n",
       "  20605      Silver\n",
       "  20606    Platinum\n",
       "  20607        Gold\n",
       "  20608        Gold\n",
       "  20808        Gold\n",
       "  20809        Gold\n",
       "  20810      Silver\n",
       "  20811      Silver\n",
       "  21099      Silver\n",
       "  21100      Silver\n",
       "  21101        Gold\n",
       "  21102      Silver\n",
       "  21103      Silver\n",
       "  21104      Silver\n",
       "             ...   \n",
       "  86703    Platinum\n",
       "  86704      Silver\n",
       "  86705      Silver\n",
       "  86706      Bronze\n",
       "  86707      Bronze\n",
       "  86708      Silver\n",
       "  86709      Silver\n",
       "  86710      Silver\n",
       "  86711        Gold\n",
       "  86712        Gold\n",
       "  86713    Platinum\n",
       "  86714      Silver\n",
       "  86715        Gold\n",
       "  86716        Gold\n",
       "  86717        Gold\n",
       "  86718        Gold\n",
       "  86719      Silver\n",
       "  86720        Gold\n",
       "  86721      Bronze\n",
       "  86722        Gold\n",
       "  86723      Silver\n",
       "  86724        Gold\n",
       "  86725        Gold\n",
       "  86726      Silver\n",
       "  86727        Gold\n",
       "  86728    Platinum\n",
       "  86729      Bronze\n",
       "  86730      Silver\n",
       "  86731        Gold\n",
       "  86732      Silver\n",
       "  Name: PURCHASED, Length: 1956, dtype: object), ('Missouri', 20199      Silver\n",
       "  20200      Silver\n",
       "  20201      Silver\n",
       "  20202      Silver\n",
       "  20203      Silver\n",
       "  20204      Silver\n",
       "  20205      Silver\n",
       "  20206        Gold\n",
       "  20267      Silver\n",
       "  20268        Gold\n",
       "  20269      Silver\n",
       "  20270      Silver\n",
       "  20271        Gold\n",
       "  20272      Silver\n",
       "  20273      Silver\n",
       "  20334      Silver\n",
       "  20335      Silver\n",
       "  20336      Silver\n",
       "  20337      Silver\n",
       "  20338        Gold\n",
       "  20390        Gold\n",
       "  20391        Gold\n",
       "  20392        Gold\n",
       "  20393      Silver\n",
       "  20394      Silver\n",
       "  20395      Silver\n",
       "  20396      Silver\n",
       "  20397      Silver\n",
       "  20398      Silver\n",
       "  20458        Gold\n",
       "             ...   \n",
       "  92852      Bronze\n",
       "  92853        Gold\n",
       "  92854      Silver\n",
       "  92855      Silver\n",
       "  92856        Gold\n",
       "  92857      Silver\n",
       "  92858      Bronze\n",
       "  92859      Bronze\n",
       "  92860      Silver\n",
       "  92861      Silver\n",
       "  92862        Gold\n",
       "  92863      Silver\n",
       "  92864      Silver\n",
       "  92865    Platinum\n",
       "  92866        Gold\n",
       "  92867        Gold\n",
       "  92868    Platinum\n",
       "  92869        Gold\n",
       "  92870      Silver\n",
       "  92871        Gold\n",
       "  92872        Gold\n",
       "  92873        Gold\n",
       "  92874      Bronze\n",
       "  92875      Silver\n",
       "  92876      Silver\n",
       "  92877        Gold\n",
       "  92878      Silver\n",
       "  92879      Silver\n",
       "  92880      Silver\n",
       "  92881      Silver\n",
       "  Name: PURCHASED, Length: 5032, dtype: object), ('Montana', 707        Gold\n",
       "  708      Silver\n",
       "  709      Silver\n",
       "  710      Silver\n",
       "  711        Gold\n",
       "  712      Silver\n",
       "  713      Silver\n",
       "  714      Silver\n",
       "  715        Gold\n",
       "  716      Silver\n",
       "  717      Silver\n",
       "  718      Silver\n",
       "  719      Silver\n",
       "  720        Gold\n",
       "  721      Silver\n",
       "  722        Gold\n",
       "  723      Silver\n",
       "  724      Silver\n",
       "  725        Gold\n",
       "  726      Silver\n",
       "  727      Silver\n",
       "  728      Silver\n",
       "  729        Gold\n",
       "  730      Silver\n",
       "  731      Silver\n",
       "  732        Gold\n",
       "  733      Silver\n",
       "  734        Gold\n",
       "  735      Silver\n",
       "  736      Silver\n",
       "            ...  \n",
       "  65654      Gold\n",
       "  65655      Gold\n",
       "  65656      Gold\n",
       "  65657    Silver\n",
       "  65658      Gold\n",
       "  65659      Gold\n",
       "  65660    Silver\n",
       "  65661    Silver\n",
       "  65662      Gold\n",
       "  65663    Silver\n",
       "  65664      Gold\n",
       "  65665    Silver\n",
       "  65666      Gold\n",
       "  65667    Silver\n",
       "  65668      Gold\n",
       "  65669    Silver\n",
       "  65670    Silver\n",
       "  65671    Silver\n",
       "  65672    Silver\n",
       "  65673      Gold\n",
       "  65674    Silver\n",
       "  65675      Gold\n",
       "  65676    Silver\n",
       "  65677    Silver\n",
       "  65678    Silver\n",
       "  65679    Silver\n",
       "  65680      Gold\n",
       "  65681    Silver\n",
       "  65682      Gold\n",
       "  65683    Silver\n",
       "  Name: PURCHASED, Length: 1158, dtype: object), ('Nebraska', 20211      Silver\n",
       "  20340      Silver\n",
       "  20341      Silver\n",
       "  20342      Silver\n",
       "  20343      Silver\n",
       "  20403      Silver\n",
       "  20404      Silver\n",
       "  20405        Gold\n",
       "  20468      Silver\n",
       "  20469        Gold\n",
       "  20470        Gold\n",
       "  20471      Silver\n",
       "  20472      Silver\n",
       "  20473      Silver\n",
       "  20553      Silver\n",
       "  20554      Silver\n",
       "  20555      Silver\n",
       "  20609    Platinum\n",
       "  20610      Silver\n",
       "  20611      Silver\n",
       "  20612        Gold\n",
       "  20613        Gold\n",
       "  20614        Gold\n",
       "  20615      Silver\n",
       "  20616      Bronze\n",
       "  20617      Silver\n",
       "  20812      Silver\n",
       "  20813        Gold\n",
       "  20814      Silver\n",
       "  20815      Bronze\n",
       "             ...   \n",
       "  87005      Silver\n",
       "  87006      Silver\n",
       "  87007      Silver\n",
       "  87008      Silver\n",
       "  87009      Silver\n",
       "  87010      Silver\n",
       "  87011      Bronze\n",
       "  87012      Silver\n",
       "  87013      Silver\n",
       "  87014      Silver\n",
       "  87015      Bronze\n",
       "  87016      Silver\n",
       "  87017      Bronze\n",
       "  87018      Silver\n",
       "  87019      Silver\n",
       "  87020      Silver\n",
       "  87021    Platinum\n",
       "  87022        Gold\n",
       "  87023      Silver\n",
       "  87024        Gold\n",
       "  87025        Gold\n",
       "  87026      Silver\n",
       "  87027      Bronze\n",
       "  87028        Gold\n",
       "  87029      Silver\n",
       "  87030      Silver\n",
       "  87031        Gold\n",
       "  87032      Silver\n",
       "  87033      Bronze\n",
       "  87034      Bronze\n",
       "  Name: PURCHASED, Length: 2464, dtype: object), ('Nevada', 847      Silver\n",
       "  848      Silver\n",
       "  849        Gold\n",
       "  850      Silver\n",
       "  851      Silver\n",
       "  852        Gold\n",
       "  853        Gold\n",
       "  854      Silver\n",
       "  855      Silver\n",
       "  856      Silver\n",
       "  857        Gold\n",
       "  858      Silver\n",
       "  859      Silver\n",
       "  860      Silver\n",
       "  861      Silver\n",
       "  862      Silver\n",
       "  863      Silver\n",
       "  864        Gold\n",
       "  865      Silver\n",
       "  866      Silver\n",
       "  867      Silver\n",
       "  868      Silver\n",
       "  869        Gold\n",
       "  870      Silver\n",
       "  871      Silver\n",
       "  872        Gold\n",
       "  873      Silver\n",
       "  874      Silver\n",
       "  875      Silver\n",
       "  1956     Silver\n",
       "            ...  \n",
       "  63526    Silver\n",
       "  63527    Silver\n",
       "  63528    Silver\n",
       "  63529    Silver\n",
       "  63530    Silver\n",
       "  63531    Silver\n",
       "  63532    Silver\n",
       "  63533    Silver\n",
       "  63534      Gold\n",
       "  63535      Gold\n",
       "  63536    Silver\n",
       "  64650    Silver\n",
       "  64651    Silver\n",
       "  64652    Silver\n",
       "  64653      Gold\n",
       "  64654    Silver\n",
       "  64655    Silver\n",
       "  64656    Silver\n",
       "  64657    Silver\n",
       "  64658    Silver\n",
       "  64659      Gold\n",
       "  64660    Silver\n",
       "  64661      Gold\n",
       "  64662    Silver\n",
       "  64663    Silver\n",
       "  64664    Silver\n",
       "  64665      Gold\n",
       "  64666      Gold\n",
       "  64667    Silver\n",
       "  64668    Silver\n",
       "  Name: PURCHASED, Length: 708, dtype: object), ('New Hampshire',\n",
       "  44856      Gold\n",
       "  44857      Gold\n",
       "  44858    Silver\n",
       "  44859      Gold\n",
       "  44860    Silver\n",
       "  44861    Silver\n",
       "  44862    Silver\n",
       "  44863    Silver\n",
       "  44864    Silver\n",
       "  44865      Gold\n",
       "  44866    Silver\n",
       "  44867      Gold\n",
       "  44868    Silver\n",
       "  44869      Gold\n",
       "  44870    Silver\n",
       "  44871    Silver\n",
       "  44872    Silver\n",
       "  44873      Gold\n",
       "  44874    Silver\n",
       "  44875    Silver\n",
       "  44876      Gold\n",
       "  44877    Silver\n",
       "  44878    Silver\n",
       "  44879    Silver\n",
       "  44880    Silver\n",
       "  44881      Gold\n",
       "  44882      Gold\n",
       "  44883    Silver\n",
       "  45422    Silver\n",
       "  45476    Silver\n",
       "            ...  \n",
       "  55393      Gold\n",
       "  57187    Silver\n",
       "  57188    Silver\n",
       "  57189      Gold\n",
       "  57190    Silver\n",
       "  57191      Gold\n",
       "  57192    Silver\n",
       "  57193    Silver\n",
       "  57194    Silver\n",
       "  57195    Silver\n",
       "  57196    Silver\n",
       "  57197    Silver\n",
       "  57198    Silver\n",
       "  57199    Silver\n",
       "  57200    Silver\n",
       "  57201    Silver\n",
       "  57202    Silver\n",
       "  57203    Silver\n",
       "  57204    Silver\n",
       "  57205    Silver\n",
       "  57206      Gold\n",
       "  57207    Silver\n",
       "  57208      Gold\n",
       "  57209    Silver\n",
       "  57210    Silver\n",
       "  57211    Silver\n",
       "  57212    Silver\n",
       "  57213    Silver\n",
       "  57214      Gold\n",
       "  57215    Silver\n",
       "  Name: PURCHASED, Length: 106, dtype: object), ('New Jersey', 43259      Gold\n",
       "  43260      Gold\n",
       "  43261    Silver\n",
       "  43262      Gold\n",
       "  43263    Silver\n",
       "  43264    Silver\n",
       "  43265    Silver\n",
       "  43266    Silver\n",
       "  43267      Gold\n",
       "  43268    Silver\n",
       "  43269    Silver\n",
       "  43270    Silver\n",
       "  43271      Gold\n",
       "  43272    Silver\n",
       "  43273    Silver\n",
       "  43274    Silver\n",
       "  43275    Silver\n",
       "  43276    Silver\n",
       "  43277      Gold\n",
       "  43278      Gold\n",
       "  43279    Silver\n",
       "  43280    Silver\n",
       "  43281    Silver\n",
       "  43282    Silver\n",
       "  43283      Gold\n",
       "  43284    Silver\n",
       "  43285    Silver\n",
       "  43286    Silver\n",
       "  43287    Silver\n",
       "  43288      Gold\n",
       "            ...  \n",
       "  57231      Gold\n",
       "  57232    Silver\n",
       "  57233      Gold\n",
       "  57234      Gold\n",
       "  57235    Silver\n",
       "  57236    Silver\n",
       "  57237    Silver\n",
       "  57238    Silver\n",
       "  57239    Silver\n",
       "  57240    Silver\n",
       "  57241    Silver\n",
       "  57242    Silver\n",
       "  57243      Gold\n",
       "  57244    Silver\n",
       "  57245    Silver\n",
       "  57246    Silver\n",
       "  57247    Silver\n",
       "  57248    Silver\n",
       "  57249    Silver\n",
       "  57250      Gold\n",
       "  57251    Silver\n",
       "  57252    Silver\n",
       "  57253    Silver\n",
       "  57254      Gold\n",
       "  57255    Silver\n",
       "  57256    Silver\n",
       "  57257    Silver\n",
       "  57258    Silver\n",
       "  57259    Silver\n",
       "  57260      Gold\n",
       "  Name: PURCHASED, Length: 292, dtype: object), ('New Mexico', 799        Gold\n",
       "  800      Silver\n",
       "  801      Silver\n",
       "  802      Silver\n",
       "  803      Silver\n",
       "  804        Gold\n",
       "  805      Silver\n",
       "  806        Gold\n",
       "  807      Silver\n",
       "  808        Gold\n",
       "  809      Silver\n",
       "  810        Gold\n",
       "  811      Silver\n",
       "  812      Silver\n",
       "  813      Silver\n",
       "  814      Silver\n",
       "  815      Silver\n",
       "  816      Silver\n",
       "  817      Silver\n",
       "  818      Silver\n",
       "  819        Gold\n",
       "  820      Silver\n",
       "  821        Gold\n",
       "  822        Gold\n",
       "  823      Silver\n",
       "  824      Silver\n",
       "  825      Silver\n",
       "  826      Silver\n",
       "  827        Gold\n",
       "  828      Silver\n",
       "            ...  \n",
       "  64620      Gold\n",
       "  64621    Silver\n",
       "  64622    Silver\n",
       "  64623    Silver\n",
       "  64624      Gold\n",
       "  64625    Silver\n",
       "  64626    Silver\n",
       "  64627      Gold\n",
       "  64628    Silver\n",
       "  64629    Silver\n",
       "  64630    Silver\n",
       "  64631    Silver\n",
       "  64632    Silver\n",
       "  64633    Silver\n",
       "  64634      Gold\n",
       "  64635    Silver\n",
       "  64636    Silver\n",
       "  64637    Silver\n",
       "  64638      Gold\n",
       "  64639    Silver\n",
       "  64640    Silver\n",
       "  64641    Silver\n",
       "  64642      Gold\n",
       "  64643    Silver\n",
       "  64644      Gold\n",
       "  64645    Silver\n",
       "  64646    Silver\n",
       "  64647    Silver\n",
       "  64648    Silver\n",
       "  64649    Silver\n",
       "  Name: PURCHASED, Length: 1184, dtype: object), ('New York', 43299    Silver\n",
       "  43300    Silver\n",
       "  43301      Gold\n",
       "  43302    Silver\n",
       "  43303    Silver\n",
       "  43304    Silver\n",
       "  43305    Silver\n",
       "  43306    Silver\n",
       "  43307    Silver\n",
       "  43308    Silver\n",
       "  43309    Silver\n",
       "  43310    Silver\n",
       "  43311    Silver\n",
       "  43312    Silver\n",
       "  43313    Silver\n",
       "  43314      Gold\n",
       "  43315    Silver\n",
       "  43316    Silver\n",
       "  43317    Silver\n",
       "  43318      Gold\n",
       "  43319    Silver\n",
       "  43320      Gold\n",
       "  43321      Gold\n",
       "  43322    Silver\n",
       "  43323    Silver\n",
       "  43324      Gold\n",
       "  43325    Silver\n",
       "  43326      Gold\n",
       "  43327    Silver\n",
       "  43328      Gold\n",
       "            ...  \n",
       "  57409    Silver\n",
       "  57410      Gold\n",
       "  57411    Silver\n",
       "  57412    Silver\n",
       "  57413    Silver\n",
       "  57414    Silver\n",
       "  57415    Silver\n",
       "  57416      Gold\n",
       "  57417    Silver\n",
       "  57418      Gold\n",
       "  57419    Silver\n",
       "  57420      Gold\n",
       "  57421    Silver\n",
       "  57422    Silver\n",
       "  57423    Silver\n",
       "  57424    Silver\n",
       "  57425      Gold\n",
       "  57426      Gold\n",
       "  57427      Gold\n",
       "  57428    Silver\n",
       "  57429      Gold\n",
       "  57430    Silver\n",
       "  57431    Silver\n",
       "  57432    Silver\n",
       "  57433    Silver\n",
       "  57434      Gold\n",
       "  57435      Gold\n",
       "  57436    Silver\n",
       "  57437    Silver\n",
       "  57438      Gold\n",
       "  Name: PURCHASED, Length: 1084, dtype: object), ('North Carolina',\n",
       "  44750      Gold\n",
       "  44751    Silver\n",
       "  44752      Gold\n",
       "  44753    Silver\n",
       "  44754    Silver\n",
       "  44755    Silver\n",
       "  44756    Silver\n",
       "  44757    Silver\n",
       "  44758      Gold\n",
       "  44759    Silver\n",
       "  44760    Silver\n",
       "  44761    Silver\n",
       "  44762    Silver\n",
       "  44763      Gold\n",
       "  44764    Silver\n",
       "  44765    Silver\n",
       "  44766    Silver\n",
       "  44767    Silver\n",
       "  44768    Silver\n",
       "  44769      Gold\n",
       "  44770    Silver\n",
       "  44771    Silver\n",
       "  44772    Silver\n",
       "  44773    Silver\n",
       "  44774    Silver\n",
       "  44775    Silver\n",
       "  44776    Silver\n",
       "  44777      Gold\n",
       "  44778    Silver\n",
       "  44779      Gold\n",
       "            ...  \n",
       "  57157      Gold\n",
       "  57158    Silver\n",
       "  57159    Silver\n",
       "  57160    Silver\n",
       "  57161    Silver\n",
       "  57162    Silver\n",
       "  57163    Silver\n",
       "  57164    Silver\n",
       "  57165    Silver\n",
       "  57166      Gold\n",
       "  57167    Silver\n",
       "  57168    Silver\n",
       "  57169    Silver\n",
       "  57170    Silver\n",
       "  57171    Silver\n",
       "  57172    Silver\n",
       "  57173    Silver\n",
       "  57174    Silver\n",
       "  57175    Silver\n",
       "  57176      Gold\n",
       "  57177    Silver\n",
       "  57178    Silver\n",
       "  57179    Silver\n",
       "  57180    Silver\n",
       "  57181    Silver\n",
       "  57182      Gold\n",
       "  57183      Gold\n",
       "  57184      Gold\n",
       "  57185      Gold\n",
       "  57186    Silver\n",
       "  Name: PURCHASED, Length: 413, dtype: object), ('North Dakota',\n",
       "  754      Silver\n",
       "  755      Silver\n",
       "  756      Silver\n",
       "  757        Gold\n",
       "  758      Silver\n",
       "  759        Gold\n",
       "  760        Gold\n",
       "  761      Silver\n",
       "  762      Silver\n",
       "  763      Silver\n",
       "  764      Silver\n",
       "  765        Gold\n",
       "  766        Gold\n",
       "  767      Silver\n",
       "  768      Silver\n",
       "  769      Silver\n",
       "  770      Silver\n",
       "  771      Silver\n",
       "  772      Silver\n",
       "  773        Gold\n",
       "  774      Silver\n",
       "  775      Silver\n",
       "  776      Silver\n",
       "  777      Silver\n",
       "  778      Silver\n",
       "  779      Silver\n",
       "  780      Silver\n",
       "  781        Gold\n",
       "  782      Silver\n",
       "  783        Gold\n",
       "            ...  \n",
       "  64589    Silver\n",
       "  64590    Silver\n",
       "  64591    Silver\n",
       "  64592    Silver\n",
       "  64593    Silver\n",
       "  64594    Silver\n",
       "  64595    Silver\n",
       "  64596    Silver\n",
       "  64597    Silver\n",
       "  64598      Gold\n",
       "  64599    Silver\n",
       "  64600      Gold\n",
       "  64601    Silver\n",
       "  64602    Silver\n",
       "  64603    Silver\n",
       "  64604    Silver\n",
       "  64605      Gold\n",
       "  65684    Silver\n",
       "  65685    Silver\n",
       "  65686    Silver\n",
       "  65687      Gold\n",
       "  65688      Gold\n",
       "  65689    Silver\n",
       "  65690      Gold\n",
       "  65691    Silver\n",
       "  65692    Silver\n",
       "  65693    Silver\n",
       "  65694      Gold\n",
       "  65695      Gold\n",
       "  65696    Silver\n",
       "  Name: PURCHASED, Length: 1125, dtype: object), ('Ohio', 43515      Gold\n",
       "  43516      Gold\n",
       "  43517    Silver\n",
       "  43518    Silver\n",
       "  43519    Silver\n",
       "  43520    Silver\n",
       "  43521    Silver\n",
       "  43522    Silver\n",
       "  43523      Gold\n",
       "  43524    Silver\n",
       "  43525      Gold\n",
       "  43526    Silver\n",
       "  43527      Gold\n",
       "  43528    Silver\n",
       "  43529    Silver\n",
       "  43530    Silver\n",
       "  43531      Gold\n",
       "  43532    Silver\n",
       "  43533    Silver\n",
       "  43534    Silver\n",
       "  43535    Silver\n",
       "  43536      Gold\n",
       "  43537    Silver\n",
       "  43538      Gold\n",
       "  43539    Silver\n",
       "  43540      Gold\n",
       "  43541    Silver\n",
       "  43542    Silver\n",
       "  43543    Silver\n",
       "  43544    Silver\n",
       "            ...  \n",
       "  57533    Silver\n",
       "  57534    Silver\n",
       "  57535      Gold\n",
       "  57536    Silver\n",
       "  57537    Silver\n",
       "  57538    Silver\n",
       "  57539      Gold\n",
       "  57540    Silver\n",
       "  57541    Silver\n",
       "  57542      Gold\n",
       "  57543      Gold\n",
       "  57544    Silver\n",
       "  57545    Silver\n",
       "  57546    Silver\n",
       "  57547    Silver\n",
       "  57548    Silver\n",
       "  57549      Gold\n",
       "  57550    Silver\n",
       "  57551      Gold\n",
       "  57552      Gold\n",
       "  57553      Gold\n",
       "  57554    Silver\n",
       "  57555    Silver\n",
       "  57556    Silver\n",
       "  57557    Silver\n",
       "  57558    Silver\n",
       "  57559    Silver\n",
       "  57560    Silver\n",
       "  57561      Gold\n",
       "  57562    Silver\n",
       "  Name: PURCHASED, Length: 688, dtype: object), ('Oklahoma', 20212      Silver\n",
       "  20213      Silver\n",
       "  20214      Silver\n",
       "  20275      Silver\n",
       "  20276      Silver\n",
       "  20277      Silver\n",
       "  20278      Silver\n",
       "  20344      Silver\n",
       "  20406      Silver\n",
       "  20407      Silver\n",
       "  20408        Gold\n",
       "  20474      Silver\n",
       "  20475      Silver\n",
       "  20556      Silver\n",
       "  20618      Bronze\n",
       "  20619        Gold\n",
       "  20620        Gold\n",
       "  20621        Gold\n",
       "  20622      Silver\n",
       "  20623      Bronze\n",
       "  20624    Platinum\n",
       "  20625        Gold\n",
       "  20626      Silver\n",
       "  20627      Silver\n",
       "  20628    Platinum\n",
       "  20629        Gold\n",
       "  20630      Silver\n",
       "  20631      Bronze\n",
       "  20632      Silver\n",
       "  20816        Gold\n",
       "             ...   \n",
       "  87376      Silver\n",
       "  87377      Silver\n",
       "  87378      Silver\n",
       "  87379      Silver\n",
       "  87380        Gold\n",
       "  87381        Gold\n",
       "  87382      Bronze\n",
       "  87383      Silver\n",
       "  87384      Silver\n",
       "  87385        Gold\n",
       "  87386        Gold\n",
       "  87387        Gold\n",
       "  87388      Bronze\n",
       "  87389    Platinum\n",
       "  87390        Gold\n",
       "  87391      Silver\n",
       "  87392      Silver\n",
       "  87393      Silver\n",
       "  87394      Silver\n",
       "  87395    Platinum\n",
       "  87396      Bronze\n",
       "  87397      Silver\n",
       "  87398        Gold\n",
       "  87399        Gold\n",
       "  87400      Bronze\n",
       "  87401      Silver\n",
       "  87402      Silver\n",
       "  87403      Silver\n",
       "  87404      Silver\n",
       "  87405    Platinum\n",
       "  Name: PURCHASED, Length: 3212, dtype: object), ('Oregon', 876        Gold\n",
       "  877        Gold\n",
       "  878      Silver\n",
       "  879      Silver\n",
       "  880        Gold\n",
       "  881      Silver\n",
       "  882      Silver\n",
       "  883      Silver\n",
       "  884      Silver\n",
       "  885      Silver\n",
       "  886      Silver\n",
       "  887      Silver\n",
       "  888        Gold\n",
       "  889        Gold\n",
       "  890        Gold\n",
       "  891      Silver\n",
       "  892      Silver\n",
       "  893      Silver\n",
       "  894        Gold\n",
       "  895        Gold\n",
       "  896      Silver\n",
       "  897      Silver\n",
       "  898      Silver\n",
       "  899        Gold\n",
       "  900      Silver\n",
       "  901      Silver\n",
       "  902      Silver\n",
       "  903      Silver\n",
       "  904        Gold\n",
       "  905      Silver\n",
       "            ...  \n",
       "  64695    Silver\n",
       "  64696      Gold\n",
       "  64697      Gold\n",
       "  64698      Gold\n",
       "  64699      Gold\n",
       "  64700    Silver\n",
       "  64701    Silver\n",
       "  64702    Silver\n",
       "  64703    Silver\n",
       "  64704      Gold\n",
       "  64705    Silver\n",
       "  64706    Silver\n",
       "  64707      Gold\n",
       "  64708      Gold\n",
       "  64709    Silver\n",
       "  64710    Silver\n",
       "  64711      Gold\n",
       "  64712    Silver\n",
       "  64713    Silver\n",
       "  64714      Gold\n",
       "  64715    Silver\n",
       "  64716    Silver\n",
       "  64717    Silver\n",
       "  64718    Silver\n",
       "  64719    Silver\n",
       "  64720    Silver\n",
       "  64721      Gold\n",
       "  64722    Silver\n",
       "  64723    Silver\n",
       "  64724    Silver\n",
       "  Name: PURCHASED, Length: 1301, dtype: object), ('Pennsylvania',\n",
       "  43670    Silver\n",
       "  43671    Silver\n",
       "  43672      Gold\n",
       "  43673    Silver\n",
       "  43674      Gold\n",
       "  43675    Silver\n",
       "  43676    Silver\n",
       "  43677    Silver\n",
       "  43678      Gold\n",
       "  43679    Silver\n",
       "  43680    Silver\n",
       "  43681    Silver\n",
       "  43682      Gold\n",
       "  43683    Silver\n",
       "  43684    Silver\n",
       "  43685    Silver\n",
       "  43686      Gold\n",
       "  43687    Silver\n",
       "  43688    Silver\n",
       "  43689      Gold\n",
       "  43690    Silver\n",
       "  43691    Silver\n",
       "  43692    Silver\n",
       "  43693    Silver\n",
       "  43694    Silver\n",
       "  43695    Silver\n",
       "  43696      Gold\n",
       "  43697    Silver\n",
       "  43698    Silver\n",
       "  43699    Silver\n",
       "            ...  \n",
       "  57727    Silver\n",
       "  57728    Silver\n",
       "  57729      Gold\n",
       "  57730    Silver\n",
       "  57731    Silver\n",
       "  57732    Silver\n",
       "  57733    Silver\n",
       "  57734      Gold\n",
       "  57735    Silver\n",
       "  57736    Silver\n",
       "  57737    Silver\n",
       "  57738    Silver\n",
       "  57739    Silver\n",
       "  57740    Silver\n",
       "  57741    Silver\n",
       "  57742    Silver\n",
       "  57743    Silver\n",
       "  57744    Silver\n",
       "  57745      Gold\n",
       "  57746    Silver\n",
       "  57747    Silver\n",
       "  57748      Gold\n",
       "  57749    Silver\n",
       "  57750    Silver\n",
       "  57751    Silver\n",
       "  57752      Gold\n",
       "  57753    Silver\n",
       "  57754      Gold\n",
       "  57755    Silver\n",
       "  57756    Silver\n",
       "  Name: PURCHASED, Length: 942, dtype: object), ('Rhode Island',\n",
       "  43897    Silver\n",
       "  43898    Silver\n",
       "  43899    Silver\n",
       "  43900    Silver\n",
       "  43901    Silver\n",
       "  43902    Silver\n",
       "  43903    Silver\n",
       "  43904    Silver\n",
       "  45443      Gold\n",
       "  52933    Silver\n",
       "  53604    Silver\n",
       "  53797    Silver\n",
       "  53798    Silver\n",
       "  53986      Gold\n",
       "  54038    Silver\n",
       "  54121    Silver\n",
       "  54255    Silver\n",
       "  55901    Silver\n",
       "  55902    Silver\n",
       "  55903    Silver\n",
       "  55904    Silver\n",
       "  55905    Silver\n",
       "  55906    Silver\n",
       "  57757      Gold\n",
       "  57758      Gold\n",
       "  57759    Silver\n",
       "  57760    Silver\n",
       "  57761    Silver\n",
       "  57762    Silver\n",
       "  57763      Gold\n",
       "  57764    Silver\n",
       "  Name: PURCHASED, dtype: object), ('South Carolina', 43905    Silver\n",
       "  43906    Silver\n",
       "  43907    Silver\n",
       "  43908      Gold\n",
       "  43909      Gold\n",
       "  43910    Silver\n",
       "  43911    Silver\n",
       "  43912    Silver\n",
       "  43913    Silver\n",
       "  43914      Gold\n",
       "  43915      Gold\n",
       "  43916    Silver\n",
       "  43917    Silver\n",
       "  43918      Gold\n",
       "  43919      Gold\n",
       "  43920    Silver\n",
       "  43921    Silver\n",
       "  43922    Silver\n",
       "  43923      Gold\n",
       "  43924    Silver\n",
       "  43925    Silver\n",
       "  43926    Silver\n",
       "  43927      Gold\n",
       "  43928    Silver\n",
       "  43929    Silver\n",
       "  43930      Gold\n",
       "  43931    Silver\n",
       "  43932      Gold\n",
       "  43933      Gold\n",
       "  43934    Silver\n",
       "            ...  \n",
       "  57786      Gold\n",
       "  57787      Gold\n",
       "  57788    Silver\n",
       "  57789    Silver\n",
       "  57790      Gold\n",
       "  57791      Gold\n",
       "  57792    Silver\n",
       "  57793    Silver\n",
       "  57794    Silver\n",
       "  57795    Silver\n",
       "  57796    Silver\n",
       "  57797    Silver\n",
       "  57798    Silver\n",
       "  57799    Silver\n",
       "  57800    Silver\n",
       "  57801      Gold\n",
       "  57802      Gold\n",
       "  57803    Silver\n",
       "  57804      Gold\n",
       "  57805    Silver\n",
       "  57806    Silver\n",
       "  57807    Silver\n",
       "  57808    Silver\n",
       "  57809    Silver\n",
       "  57810    Silver\n",
       "  57811      Gold\n",
       "  57812      Gold\n",
       "  57813      Gold\n",
       "  57814      Gold\n",
       "  57815      Gold\n",
       "  Name: PURCHASED, Length: 205, dtype: object), ('South Dakota',\n",
       "  922      Silver\n",
       "  923      Silver\n",
       "  924      Silver\n",
       "  925      Silver\n",
       "  926      Silver\n",
       "  927      Silver\n",
       "  928      Silver\n",
       "  929      Silver\n",
       "  930      Silver\n",
       "  931        Gold\n",
       "  932        Gold\n",
       "  933      Silver\n",
       "  934      Silver\n",
       "  935      Silver\n",
       "  936        Gold\n",
       "  937      Silver\n",
       "  938      Silver\n",
       "  939      Silver\n",
       "  940        Gold\n",
       "  941        Gold\n",
       "  942      Silver\n",
       "  943      Silver\n",
       "  944      Silver\n",
       "  945      Silver\n",
       "  946      Silver\n",
       "  947      Silver\n",
       "  948      Silver\n",
       "  949      Silver\n",
       "  950      Silver\n",
       "  951        Gold\n",
       "            ...  \n",
       "  64733      Gold\n",
       "  64734    Silver\n",
       "  64735    Silver\n",
       "  64736    Silver\n",
       "  64737    Silver\n",
       "  64738      Gold\n",
       "  64739    Silver\n",
       "  64740    Silver\n",
       "  64741    Silver\n",
       "  64742      Gold\n",
       "  64743      Gold\n",
       "  64744    Silver\n",
       "  64745    Silver\n",
       "  64746    Silver\n",
       "  64747    Silver\n",
       "  64748    Silver\n",
       "  64749      Gold\n",
       "  64750      Gold\n",
       "  64751    Silver\n",
       "  64752      Gold\n",
       "  64753    Silver\n",
       "  64754      Gold\n",
       "  64755    Silver\n",
       "  64756    Silver\n",
       "  64757    Silver\n",
       "  64758    Silver\n",
       "  64759    Silver\n",
       "  64760    Silver\n",
       "  64761      Gold\n",
       "  64762      Gold\n",
       "  Name: PURCHASED, Length: 1082, dtype: object), ('Tennessee',\n",
       "  20215        Gold\n",
       "  20279        Gold\n",
       "  20280      Silver\n",
       "  20281      Silver\n",
       "  20282      Silver\n",
       "  20283      Silver\n",
       "  20345      Silver\n",
       "  20346      Silver\n",
       "  20347        Gold\n",
       "  20348      Silver\n",
       "  20349      Silver\n",
       "  20350      Silver\n",
       "  20351      Silver\n",
       "  20409      Silver\n",
       "  20410      Silver\n",
       "  20411      Silver\n",
       "  20476        Gold\n",
       "  20477      Silver\n",
       "  20557      Silver\n",
       "  20558        Gold\n",
       "  20559      Silver\n",
       "  20560      Silver\n",
       "  20561      Silver\n",
       "  20562      Silver\n",
       "  20633      Silver\n",
       "  20634      Bronze\n",
       "  20635    Platinum\n",
       "  20636        Gold\n",
       "  20637      Silver\n",
       "  20638      Bronze\n",
       "             ...   \n",
       "  87765      Silver\n",
       "  87766      Silver\n",
       "  87767      Silver\n",
       "  87768      Silver\n",
       "  87769        Gold\n",
       "  87770        Gold\n",
       "  87771        Gold\n",
       "  87772        Gold\n",
       "  87773      Bronze\n",
       "  87774        Gold\n",
       "  87775      Bronze\n",
       "  87776      Bronze\n",
       "  87777    Platinum\n",
       "  87778      Silver\n",
       "  87779    Platinum\n",
       "  87780      Bronze\n",
       "  87781      Silver\n",
       "  87782      Bronze\n",
       "  87783      Bronze\n",
       "  87784      Bronze\n",
       "  87785        Gold\n",
       "  87786      Silver\n",
       "  87787    Platinum\n",
       "  87788      Bronze\n",
       "  87789        Gold\n",
       "  87790      Silver\n",
       "  87791    Platinum\n",
       "  87792      Silver\n",
       "  87793      Silver\n",
       "  87794      Bronze\n",
       "  Name: PURCHASED, Length: 3154, dtype: object), ('Texas', 962        Silver\n",
       "  963        Silver\n",
       "  964          Gold\n",
       "  965          Gold\n",
       "  966        Silver\n",
       "  967        Silver\n",
       "  968        Silver\n",
       "  2065       Silver\n",
       "  2066       Silver\n",
       "  2067       Silver\n",
       "  2068         Gold\n",
       "  2069       Silver\n",
       "  2070       Silver\n",
       "  2071       Silver\n",
       "  2072       Silver\n",
       "  2073       Silver\n",
       "  2074       Silver\n",
       "  2075       Silver\n",
       "  2076       Silver\n",
       "  3172         Gold\n",
       "  3173       Silver\n",
       "  3174       Silver\n",
       "  3175       Silver\n",
       "  3176       Silver\n",
       "  3177       Silver\n",
       "  3178       Silver\n",
       "  4303       Silver\n",
       "  4304         Gold\n",
       "  4305       Silver\n",
       "  4306       Silver\n",
       "             ...   \n",
       "  88950        Gold\n",
       "  88951        Gold\n",
       "  88952      Bronze\n",
       "  88953      Bronze\n",
       "  88954      Bronze\n",
       "  88955    Platinum\n",
       "  88956      Bronze\n",
       "  88957      Silver\n",
       "  88958      Bronze\n",
       "  88959      Bronze\n",
       "  88960      Silver\n",
       "  88961        Gold\n",
       "  88962      Bronze\n",
       "  88963      Bronze\n",
       "  88964      Silver\n",
       "  88965        Gold\n",
       "  88966        Gold\n",
       "  88967    Platinum\n",
       "  88968        Gold\n",
       "  88969        Gold\n",
       "  88970        Gold\n",
       "  88971        Gold\n",
       "  88972        Gold\n",
       "  88973      Silver\n",
       "  88974        Gold\n",
       "  88975        Gold\n",
       "  88976      Bronze\n",
       "  88977        Gold\n",
       "  88978    Platinum\n",
       "  88979      Silver\n",
       "  Name: PURCHASED, Length: 10410, dtype: object), ('Utah', 969      Silver\n",
       "  970      Silver\n",
       "  971        Gold\n",
       "  972      Silver\n",
       "  973        Gold\n",
       "  974        Gold\n",
       "  975      Silver\n",
       "  976        Gold\n",
       "  977      Silver\n",
       "  978      Silver\n",
       "  979      Silver\n",
       "  980      Silver\n",
       "  981      Silver\n",
       "  982      Silver\n",
       "  983      Silver\n",
       "  984      Silver\n",
       "  985      Silver\n",
       "  986        Gold\n",
       "  987      Silver\n",
       "  988      Silver\n",
       "  989      Silver\n",
       "  990      Silver\n",
       "  991      Silver\n",
       "  992        Gold\n",
       "  993      Silver\n",
       "  994      Silver\n",
       "  995      Silver\n",
       "  2077     Silver\n",
       "  2078       Gold\n",
       "  2079       Gold\n",
       "            ...  \n",
       "  64780      Gold\n",
       "  64781    Silver\n",
       "  64782    Silver\n",
       "  64783    Silver\n",
       "  64784    Silver\n",
       "  64785      Gold\n",
       "  64786      Gold\n",
       "  64787      Gold\n",
       "  64788      Gold\n",
       "  64789      Gold\n",
       "  64790    Silver\n",
       "  64791      Gold\n",
       "  64792    Silver\n",
       "  64793      Gold\n",
       "  64794    Silver\n",
       "  64795    Silver\n",
       "  64796    Silver\n",
       "  64797    Silver\n",
       "  64798      Gold\n",
       "  64799      Gold\n",
       "  64800    Silver\n",
       "  64801    Silver\n",
       "  64802      Gold\n",
       "  64803    Silver\n",
       "  64804    Silver\n",
       "  64805      Gold\n",
       "  64806    Silver\n",
       "  64807    Silver\n",
       "  64808    Silver\n",
       "  64809    Silver\n",
       "  Name: PURCHASED, Length: 984, dtype: object), ('Vermont', 44078    Silver\n",
       "  44079      Gold\n",
       "  44080      Gold\n",
       "  44081    Silver\n",
       "  44082      Gold\n",
       "  44083      Gold\n",
       "  44084      Gold\n",
       "  44085      Gold\n",
       "  44086    Silver\n",
       "  44087    Silver\n",
       "  44088      Gold\n",
       "  44089      Gold\n",
       "  44090    Silver\n",
       "  44091      Gold\n",
       "  44092      Gold\n",
       "  44093    Silver\n",
       "  44094    Silver\n",
       "  44095    Silver\n",
       "  44096    Silver\n",
       "  44097    Silver\n",
       "  44098    Silver\n",
       "  44099    Silver\n",
       "  44100    Silver\n",
       "  44101    Silver\n",
       "  44102    Silver\n",
       "  44103    Silver\n",
       "  44104    Silver\n",
       "  44105    Silver\n",
       "  44106    Silver\n",
       "  44107    Silver\n",
       "            ...  \n",
       "  56519    Silver\n",
       "  56520    Silver\n",
       "  56521    Silver\n",
       "  56522    Silver\n",
       "  57925    Silver\n",
       "  57926    Silver\n",
       "  57927      Gold\n",
       "  57928    Silver\n",
       "  57929    Silver\n",
       "  57930      Gold\n",
       "  57931    Silver\n",
       "  57932    Silver\n",
       "  57933      Gold\n",
       "  57934    Silver\n",
       "  57935      Gold\n",
       "  57936    Silver\n",
       "  57937      Gold\n",
       "  57938      Gold\n",
       "  57939    Silver\n",
       "  57940    Silver\n",
       "  57941    Silver\n",
       "  57942    Silver\n",
       "  57943      Gold\n",
       "  57944      Gold\n",
       "  57945    Silver\n",
       "  57946    Silver\n",
       "  57947    Silver\n",
       "  57948    Silver\n",
       "  57949      Gold\n",
       "  57950    Silver\n",
       "  Name: PURCHASED, Length: 151, dtype: object), ('Virginia', 43961    Silver\n",
       "  43962      Gold\n",
       "  43963      Gold\n",
       "  43964    Silver\n",
       "  43965    Silver\n",
       "  43966      Gold\n",
       "  43967    Silver\n",
       "  43968    Silver\n",
       "  43969    Silver\n",
       "  43970    Silver\n",
       "  43971    Silver\n",
       "  43972    Silver\n",
       "  43973      Gold\n",
       "  43974    Silver\n",
       "  43975    Silver\n",
       "  43976      Gold\n",
       "  43977    Silver\n",
       "  43978      Gold\n",
       "  43979    Silver\n",
       "  43980      Gold\n",
       "  43981    Silver\n",
       "  43982    Silver\n",
       "  43983    Silver\n",
       "  43984    Silver\n",
       "  43985    Silver\n",
       "  43986      Gold\n",
       "  43987    Silver\n",
       "  43988    Silver\n",
       "  43989    Silver\n",
       "  43990    Silver\n",
       "            ...  \n",
       "  57895    Silver\n",
       "  57896    Silver\n",
       "  57897    Silver\n",
       "  57898    Silver\n",
       "  57899    Silver\n",
       "  57900    Silver\n",
       "  57901    Silver\n",
       "  57902    Silver\n",
       "  57903    Silver\n",
       "  57904      Gold\n",
       "  57905    Silver\n",
       "  57906    Silver\n",
       "  57907    Silver\n",
       "  57908      Gold\n",
       "  57909      Gold\n",
       "  57910    Silver\n",
       "  57911    Silver\n",
       "  57912      Gold\n",
       "  57913    Silver\n",
       "  57914      Gold\n",
       "  57915    Silver\n",
       "  57916    Silver\n",
       "  57917    Silver\n",
       "  57918    Silver\n",
       "  57919    Silver\n",
       "  57920      Gold\n",
       "  57921    Silver\n",
       "  57922      Gold\n",
       "  57923    Silver\n",
       "  57924    Silver\n",
       "  Name: PURCHASED, Length: 532, dtype: object), ('Washington', 996      Silver\n",
       "  997      Silver\n",
       "  998      Silver\n",
       "  999        Gold\n",
       "  1000       Gold\n",
       "  1001     Silver\n",
       "  1002     Silver\n",
       "  1003     Silver\n",
       "  1004     Silver\n",
       "  1005       Gold\n",
       "  1006       Gold\n",
       "  1007     Silver\n",
       "  1008       Gold\n",
       "  1009     Silver\n",
       "  1010       Gold\n",
       "  1011     Silver\n",
       "  1012     Silver\n",
       "  1013     Silver\n",
       "  1014     Silver\n",
       "  1015       Gold\n",
       "  1016     Silver\n",
       "  1017       Gold\n",
       "  1018     Silver\n",
       "  1019       Gold\n",
       "  1020     Silver\n",
       "  1021     Silver\n",
       "  1022       Gold\n",
       "  1023     Silver\n",
       "  1024     Silver\n",
       "  1025     Silver\n",
       "            ...  \n",
       "  64850    Silver\n",
       "  64851      Gold\n",
       "  64852      Gold\n",
       "  64853    Silver\n",
       "  64854      Gold\n",
       "  64855    Silver\n",
       "  64856    Silver\n",
       "  64857    Silver\n",
       "  64858    Silver\n",
       "  64859    Silver\n",
       "  64860      Gold\n",
       "  64861    Silver\n",
       "  64862    Silver\n",
       "  64863      Gold\n",
       "  64864      Gold\n",
       "  64865    Silver\n",
       "  64866    Silver\n",
       "  64867    Silver\n",
       "  64868    Silver\n",
       "  64869    Silver\n",
       "  64870    Silver\n",
       "  64871    Silver\n",
       "  64872    Silver\n",
       "  64873    Silver\n",
       "  64874    Silver\n",
       "  64875    Silver\n",
       "  64876      Gold\n",
       "  64877    Silver\n",
       "  64878    Silver\n",
       "  64879    Silver\n",
       "  Name: PURCHASED, Length: 2020, dtype: object), ('West Virginia',\n",
       "  44113      Gold\n",
       "  44114      Gold\n",
       "  44115    Silver\n",
       "  44116      Gold\n",
       "  44117    Silver\n",
       "  44118    Silver\n",
       "  44119    Silver\n",
       "  44120    Silver\n",
       "  44121    Silver\n",
       "  44122    Silver\n",
       "  44123      Gold\n",
       "  44124      Gold\n",
       "  44125    Silver\n",
       "  44126    Silver\n",
       "  44127    Silver\n",
       "  44128    Silver\n",
       "  44129    Silver\n",
       "  44130      Gold\n",
       "  44131      Gold\n",
       "  44132    Silver\n",
       "  44133    Silver\n",
       "  44134      Gold\n",
       "  44135    Silver\n",
       "  44136    Silver\n",
       "  44137    Silver\n",
       "  44138    Silver\n",
       "  44139    Silver\n",
       "  44140    Silver\n",
       "  44141    Silver\n",
       "  44142    Silver\n",
       "            ...  \n",
       "  57992    Silver\n",
       "  57993    Silver\n",
       "  57994      Gold\n",
       "  57995    Silver\n",
       "  57996      Gold\n",
       "  57997    Silver\n",
       "  57998    Silver\n",
       "  57999    Silver\n",
       "  58000    Silver\n",
       "  58001    Silver\n",
       "  58002    Silver\n",
       "  58003      Gold\n",
       "  58004      Gold\n",
       "  58005    Silver\n",
       "  58006      Gold\n",
       "  58007    Silver\n",
       "  58008    Silver\n",
       "  58009      Gold\n",
       "  58010    Silver\n",
       "  58011    Silver\n",
       "  58012    Silver\n",
       "  58013      Gold\n",
       "  58014    Silver\n",
       "  58015      Gold\n",
       "  58016      Gold\n",
       "  58017      Gold\n",
       "  58018    Silver\n",
       "  58019    Silver\n",
       "  58020    Silver\n",
       "  58021      Gold\n",
       "  Name: PURCHASED, Length: 460, dtype: object), ('Wisconsin', 1067     Silver\n",
       "  1068     Silver\n",
       "  1069     Silver\n",
       "  1070     Silver\n",
       "  1071     Silver\n",
       "  1072     Silver\n",
       "  1073     Silver\n",
       "  1074       Gold\n",
       "  1075       Gold\n",
       "  1076       Gold\n",
       "  1077     Silver\n",
       "  1078       Gold\n",
       "  1079     Silver\n",
       "  1080     Silver\n",
       "  1081     Silver\n",
       "  1082     Silver\n",
       "  1083     Silver\n",
       "  1084     Silver\n",
       "  1085     Silver\n",
       "  1086     Silver\n",
       "  1087     Silver\n",
       "  1088     Silver\n",
       "  1089     Silver\n",
       "  1090     Silver\n",
       "  1091     Silver\n",
       "  1092     Silver\n",
       "  1093     Silver\n",
       "  1094       Gold\n",
       "  1095       Gold\n",
       "  1096     Silver\n",
       "            ...  \n",
       "  64940    Silver\n",
       "  64941      Gold\n",
       "  64942    Silver\n",
       "  64943      Gold\n",
       "  64944    Silver\n",
       "  64945    Silver\n",
       "  64946    Silver\n",
       "  64947    Silver\n",
       "  64948    Silver\n",
       "  64949      Gold\n",
       "  64950    Silver\n",
       "  64951    Silver\n",
       "  64952      Gold\n",
       "  64953    Silver\n",
       "  64954    Silver\n",
       "  64955    Silver\n",
       "  64956    Silver\n",
       "  64957      Gold\n",
       "  64958    Silver\n",
       "  64959    Silver\n",
       "  64960    Silver\n",
       "  64961    Silver\n",
       "  64962    Silver\n",
       "  64963    Silver\n",
       "  64964    Silver\n",
       "  64965    Silver\n",
       "  64966    Silver\n",
       "  64967    Silver\n",
       "  64968    Silver\n",
       "  64969    Silver\n",
       "  Name: PURCHASED, Length: 2462, dtype: object), ('Wyoming', 1153     Silver\n",
       "  1154     Silver\n",
       "  1155     Silver\n",
       "  1156       Gold\n",
       "  1157     Silver\n",
       "  1158     Silver\n",
       "  1159       Gold\n",
       "  1160       Gold\n",
       "  1161     Silver\n",
       "  1162       Gold\n",
       "  1163     Silver\n",
       "  1164     Silver\n",
       "  1165     Silver\n",
       "  1166     Silver\n",
       "  1167     Silver\n",
       "  1168       Gold\n",
       "  1169     Silver\n",
       "  1170     Silver\n",
       "  1171     Silver\n",
       "  1172       Gold\n",
       "  1173       Gold\n",
       "  1174     Silver\n",
       "  2262     Silver\n",
       "  2263     Silver\n",
       "  2264       Gold\n",
       "  2265     Silver\n",
       "  2266     Silver\n",
       "  2267       Gold\n",
       "  2268       Gold\n",
       "  2269     Silver\n",
       "            ...  \n",
       "  63857    Silver\n",
       "  63858      Gold\n",
       "  63859    Silver\n",
       "  63860    Silver\n",
       "  63861    Silver\n",
       "  64970      Gold\n",
       "  64971    Silver\n",
       "  64972    Silver\n",
       "  64973    Silver\n",
       "  64974    Silver\n",
       "  64975    Silver\n",
       "  64976    Silver\n",
       "  64977    Silver\n",
       "  64978    Silver\n",
       "  64979    Silver\n",
       "  64980      Gold\n",
       "  64981    Silver\n",
       "  64982      Gold\n",
       "  64983    Silver\n",
       "  64984    Silver\n",
       "  64985    Silver\n",
       "  64986    Silver\n",
       "  64987    Silver\n",
       "  64988      Gold\n",
       "  64989    Silver\n",
       "  64990    Silver\n",
       "  64991      Gold\n",
       "  64992      Gold\n",
       "  64993    Silver\n",
       "  64994    Silver\n",
       "  Name: PURCHASED, Length: 551, dtype: object)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(group_insurance_by_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>3484</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>754</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>1491</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>2725</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>7474</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>1789</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>6145</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>3605</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>384</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>965</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>5568</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>3037</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>3176</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>413</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>3051</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>335</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>446</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>2850</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>1956</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>5032</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>1158</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>2464</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>708</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>292</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>1184</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>1084</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>413</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>1125</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>688</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>3212</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>1301</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>942</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>1082</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>3154</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>10410</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>984</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>532</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>460</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>2462</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>551</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count unique     top  freq\n",
       "state                                           \n",
       "Alabama                3484      4  Silver  1783\n",
       "Alaska                  754      2  Silver   564\n",
       "Arizona                1491      2  Silver  1084\n",
       "Arkansas               2725      4  Silver  1437\n",
       "California             7474      2  Silver  5523\n",
       "Colorado               1789      2  Silver  1336\n",
       "Connecticut             234      2  Silver   162\n",
       "Delaware                 57      2  Silver    38\n",
       "District of Columbia    139      2  Silver   103\n",
       "Florida                6145      4  Silver  3181\n",
       "Georgia                3605      4  Silver  1917\n",
       "Hawaii                  384      2  Silver   300\n",
       "Idaho                   965      2  Silver   713\n",
       "Illinois               5568      4  Silver  2993\n",
       "Indiana                 508      2  Silver   373\n",
       "Iowa                   3037      2  Silver  2286\n",
       "Kansas                 3176      4  Silver  1694\n",
       "Kentucky                413      2  Silver   291\n",
       "Louisiana              3051      4  Silver  1595\n",
       "Maine                   229      2  Silver   171\n",
       "Maryland                279      2  Silver   213\n",
       "Massachusetts           335      2  Silver   253\n",
       "Michigan                446      2  Silver   327\n",
       "Minnesota              2850      2  Silver  2119\n",
       "Mississippi            1956      4  Silver  1065\n",
       "Missouri               5032      4  Silver  2618\n",
       "Montana                1158      2  Silver   837\n",
       "Nebraska               2464      4  Silver  1313\n",
       "Nevada                  708      2  Silver   515\n",
       "New Hampshire           106      2  Silver    78\n",
       "New Jersey              292      2  Silver   214\n",
       "New Mexico             1184      2  Silver   869\n",
       "New York               1084      2  Silver   782\n",
       "North Carolina          413      2  Silver   308\n",
       "North Dakota           1125      2  Silver   827\n",
       "Ohio                    688      2  Silver   521\n",
       "Oklahoma               3212      4  Silver  1660\n",
       "Oregon                 1301      2  Silver   953\n",
       "Pennsylvania            942      2  Silver   690\n",
       "Rhode Island             31      2  Silver    26\n",
       "South Carolina          205      2  Silver   146\n",
       "South Dakota           1082      2  Silver   779\n",
       "Tennessee              3154      4  Silver  1654\n",
       "Texas                 10410      4  Silver  5340\n",
       "Utah                    984      2  Silver   726\n",
       "Vermont                 151      2  Silver   108\n",
       "Virginia                532      2  Silver   393\n",
       "Washington             2020      2  Silver  1480\n",
       "West Virginia           460      2  Silver   338\n",
       "Wisconsin              2462      2  Silver  1820\n",
       "Wyoming                 551      2  Silver   405"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_insurance_by_state.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bd_json = joined_bd_df.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('basic_decision_combined.json', 'w') as f:\n",
    "#     f.write(bd_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "for item in list(group_insurance_by_state)[:10]:\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(group_insurance_by_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_series = pd.Series(list(group_insurance_by_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (Alabama, [Gold, Silver, Silver, Silver, Silve...\n",
       "1     (Alaska, [Silver, Silver, Gold, Silver, Gold, ...\n",
       "2     (Arizona, [Silver, Gold, Gold, Silver, Silver,...\n",
       "3     (Arkansas, [Silver, Gold, Silver, Gold, Silver...\n",
       "4     (California, [Silver, Silver, Silver, Silver, ...\n",
       "5     (Colorado, [Gold, Silver, Silver, Silver, Gold...\n",
       "6     (Connecticut, [Silver, Silver, Gold, Gold, Gol...\n",
       "7     (Delaware, [Silver, Silver, Silver, Silver, Go...\n",
       "8     (District of Columbia, [Silver, Gold, Gold, Si...\n",
       "9     (Florida, [Silver, Gold, Silver, Silver, Silve...\n",
       "10    (Georgia, [Silver, Silver, Gold, Silver, Gold,...\n",
       "11    (Hawaii, [Silver, Silver, Silver, Silver, Silv...\n",
       "12    (Idaho, [Silver, Silver, Gold, Gold, Silver, S...\n",
       "13    (Illinois, [Silver, Silver, Gold, Silver, Silv...\n",
       "14    (Indiana, [Silver, Silver, Silver, Gold, Gold,...\n",
       "15    (Iowa, [Silver, Silver, Silver, Gold, Silver, ...\n",
       "16    (Kansas, [Silver, Gold, Silver, Silver, Silver...\n",
       "17    (Kentucky, [Silver, Gold, Silver, Gold, Silver...\n",
       "18    (Louisiana, [Silver, Silver, Gold, Gold, Silve...\n",
       "19    (Maine, [Silver, Silver, Gold, Silver, Silver,...\n",
       "20    (Maryland, [Gold, Gold, Gold, Gold, Silver, Si...\n",
       "21    (Massachusetts, [Gold, Silver, Gold, Silver, G...\n",
       "22    (Michigan, [Silver, Silver, Gold, Gold, Silver...\n",
       "23    (Minnesota, [Silver, Silver, Silver, Gold, Sil...\n",
       "24    (Mississippi, [Silver, Gold, Silver, Silver, S...\n",
       "25    (Missouri, [Silver, Silver, Silver, Silver, Si...\n",
       "26    (Montana, [Gold, Silver, Silver, Silver, Gold,...\n",
       "27    (Nebraska, [Silver, Silver, Silver, Silver, Si...\n",
       "28    (Nevada, [Silver, Silver, Gold, Silver, Silver...\n",
       "29    (New Hampshire, [Gold, Gold, Silver, Gold, Sil...\n",
       "30    (New Jersey, [Gold, Gold, Silver, Gold, Silver...\n",
       "31    (New Mexico, [Gold, Silver, Silver, Silver, Si...\n",
       "32    (New York, [Silver, Silver, Gold, Silver, Silv...\n",
       "33    (North Carolina, [Gold, Silver, Gold, Silver, ...\n",
       "34    (North Dakota, [Silver, Silver, Silver, Gold, ...\n",
       "35    (Ohio, [Gold, Gold, Silver, Silver, Silver, Si...\n",
       "36    (Oklahoma, [Silver, Silver, Silver, Silver, Si...\n",
       "37    (Oregon, [Gold, Gold, Silver, Silver, Gold, Si...\n",
       "38    (Pennsylvania, [Silver, Silver, Gold, Silver, ...\n",
       "39    (Rhode Island, [Silver, Silver, Silver, Silver...\n",
       "40    (South Carolina, [Silver, Silver, Silver, Gold...\n",
       "41    (South Dakota, [Silver, Silver, Silver, Silver...\n",
       "42    (Tennessee, [Gold, Gold, Silver, Silver, Silve...\n",
       "43    (Texas, [Silver, Silver, Gold, Gold, Silver, S...\n",
       "44    (Utah, [Silver, Silver, Gold, Silver, Gold, Go...\n",
       "45    (Vermont, [Silver, Gold, Gold, Silver, Gold, G...\n",
       "46    (Virginia, [Silver, Gold, Gold, Silver, Silver...\n",
       "47    (Washington, [Silver, Silver, Silver, Gold, Go...\n",
       "48    (West Virginia, [Gold, Gold, Silver, Gold, Sil...\n",
       "49    (Wisconsin, [Silver, Silver, Silver, Silver, S...\n",
       "50    (Wyoming, [Silver, Silver, Silver, Gold, Silve...\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Series in module pandas.core.series object:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.strings.StringAccessorMixin, pandas.core.generic.NDFrame)\n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, dict, or scalar value\n",
      " |      Contains data stored in Series\n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex(len(data)) if not provided. If both a dict and index\n",
      " |      sequence are used, the index will override the keys found in the\n",
      " |      dict.\n",
      " |  dtype : numpy.dtype or None\n",
      " |      If None, dtype will be inferred\n",
      " |  copy : boolean, default False\n",
      " |      Copy input data\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.strings.StringAccessorMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__ = wrapper(left, right, name='__add__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5bf28>)\n",
      " |  \n",
      " |  __and__ = wrapper(self, other)\n",
      " |  \n",
      " |  __array__(self, result=None)\n",
      " |      the array interface, return my values\n",
      " |  \n",
      " |  __array_prepare__(self, result, context=None)\n",
      " |      Gets called prior to a ufunc\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |      Gets called after a ufunc\n",
      " |  \n",
      " |  __div__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c6a8>)\n",
      " |  \n",
      " |  __divmod__ = wrapper(left, right, name='__divmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a618c8>)\n",
      " |  \n",
      " |  __eq__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __float__ = wrapper(self)\n",
      " |  \n",
      " |  __floordiv__ = wrapper(left, right, name='__floordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c840>)\n",
      " |  \n",
      " |  __ge__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __int__ = wrapper(self)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      provide iteration over the values of the Series\n",
      " |      box values if necessary\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __le__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      return the length of the Series\n",
      " |  \n",
      " |  __long__ = wrapper(self)\n",
      " |  \n",
      " |  __lt__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __mod__ = wrapper(left, right, name='__mod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c9d8>)\n",
      " |  \n",
      " |  __mul__ = wrapper(left, right, name='__mul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c510>)\n",
      " |  \n",
      " |  __ne__ = wrapper(self, other, axis=None)\n",
      " |  \n",
      " |  __or__ = wrapper(self, other)\n",
      " |  \n",
      " |  __pow__ = wrapper(left, right, name='__pow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5cb70>)\n",
      " |  \n",
      " |  __radd__ = wrapper(left, right, name='__radd__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c1e0>)\n",
      " |  \n",
      " |  __rand__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rdiv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5e1e0>)\n",
      " |  \n",
      " |  __rfloordiv__ = wrapper(left, right, name='__rfloordiv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5e400>)\n",
      " |  \n",
      " |  __rmod__ = wrapper(left, right, name='__rmod__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5e840>)\n",
      " |  \n",
      " |  __rmul__ = wrapper(left, right, name='__rmul__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5cd08>)\n",
      " |  \n",
      " |  __ror__ = wrapper(self, other)\n",
      " |  \n",
      " |  __rpow__ = wrapper(left, right, name='__rpow__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5e620>)\n",
      " |  \n",
      " |  __rsub__ = wrapper(left, right, name='__rsub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5cf28>)\n",
      " |  \n",
      " |  __rtruediv__ = wrapper(left, right, name='__rtruediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5e1e0>)\n",
      " |  \n",
      " |  __rxor__ = wrapper(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__ = wrapper(left, right, name='__sub__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c378>)\n",
      " |  \n",
      " |  __truediv__ = wrapper(left, right, name='__truediv__', na_op=<function _arith_method_SERIES.<locals>.na_op at 0x119a5c6a8>)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__ = wrapper(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using callable, string, dict, or list of string/callables\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      " |      default behavior is applying the function along axis=0\n",
      " |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      " |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      " |      \n",
      " |      agg is an alias for aggregate. Use it.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = Series(np.random.randn(10))\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      -1.3018049988556679\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   -1.301805\n",
      " |      max    1.127688\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.apply\n",
      " |      pandas.Series.transform\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two object on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0, 'index'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0, 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : scalar or Series (if level specified)\n",
      " |  \n",
      " |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : scalar or Series (if level specified)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      \n",
      " |          .. versionadded: 0.19.0\n",
      " |      \n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise Exception on creating index with duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3,4,5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series. Can be ufunc (a NumPy function\n",
      " |      that applies to the entire Series) or a Python function that only works\n",
      " |      on single values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      convert_dtype : boolean, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the value\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series or DataFrame if func returns a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations\n",
      " |      Series.agg: only perform aggregating type operations\n",
      " |      Series.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> series = pd.Series([20, 21, 12], index=['London',\n",
      " |      ... 'New York','Helsinki'])\n",
      " |      >>> series\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x**2\n",
      " |      >>> series.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> series.apply(lambda x: x**2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x-custom_value\n",
      " |      \n",
      " |      >>> series.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x+=kwargs[month]\n",
      " |      ...         return x\n",
      " |      \n",
      " |      >>> series.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> series.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argmax = idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |  \n",
      " |  argmin = idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int (can only be zero)\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm\n",
      " |      order : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      argsorted : Series, with -1 indicated where nan values are present\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Lag-N autocorrelation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      autocorr : float\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right. NA values\n",
      " |      will be treated as False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar\n",
      " |          Left boundary\n",
      " |      right : scalar\n",
      " |          Right boundary\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_between : Series\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=nan)\n",
      " |      Perform elementwise binary operation on two Series using given function\n",
      " |      with optional fill value when an index is missing from one Series or\n",
      " |      the other\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      func : function\n",
      " |      fill_value : scalar value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values\n",
      " |      first. Result index will be the union of the two indexes\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : scalar or Series (if level specified)\n",
      " |  \n",
      " |  compress(self, condition, *args, **kwargs)\n",
      " |      Return selected slices of an array along given axis as a Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.compress\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correlation : float\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nobs : int or Series (if level specified)\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      covariance : float\n",
      " |      \n",
      " |      Normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative max over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : scalar\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : Series\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or inner-product with Series\n",
      " |      objects\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : scalar or Series\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : boolean, default False\n",
      " |      If True, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : Series\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, **kwargs)\n",
      " |      Return Series without null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      valid : Series\n",
      " |      inplace : boolean, default False\n",
      " |          Do operation in place.\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Return boolean Series denoting duplicate values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, freq=None, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      freq : None or string alias / date offset object, default=None (DEPRECATED)\n",
      " |          Frequency to conform to before computing statistic\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |  \n",
      " |  expanding(self, min_periods=1, freq=None, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      freq : string or DateOffset object, optional (default None) (DEPRECATED)\n",
      " |          Frequency to conform the data to before computing the statistic.\n",
      " |          Specified as a frequency string or DateOffset object.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0, 'index'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : Series\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return label for first non-NA/null value\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  get_value(self, label, takeable=False)\n",
      " |      Quickly retrieve single value at passed index label\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : label\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions); is a view\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, **kwds)\n",
      " |      Draw histogram of the input series using matplotlib\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca()\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      figsize : tuple, default None\n",
      " |          figure size in inches by default\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : keywords\n",
      " |          To be passed to the actual plotting function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See matplotlib documentation online for more on this\n",
      " |  \n",
      " |  idxmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of maximum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Index of maximum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmax\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  idxmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Index of first occurrence of minimum of values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Index of minimum of values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.idxmin\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return a boolean :class:`~pandas.Series` showing whether each element\n",
      " |      in the :class:`~pandas.Series` is exactly contained in the passed\n",
      " |      sequence of ``values``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          ``list`` of one element.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |          Support for values as a set\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      isin : Series (bool dtype)\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If ``values`` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.isin\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series(list('abc'))\n",
      " |      >>> s.isin(['a', 'c', 'e'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('a')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['a'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Alias for index\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return label for last non-NA/null value\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series using input correspondence (which can be\n",
      " |      a dict, Series, or function)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, dict, or Series\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |          same index as caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Map inputs to outputs (both of type `Series`)\n",
      " |      \n",
      " |      >>> x = pd.Series([1,2,3], index=['one', 'two', 'three'])\n",
      " |      >>> x\n",
      " |      one      1\n",
      " |      two      2\n",
      " |      three    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> y = pd.Series(['foo', 'bar', 'baz'], index=[1,2,3])\n",
      " |      >>> y\n",
      " |      1    foo\n",
      " |      2    bar\n",
      " |      3    baz\n",
      " |      \n",
      " |      >>> x.map(y)\n",
      " |      one   foo\n",
      " |      two   bar\n",
      " |      three baz\n",
      " |      \n",
      " |      If `arg` is a dictionary, return a new Series with values converted\n",
      " |      according to the dictionary's mapping:\n",
      " |      \n",
      " |      >>> z = {1: 'A', 2: 'B', 3: 'C'}\n",
      " |      \n",
      " |      >>> x.map(z)\n",
      " |      one   A\n",
      " |      two   B\n",
      " |      three C\n",
      " |      \n",
      " |      Use na_action to control whether NA values are affected by the mapping\n",
      " |      function.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, np.nan])\n",
      " |      \n",
      " |      >>> s2 = s.map('this is a string {}'.format, na_action=None)\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3    this is a string nan\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s3 = s.map('this is a string {}'.format, na_action='ignore')\n",
      " |      0    this is a string 1.0\n",
      " |      1    this is a string 2.0\n",
      " |      2    this is a string 3.0\n",
      " |      3                     NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply: For applying more complex functions on a Series\n",
      " |      DataFrame.apply: Apply a function row-/column-wise\n",
      " |      DataFrame.applymap: Apply a function elementwise on a whole DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When `arg` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``:\n",
      " |      \n",
      " |      >>> from collections import Counter\n",
      " |      >>> counter = Counter()\n",
      " |      >>> counter['bar'] += 1\n",
      " |      >>> y.map(counter)\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Memory usage of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool\n",
      " |          Specifies whether to include memory usage of Series index\n",
      " |      deep : bool\n",
      " |          Introspect the data deeply, interrogate\n",
      " |          `object` dtypes for system-level memory consumption\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar bytes of memory consumed\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array if deep=False\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : scalar or Series (if level specified)\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |  \n",
      " |  mode(self)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : Series (sorted)\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many descending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      top_n : Series\n",
      " |          The n largest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nlargest(10)  # only sorts up to the N requested\n",
      " |      219921    4.644710\n",
      " |      82124     4.608745\n",
      " |      421689    4.564644\n",
      " |      425277    4.447014\n",
      " |      718691    4.414137\n",
      " |      43154     4.403520\n",
      " |      283187    4.313922\n",
      " |      595519    4.273635\n",
      " |      503969    4.250236\n",
      " |      121637    4.240952\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      Return the indices of the elements that are non-zero\n",
      " |      \n",
      " |      This method is equivalent to calling `numpy.nonzero` on the\n",
      " |      series data. For compatability with NumPy, the return value is\n",
      " |      the same (a tuple with an array of indices for each dimension),\n",
      " |      but it will always be a one-item tuple because series only have\n",
      " |      one dimension.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 3, 0, 4])\n",
      " |      >>> s.nonzero()\n",
      " |      (array([1, 3]),)\n",
      " |      >>> s.iloc[s.nonzero()[0]]\n",
      " |      1    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.nonzero\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Return this many ascending sorted values\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bottom_n : Series\n",
      " |          The n smallest values in the Series, in sorted order\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> s = pd.Series(np.random.randn(10**6))\n",
      " |      >>> s.nsmallest(10)  # only sorts up to the N requested\n",
      " |      288532   -4.954580\n",
      " |      732345   -4.835960\n",
      " |      64803    -4.812550\n",
      " |      446457   -4.609998\n",
      " |      501225   -4.483945\n",
      " |      669476   -4.472935\n",
      " |      973615   -4.401699\n",
      " |      621279   -4.355126\n",
      " |      773916   -4.347355\n",
      " |      359919   -4.331927\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : scalar or Series (if level specified)\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  ptp(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Returns the difference between the maximum value and the\n",
      " |                  minimum value in the object. This is the equivalent of the\n",
      " |                  ``numpy.ndarray`` method ``ptp``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ptp : scalar or Series (if level specified)\n",
      " |  \n",
      " |  put(self, *args, **kwargs)\n",
      " |      Applies the `put` method to its `values` attribute\n",
      " |      if it has one.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.put\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantile : float or Series\n",
      " |          if ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : array-like, optional (can be specified in order, or as\n",
      " |          keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only  applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : Series\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, **kwargs)\n",
      " |      for compatibility with higher dims\n",
      " |  \n",
      " |  rename(self, index=None, **kwargs)\n",
      " |      Alter axes input function or functions. Function / dict values must be\n",
      " |      unique (1-to-1). Labels not contained in a dict / Series will be left\n",
      " |      as-is. Extra labels listed don't throw an error. Alternatively, change\n",
      " |      ``Series.name`` with a scalar value (Series only).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : scalar, list-like, dict-like or function, optional\n",
      " |          Scalar or list-like will alter the ``Series.name`` attribute,\n",
      " |          and raise on DataFrame or Panel.\n",
      " |          dict-like or functions are transformations to apply to\n",
      " |          that axis' values\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new Series. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series (new object)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.NDFrame.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\") # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(2)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      TypeError: 'int' object is not callable\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      " |         a  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order. May not drop or duplicate\n",
      " |      levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order.\n",
      " |             (reference level by number or key)\n",
      " |      axis : where to reorder levels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, *args, **kwargs)\n",
      " |      Repeat elements of an Series. Refer to `numpy.ndarray.repeat`\n",
      " |      for more information about the `repeats` argument.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.repeat\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Analogous to the :meth:`pandas.DataFrame.reset_index` function, see\n",
      " |      docstring there.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns\n",
      " |      name : object, default None\n",
      " |          The name of the column corresponding to the Series values\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the Series in place (do not create a new object)\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      resetted : DataFrame, or Series if drop == True\n",
      " |  \n",
      " |  reshape(self, *args, **kwargs)\n",
      " |      DEPRECATED: calling this method will raise an error in a\n",
      " |      future release. Please call ``.values.reshape(...)`` instead.\n",
      " |      \n",
      " |      return an ndarray with the values shape\n",
      " |      if the specified shape matches exactly the current shape, then\n",
      " |      return self (for compat)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.reshape\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, freq=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculcations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      freq : string or DateOffset object, optional (default None) (DEPRECATED)\n",
      " |          Frequency to conform the data to before computing the statistic.\n",
      " |          Specified as a frequency string or DateOffset object.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. See the notes below.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicity set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ....:                 index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:02'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:03'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:05'),\n",
      " |      ....:                          pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      The `freq` keyword is used to conform time series data to a specified\n",
      " |      frequency by resampling the data. This is done with the default parameters\n",
      " |      of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int\n",
      " |          Number of decimal places to round to (default: 0).\n",
      " |          If decimals is negative, it specifies the number of\n",
      " |          positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      DataFrame.round\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indices : array of ints\n",
      " |          Array of insertion points with the same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      array([3])\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread', 'cheese', 'milk' ])\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      array([1])     # Note: an array, not a scalar\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'])\n",
      " |      array([1])\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread', 'eggs'])\n",
      " |      array([1, 4])\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread', 'eggs'], side='right')\n",
      " |      array([3, 4])    # eggs before milk\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : scalar or Series (if level specified)\n",
      " |  \n",
      " |  set_value(self, label, value, takeable=False)\n",
      " |      Quickly set single value at passed label. If label is not contained, a\n",
      " |      new object is created with the label placed at the end of the result\n",
      " |      index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Partial indexing with MultiIndex not allowed\n",
      " |      value : object\n",
      " |          Scalar value\n",
      " |      takeable : interpret the index as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      series : Series\n",
      " |          If label is contained, will be reference to calling Series,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0, 'index'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True)\n",
      " |      Sort object by labels (along an axis)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : index to direct sorting\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          if not None, sort on values in specified index level(s)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending vs. descending\n",
      " |      inplace : bool, default False\n",
      " |          if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      " |           Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          if true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values along either axis\n",
      " |      \n",
      " |      .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 'index'}, default 0\n",
      " |          Axis to direct sorting\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : Series\n",
      " |  \n",
      " |  sortlevel(self, level=0, ascending=True, sort_remaining=True)\n",
      " |      DEPRECATED: use :meth:`Series.sort_index`\n",
      " |      \n",
      " |      Sort Series with MultiIndex by chosen level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |      ascending : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index(level=...)\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : scalar or Series (if level specified)\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : Series\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=True, is_copy=False, **kwargs)\n",
      " |      return Series corresponding to requested indices\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      convert : translate negative to positive indices (default)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      numpy.ndarray.take\n",
      " |  \n",
      " |  to_csv(self, path=None, index=True, sep=',', na_rep='', float_format=None, header=False, index_label=None, mode='w', encoding=None, date_format=None, decimal='.')\n",
      " |      Write Series to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      header : boolean, default False\n",
      " |          Write out series name\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      mode : Python write mode, default 'w'\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      date_format: string, default None\n",
      " |          Format string for datetime objects.\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |      Convert Series to {label -> value} dict\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value_dict : dict\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)\n",
      " |      Write Series to an excel sheet\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      data_frame : DataFrame\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with PeriodIndex\n",
      " |  \n",
      " |  to_sparse(self, kind='block', fill_value=None)\n",
      " |      Convert Series to SparseSeries\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kind : {'block', 'integer'}\n",
      " |      fill_value : float, defaults to NaN (missing)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sp : SparseSeries\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None)\n",
      " |      Render a string representation of the Series\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats\n",
      " |          default None\n",
      " |      header: boolean, default True\n",
      " |          Add the Series header (index name)\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True\n",
      " |      length : boolean, default False\n",
      " |          Add the Series length\n",
      " |      dtype : boolean, default False\n",
      " |          Add the Series dtype\n",
      " |      name : boolean, default False\n",
      " |          Add the Series name if not None\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (if not buffer passed)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to datetimeindex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : Series with DatetimeIndex\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Convert Series to a nested list\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values`\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill missing (NaN) values with this value. If both Series are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : Series\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values in the object. Uniques are returned in order\n",
      " |      of appearance, this does NOT sort. Hash table-based unique.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : 1d array-like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unique values.\n",
      " |        - If the input is an Index, the return is an Index\n",
      " |        - If the input is a Categorical dtype, the return is a Categorical\n",
      " |        - If the input is a Series/ndarray, the return will be an ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique\n",
      " |      Index.unique\n",
      " |      Series.unique\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded: 0.18.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...     index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |  \n",
      " |  valid lambda self, inplace=False, **kwargs\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar\n",
      " |      ddof : int, default 1\n",
      " |          degrees of freedom\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_array(arr, index=None, name=None, dtype=None, copy=False, fastpath=False) from builtins.type\n",
      " |  \n",
      " |  from_csv(path, sep=',', parse_dates=True, header=None, index_col=0, encoding=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file (DISCOURAGED, please use :func:`pandas.read_csv`\n",
      " |      instead).\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a time Series.\n",
      " |      \n",
      " |      This method only differs from :func:`pandas.read_csv` in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `header` is ``None`` instead of ``0`` (the first row is not used as\n",
      " |        the column names)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      With :func:`pandas.read_csv`, the option ``squeeze=True`` can be used\n",
      " |      to return a Series like ``from_csv``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      header : int, default None\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      encoding : string, optional\n",
      " |          a string representing the encoding to use if the contents are\n",
      " |          non-ascii, for python versions prior to 3\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  asobject\n",
      " |      return object Series which contains boxed values\n",
      " |      \n",
      " |      *this is an internal non-public method*\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels\n",
      " |  \n",
      " |  dtype\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  dtypes\n",
      " |      return the dtype object of the underlying data\n",
      " |  \n",
      " |  ftype\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  ftypes\n",
      " |      return if the data is sparse|dense\n",
      " |  \n",
      " |  imag\n",
      " |  \n",
      " |  index\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  real\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like\n",
      " |      depending on the dtype\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  cat = <class 'pandas.core.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |      Accessor object for datetimelike properties of the Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.dt.hour\n",
      " |      >>> s.dt.second\n",
      " |      >>> s.dt.quarter\n",
      " |      \n",
      " |      Returns a Series indexed like the original Series.\n",
      " |      Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.SeriesPlotMethods'>\n",
      " |      Series plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.plot.line()\n",
      " |      >>> s.plot.bar()\n",
      " |      >>> s.plot.hist()\n",
      " |      \n",
      " |      Plotting methods can also be accessed by calling the accessor as a method\n",
      " |      with the ``kind`` argument:\n",
      " |      ``s.plot(kind='line')`` is equivalent to ``s.plot.line()``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : boolean, default False\n",
      " |          Sort by values\n",
      " |      na_sentinel: int, default -1\n",
      " |          Value to mark \"not found\"\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : the indexer to the original array\n",
      " |      uniques : the unique Index\n",
      " |  \n",
      " |  item(self)\n",
      " |      return the first element of the underlying data as a python\n",
      " |      scalar\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : int\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Returns object containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : boolean, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : boolean, default True\n",
      " |          Sort by values\n",
      " |      ascending : boolean, default False\n",
      " |          Sort in ascending order\n",
      " |      bins : integer, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for pd.cut, only works with numeric data\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      counts : Series\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      return the transpose, which is by definition self\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base\n",
      " |      return the base object if the memory of the underlying data is\n",
      " |      shared\n",
      " |  \n",
      " |  data\n",
      " |      return the data pointer of the underlying data\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  flags\n",
      " |      return the ndarray.flags for the underlying data\n",
      " |  \n",
      " |  hasnans\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic_decreasing : boolean\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_monotonic : boolean\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      is_unique : boolean\n",
      " |  \n",
      " |  itemsize\n",
      " |      return the size of the dtype of the item of the underlying data\n",
      " |  \n",
      " |  nbytes\n",
      " |      return the number of bytes in the underlying data\n",
      " |  \n",
      " |  ndim\n",
      " |      return the number of dimensions of the underlying data,\n",
      " |      by definition 1\n",
      " |  \n",
      " |  shape\n",
      " |      return a tuple of the shape of the underlying data\n",
      " |  \n",
      " |  size\n",
      " |      return the number of elements in the underlying data\n",
      " |  \n",
      " |  strides\n",
      " |      return the strides of the underlying data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.strings.StringAccessorMixin:\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return an object with absolute value taken--only applicable to objects\n",
      " |      that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs: type of caller\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Concatenate prefix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_prefix : type of caller\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Concatenate suffix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_suffix : type of caller\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |             .. versionadded: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast object to input numpy.dtype\n",
      " |      Return a copy when copy = True (be really careful with this!)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : DEPRECATED use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |      upper : float or array_like, default None\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |                0         1\n",
      " |      0  0.335232 -1.256177\n",
      " |      1 -1.367855  0.746646\n",
      " |      2  0.027753 -1.176076\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  1.261967  0.570967\n",
      " |      \n",
      " |      >>> df.clip(-1.0, 0.5)\n",
      " |                0         1\n",
      " |      0  0.335232 -1.000000\n",
      " |      1 -1.000000  0.500000\n",
      " |      2  0.027753 -1.000000\n",
      " |      3  0.230930 -0.679613\n",
      " |      4  0.500000  0.500000\n",
      " |      \n",
      " |      >>> t\n",
      " |      0   -0.3\n",
      " |      1   -0.2\n",
      " |      2   -0.1\n",
      " |      3    0.0\n",
      " |      4    0.1\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 1, axis=0)\n",
      " |                0         1\n",
      " |      0  0.335232 -0.300000\n",
      " |      1 -0.200000  0.746646\n",
      " |      2  0.027753 -0.100000\n",
      " |      3  0.230930  0.000000\n",
      " |      4  1.100000  0.570967\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None)\n",
      " |      Return copy of the input with values below given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      DEPRECATED: consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Deprecated.\n",
      " |      \n",
      " |      Attempt to infer better dtype for object columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this objects data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean or string, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices or the data are copied.\n",
      " |      \n",
      " |          Note that when ``deep=True`` data is copied, actual python objects\n",
      " |          will not be copied recursively, only the reference to the object.\n",
      " |          This is in contrast to ``copy.deepcopy`` in the Standard Library,\n",
      " |          which recursively copies object data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : type of caller\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to categorical\n",
      " |            objects submit the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To select numeric types submit\n",
      " |            ``numpy.number``. To select categorical objects submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``)\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If ``include='all'``\n",
      " |      is provided as an option, the result will include a union of\n",
      " |      attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 'a'], [2, 'b'], [3, 'c']],\n",
      " |      ...                   columns=['numeric', 'object'])\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              numeric object\n",
      " |      count       3.0      3\n",
      " |      unique      NaN      3\n",
      " |      top         NaN      b\n",
      " |      freq        NaN      1\n",
      " |      mean        2.0    NaN\n",
      " |      std         1.0    NaN\n",
      " |      min         1.0    NaN\n",
      " |      25%         1.5    NaN\n",
      " |      50%         2.0    NaN\n",
      " |      75%         2.5    NaN\n",
      " |      max         3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         b\n",
      " |      freq        1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         b\n",
      " |      freq        1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  drop(self, labels, axis=0, level=None, inplace=False, errors='raise')\n",
      " |      Return new object with labels in requested axis removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |      axis : int or axis name\n",
      " |      level : int or level name, default None\n",
      " |          For MultiIndex\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and existing labels are dropped.\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : type of caller\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.select\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.first('10D') -> First 10 days\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return the counts of dtypes in this object.\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return the counts of ftypes in this object.\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, str, or iterable\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A str or list of strs\n",
      " |          may be passed to group by the columns in ``self``\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are null.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      notnull : boolean inverse of isnull\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('5M') -> Last 5 months\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is False and otherwise are from\n",
      " |      other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          If cond is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are\n",
      " |      not null.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      isnull : boolean inverse of notnull\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      .. versionadded:: 0.16.2\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : positional arguments passed into ``func``.\n",
      " |      kwargs : a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      on Series or DataFrames. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches.\n",
      " |      \n",
      " |          .. versionadded:: 0.17.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter index and / or columns using input function or functions.\n",
      " |      A scalar or list-like for ``mapper`` will alter the ``Index.name``\n",
      " |      or ``MultiIndex.names`` attribute.\n",
      " |      A function or dict for ``mapper`` will alter the labels.\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, dict-like or function, optional\n",
      " |      axis : int or string, default 0\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.NDFrame.rename\n",
      " |      pandas.Index.rename\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")  # scalar, alters df.index.name\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      >>> df.rename_axis(lambda x: 2 * x)  # function: alters labels\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |      >>> df.rename_axis({\"A\": \"ehh\", \"C\": \"see\"}, axis=\"columns\")  # mapping\n",
      " |         ehh  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      " |      Replace values given in 'to_replace' with 'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      " |      \n",
      " |          * str or regex:\n",
      " |      \n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str and regex rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      " |                follows: look in column 'a' for the value 'b' and replace it\n",
      " |                with nan. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |              - Keys map to column names and values map to substitution\n",
      " |                values. You can treat this as a special case of passing two\n",
      " |                lists except that you are specifying the column to search in.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the ``regex`` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or Series\n",
      " |                of such elements. If `value` is also ``None`` then this\n",
      " |                **must** be a nested dictionary or ``Series``.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      " |          specifying which value to use for each column (columns not in the\n",
      " |          dict will not be filled). Regular expressions, strings and lists or\n",
      " |          dicts of such objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column form a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      " |          parameter will be interpreted as a regular expression or a list,\n",
      " |          dict, or array of regular expressions.\n",
      " |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when ``to_replace`` is a\n",
      " |          ``list``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NDFrame.reindex\n",
      " |      NDFrame.asfreq\n",
      " |      NDFrame.fillna\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : NDFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      " |            regular expression or is a list, dict, ndarray, or Series.\n",
      " |      ValueError\n",
      " |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      " |            they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point numbers\n",
      " |        *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Returns a random sample of items from an axis of object.\n",
      " |      \n",
      " |      .. versionadded:: 0.16.1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, axis, labels)\n",
      " |      public verson of axis assignment\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows\n",
      " |  \n",
      " |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      " |      Attempt to write text representation of object to the system clipboard\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : boolean, defaults to True\n",
      " |              if True, use the provided separator, writing in a csv\n",
      " |              format for allowing easy pasting into excel.\n",
      " |              if False, write a string representation of the object\n",
      " |              to the clipboard\n",
      " |      sep : optional, defaults to tab\n",
      " |      other keywords are passed to to_csv\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform\n",
      " |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      " |        - Windows: none\n",
      " |        - OS X: none\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path (string) or HDFStore object\n",
      " |      key : string\n",
      " |          identifier for the group in the store\n",
      " |      mode : optional, {'a', 'w', 'r+'}, default 'a'\n",
      " |      \n",
      " |        ``'w'``\n",
      " |            Write; a new file is created (an existing file with the same\n",
      " |            name would be deleted).\n",
      " |        ``'a'``\n",
      " |            Append; an existing file is opened for reading and writing,\n",
      " |            and if the file does not exist it is created.\n",
      " |        ``'r+'``\n",
      " |            It is similar to ``'a'``, but the file must already exist.\n",
      " |      format : 'fixed(f)|table(t)', default is 'fixed'\n",
      " |          fixed(f) : Fixed format\n",
      " |                     Fast writing/reading. Not-appendable, nor searchable\n",
      " |          table(t) : Table format\n",
      " |                     Write as a PyTables Table structure which may perform\n",
      " |                     worse but allow more flexible operations like searching\n",
      " |                     / selecting subsets of the data\n",
      " |      append : boolean, default False\n",
      " |          For Table formats, append the input data to the existing\n",
      " |      data_columns :  list of columns, or True, default None\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See `here\n",
      " |          <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n",
      " |      \n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : int, 0-9, default 0\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc', None}, default None\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |           'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum\n",
      " |      dropna : boolean, default False.\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path or buffer to write the result string\n",
      " |          if this is None, return a StringIO of the converted string\n",
      " |      orient : string\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - split : dict like\n",
      " |              {index -> [index], columns -> [columns], data -> [values]}\n",
      " |            - records : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - index : dict like {index -> {column -> value}}\n",
      " |            - columns : dict like {column -> {index -> value}}\n",
      " |            - values : just the values array\n",
      " |            - table : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      " |          `iso` = ISO8601. The default depends on the `orient`. For\n",
      " |          `orient='table'`, the default is `'iso'`. For all other orients,\n",
      " |          the default is `'epoch'`.\n",
      " |      double_precision : The number of decimal places to use when encoding\n",
      " |          floating point values, default 10.\n",
      " |      force_ascii : force encoded string to be ASCII, default True.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object with filtered info axis\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pd.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer')\n",
      " |      Pickle (serialize) object to input file path.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string\n",
      " |          File path\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'xz', None}, default 'infer'\n",
      " |          a string representing the compression to use in the output file\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table\n",
      " |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. If a DBAPI2 object, only sqlite3 is supported.\n",
      " |      flavor : 'sqlite', default None\n",
      " |          DEPRECATED: this parameter will be removed in a future version,\n",
      " |          as 'sqlite' is the only supported option if SQLAlchemy is not\n",
      " |          installed.\n",
      " |      schema : string, default None\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          - fail: If table exists, do nothing.\n",
      " |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      " |          - append: If table exists, insert data. Create if does not exist.\n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, default None\n",
      " |          If not None, then rows will be written in batches of this size at a\n",
      " |          time.  If None, all rows will be written at once.\n",
      " |      dtype : dict of column name to SQL type, default None\n",
      " |          Optional specifying the datatype for columns. The SQL type should\n",
      " |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncates a sorted NDFrame before and/or after some particular\n",
      " |      index value. If the axis contains only datetime values, before/after\n",
      " |      parameters are converted to datetime values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date\n",
      " |          Truncate before index value\n",
      " |      after : date\n",
      " |          Truncate after index value\n",
      " |      axis : the truncation axis, defaults to the stat axis\n",
      " |      copy : boolean, default is True,\n",
      " |          return a copy of the truncated section\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      truncated : type of caller\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      infer_dst : boolean, default False (DEPRECATED)\n",
      " |          Attempt to infer fall dst-transition hours based on order\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is True and otherwise are from\n",
      " |      other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          If cond is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Fast label-based scalar accessor\n",
      " |      \n",
      " |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |  \n",
      " |  iat\n",
      " |      Fast integer location scalar accessor.\n",
      " |      \n",
      " |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierachical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Purely label-location based indexer for selection by label.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |        to usual python slices, **both** the start and the stop are included!).\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  is_copy = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for a object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bd_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20167        Gold\n",
       "20168      Silver\n",
       "20229      Silver\n",
       "20230      Silver\n",
       "20231      Silver\n",
       "20294        Gold\n",
       "20295      Silver\n",
       "20296      Silver\n",
       "20365      Silver\n",
       "20366      Silver\n",
       "20486      Silver\n",
       "20487      Silver\n",
       "20488        Gold\n",
       "20489      Silver\n",
       "20490      Silver\n",
       "20572        Gold\n",
       "20573      Silver\n",
       "20574      Silver\n",
       "20687      Silver\n",
       "20688      Silver\n",
       "20689      Silver\n",
       "20690      Silver\n",
       "20691      Silver\n",
       "20692      Silver\n",
       "20693      Bronze\n",
       "20694      Silver\n",
       "20695      Silver\n",
       "20696      Silver\n",
       "20697      Bronze\n",
       "20698      Silver\n",
       "           ...   \n",
       "89346      Bronze\n",
       "89347        Gold\n",
       "89348      Silver\n",
       "89349      Silver\n",
       "89350      Silver\n",
       "89351      Bronze\n",
       "89352        Gold\n",
       "89353      Bronze\n",
       "89354      Silver\n",
       "89355      Silver\n",
       "89356        Gold\n",
       "89357      Bronze\n",
       "89358      Bronze\n",
       "89359        Gold\n",
       "89360      Silver\n",
       "89361        Gold\n",
       "89362    Platinum\n",
       "89363        Gold\n",
       "89364      Bronze\n",
       "89365      Silver\n",
       "89366        Gold\n",
       "89367      Silver\n",
       "89368        Gold\n",
       "89369    Platinum\n",
       "89370      Silver\n",
       "89371      Silver\n",
       "89372      Silver\n",
       "89373      Silver\n",
       "89374        Gold\n",
       "89375      Bronze\n",
       "Name: PURCHASED, Length: 3484, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_series[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_dict = {'Alaska': 'AK', 'Alabama': 'AL', 'Arkansas': 'AR', 'American Samoa': 'AS', 'Arizona': 'AZ', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'District of Columbia': 'DC', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', 'Guam': 'GU', 'Hawaii': 'HI', 'Iowa': 'IA', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Massachusetts': 'MA', 'Maryland': 'MD', 'Maine': 'ME', 'Michigan': 'MI', 'Minnesota': 'MN', 'Missouri': 'MO', 'Northern Mariana Islands': 'MP', 'Mississippi': 'MS', 'Montana': 'MT', 'National': 'NA', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Nebraska': 'NE', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'Nevada': 'NV', 'New York': 'NY', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Virginia': 'VA', 'Virgin Islands': 'VI', 'Vermont': 'VT', 'Washington': 'WA', 'Wisconsin': 'WI', 'West Virginia': 'WV', 'Wyoming': 'WY'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_percentages(series):\n",
    "    state_dict = {}\n",
    "    for state_Data in bd_series:\n",
    "        len_state_users = len(state_Data[1])\n",
    "        d = {\"Platinum\":0, \"Gold\":0, \"Silver\":0, \"Bronze\":0}\n",
    "        for item in state_Data[1]:\n",
    "            d[item] += 1\n",
    "        for k,v in d.items():\n",
    "            val = (v/len_state_users)*100\n",
    "            d[k] = round(val,2)\n",
    "        state_abbr = states_dict[state_Data[0]]\n",
    "        state_dict[state_abbr] = d\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_percentages = cal_percentages(bd_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AK': {'Bronze': 0.0, 'Gold': 25.2, 'Platinum': 0.0, 'Silver': 74.8},\n",
       " 'AL': {'Bronze': 17.37, 'Gold': 26.38, 'Platinum': 5.08, 'Silver': 51.18},\n",
       " 'AR': {'Bronze': 16.04, 'Gold': 25.91, 'Platinum': 5.32, 'Silver': 52.73},\n",
       " 'AZ': {'Bronze': 0.0, 'Gold': 27.3, 'Platinum': 0.0, 'Silver': 72.7},\n",
       " 'CA': {'Bronze': 0.0, 'Gold': 26.1, 'Platinum': 0.0, 'Silver': 73.9},\n",
       " 'CO': {'Bronze': 0.0, 'Gold': 25.32, 'Platinum': 0.0, 'Silver': 74.68},\n",
       " 'CT': {'Bronze': 0.0, 'Gold': 30.77, 'Platinum': 0.0, 'Silver': 69.23},\n",
       " 'DC': {'Bronze': 0.0, 'Gold': 25.9, 'Platinum': 0.0, 'Silver': 74.1},\n",
       " 'DE': {'Bronze': 0.0, 'Gold': 33.33, 'Platinum': 0.0, 'Silver': 66.67},\n",
       " 'FL': {'Bronze': 16.37, 'Gold': 26.2, 'Platinum': 5.66, 'Silver': 51.77},\n",
       " 'GA': {'Bronze': 15.76, 'Gold': 25.74, 'Platinum': 5.33, 'Silver': 53.18},\n",
       " 'HI': {'Bronze': 0.0, 'Gold': 21.88, 'Platinum': 0.0, 'Silver': 78.12},\n",
       " 'IA': {'Bronze': 0.0, 'Gold': 24.73, 'Platinum': 0.0, 'Silver': 75.27},\n",
       " 'ID': {'Bronze': 0.0, 'Gold': 26.11, 'Platinum': 0.0, 'Silver': 73.89},\n",
       " 'IL': {'Bronze': 15.37, 'Gold': 26.11, 'Platinum': 4.76, 'Silver': 53.75},\n",
       " 'IN': {'Bronze': 0.0, 'Gold': 26.57, 'Platinum': 0.0, 'Silver': 73.43},\n",
       " 'KS': {'Bronze': 15.71, 'Gold': 25.98, 'Platinum': 4.97, 'Silver': 53.34},\n",
       " 'KY': {'Bronze': 0.0, 'Gold': 29.54, 'Platinum': 0.0, 'Silver': 70.46},\n",
       " 'LA': {'Bronze': 17.14, 'Gold': 25.2, 'Platinum': 5.38, 'Silver': 52.28},\n",
       " 'MA': {'Bronze': 0.0, 'Gold': 24.48, 'Platinum': 0.0, 'Silver': 75.52},\n",
       " 'MD': {'Bronze': 0.0, 'Gold': 23.66, 'Platinum': 0.0, 'Silver': 76.34},\n",
       " 'ME': {'Bronze': 0.0, 'Gold': 25.33, 'Platinum': 0.0, 'Silver': 74.67},\n",
       " 'MI': {'Bronze': 0.0, 'Gold': 26.68, 'Platinum': 0.0, 'Silver': 73.32},\n",
       " 'MN': {'Bronze': 0.0, 'Gold': 25.65, 'Platinum': 0.0, 'Silver': 74.35},\n",
       " 'MO': {'Bronze': 16.83, 'Gold': 25.99, 'Platinum': 5.15, 'Silver': 52.03},\n",
       " 'MS': {'Bronze': 14.93, 'Gold': 25.92, 'Platinum': 4.7, 'Silver': 54.45},\n",
       " 'MT': {'Bronze': 0.0, 'Gold': 27.72, 'Platinum': 0.0, 'Silver': 72.28},\n",
       " 'NC': {'Bronze': 0.0, 'Gold': 25.42, 'Platinum': 0.0, 'Silver': 74.58},\n",
       " 'ND': {'Bronze': 0.0, 'Gold': 26.49, 'Platinum': 0.0, 'Silver': 73.51},\n",
       " 'NE': {'Bronze': 16.03, 'Gold': 24.8, 'Platinum': 5.88, 'Silver': 53.29},\n",
       " 'NH': {'Bronze': 0.0, 'Gold': 26.42, 'Platinum': 0.0, 'Silver': 73.58},\n",
       " 'NJ': {'Bronze': 0.0, 'Gold': 26.71, 'Platinum': 0.0, 'Silver': 73.29},\n",
       " 'NM': {'Bronze': 0.0, 'Gold': 26.6, 'Platinum': 0.0, 'Silver': 73.4},\n",
       " 'NV': {'Bronze': 0.0, 'Gold': 27.26, 'Platinum': 0.0, 'Silver': 72.74},\n",
       " 'NY': {'Bronze': 0.0, 'Gold': 27.86, 'Platinum': 0.0, 'Silver': 72.14},\n",
       " 'OH': {'Bronze': 0.0, 'Gold': 24.27, 'Platinum': 0.0, 'Silver': 75.73},\n",
       " 'OK': {'Bronze': 16.87, 'Gold': 25.84, 'Platinum': 5.6, 'Silver': 51.68},\n",
       " 'OR': {'Bronze': 0.0, 'Gold': 26.75, 'Platinum': 0.0, 'Silver': 73.25},\n",
       " 'PA': {'Bronze': 0.0, 'Gold': 26.75, 'Platinum': 0.0, 'Silver': 73.25},\n",
       " 'RI': {'Bronze': 0.0, 'Gold': 16.13, 'Platinum': 0.0, 'Silver': 83.87},\n",
       " 'SC': {'Bronze': 0.0, 'Gold': 28.78, 'Platinum': 0.0, 'Silver': 71.22},\n",
       " 'SD': {'Bronze': 0.0, 'Gold': 28.0, 'Platinum': 0.0, 'Silver': 72.0},\n",
       " 'TN': {'Bronze': 17.22, 'Gold': 24.7, 'Platinum': 5.64, 'Silver': 52.44},\n",
       " 'TX': {'Bronze': 16.74, 'Gold': 26.06, 'Platinum': 5.9, 'Silver': 51.3},\n",
       " 'UT': {'Bronze': 0.0, 'Gold': 26.22, 'Platinum': 0.0, 'Silver': 73.78},\n",
       " 'VA': {'Bronze': 0.0, 'Gold': 26.13, 'Platinum': 0.0, 'Silver': 73.87},\n",
       " 'VT': {'Bronze': 0.0, 'Gold': 28.48, 'Platinum': 0.0, 'Silver': 71.52},\n",
       " 'WA': {'Bronze': 0.0, 'Gold': 26.73, 'Platinum': 0.0, 'Silver': 73.27},\n",
       " 'WI': {'Bronze': 0.0, 'Gold': 26.08, 'Platinum': 0.0, 'Silver': 73.92},\n",
       " 'WV': {'Bronze': 0.0, 'Gold': 26.52, 'Platinum': 0.0, 'Silver': 73.48},\n",
       " 'WY': {'Bronze': 0.0, 'Gold': 26.5, 'Platinum': 0.0, 'Silver': 73.5}}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_perc_StrObj = json.dumps(state_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"insurance_plan_by_state_data.json\", 'w') as f:\n",
    "    f.write(state_perc_StrObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_percentages.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_states = [\"HI\", \"AK\", \"FL\", \"SC\", \"GA\", \"AL\", \"NC\", \"TN\", \"RI\", \"CT\", \"MA\",\n",
    "        \"ME\", \"NH\", \"VT\", \"NY\", \"NJ\", \"PA\", \"DE\", \"MD\", \"WV\", \"KY\", \"OH\",\n",
    "        \"MI\", \"WY\", \"MT\", \"ID\", \"WA\", \"DC\", \"TX\", \"CA\", \"AZ\", \"NV\", \"UT\",\n",
    "        \"CO\", \"NM\", \"OR\", \"ND\", \"SD\", \"NE\", \"IA\", \"MS\", \"IN\", \"IL\", \"MN\",\n",
    "        \"WI\", \"MO\", \"AR\", \"OK\", \"KS\", \"LA\", \"VA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_States = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_States.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_states.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AK',\n",
       " 'AL',\n",
       " 'AR',\n",
       " 'AZ',\n",
       " 'CA',\n",
       " 'CO',\n",
       " 'CT',\n",
       " 'DC',\n",
       " 'DE',\n",
       " 'FL',\n",
       " 'GA',\n",
       " 'HI',\n",
       " 'IA',\n",
       " 'ID',\n",
       " 'IL',\n",
       " 'IN',\n",
       " 'KS',\n",
       " 'KY',\n",
       " 'LA',\n",
       " 'MA',\n",
       " 'MD',\n",
       " 'ME',\n",
       " 'MI',\n",
       " 'MN',\n",
       " 'MO',\n",
       " 'MS',\n",
       " 'MT',\n",
       " 'NC',\n",
       " 'ND',\n",
       " 'NE',\n",
       " 'NH',\n",
       " 'NJ',\n",
       " 'NM',\n",
       " 'NV',\n",
       " 'NY',\n",
       " 'OH',\n",
       " 'OK',\n",
       " 'OR',\n",
       " 'PA',\n",
       " 'RI',\n",
       " 'SC',\n",
       " 'SD',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'UT',\n",
       " 'VA',\n",
       " 'VT',\n",
       " 'WA',\n",
       " 'WI',\n",
       " 'WV',\n",
       " 'WY']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_states == script_States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK AK\n",
      "AL AL\n",
      "AR AR\n",
      "AZ AZ\n",
      "CA CA\n",
      "CO CO\n",
      "CT CT\n",
      "DC DC\n",
      "DE DE\n",
      "FL FL\n",
      "GA GA\n",
      "HI HI\n",
      "IA IA\n",
      "ID ID\n",
      "IL IL\n",
      "IN IN\n",
      "KS KS\n",
      "KY KY\n",
      "LA LA\n",
      "MA MA\n",
      "MD MD\n",
      "ME ME\n",
      "MI MI\n",
      "MN MN\n",
      "MO MO\n",
      "MS MS\n",
      "MT MT\n",
      "NC NC\n",
      "ND ND\n",
      "NE NE\n",
      "NH NH\n",
      "NJ NJ\n",
      "NM NM\n",
      "NV NV\n",
      "NY NY\n",
      "OH OH\n",
      "OK OK\n",
      "OR OR\n",
      "PA PA\n",
      "RI RI\n",
      "SC SC\n",
      "SD SD\n",
      "TN TN\n",
      "TX TX\n",
      "UT UT\n",
      "VA VA\n",
      "VT VT\n",
      "WA WA\n",
      "WI WI\n",
      "WV WV\n",
      "WY WY\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(json_states)):\n",
    "    print(json_states[i], script_States[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
